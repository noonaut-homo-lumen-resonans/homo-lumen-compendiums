"""
HOMO LUMEN LIVE - LIVE PODCAST STREAMING API
============================================
Created: 30. oktober 2025
Purpose: Enable 10 AI agents to have live conversations with Osvald
         participating in real-time, streamed to YouTube/Twitch

Features:
- Create and manage live podcast sessions
- Real-time agent conversation orchestration
- Osvald voice/text interaction
- YouTube Live streaming integration
- TTS voice generation (ElevenLabs)
- Auto-generated chapters and transcripts
- Multi-platform streaming (YouTube, Twitch, Facebook)
"""

from fastapi import APIRouter, HTTPException, WebSocket, WebSocketDisconnect, BackgroundTasks
from pydantic import BaseModel, Field
from typing import List, Optional, Dict, Any
from uuid import UUID, uuid4
from datetime import datetime, timedelta
from decimal import Decimal
import asyncio
import asyncpg
import os

router = APIRouter(prefix="/podcast", tags=["Live Podcast"])

# ============================================================
# DATABASE CONNECTION
# ============================================================

async def get_db_pool():
    """Get database connection pool."""
    return await asyncpg.create_pool(
        host=os.getenv("DB_HOST", "localhost"),
        port=int(os.getenv("DB_PORT", 5432)),
        database=os.getenv("DB_NAME", "homelumen"),
        user=os.getenv("DB_USER", "postgres"),
        password=os.getenv("DB_PASSWORD", "")
    )

# ============================================================
# PYDANTIC MODELS
# ============================================================

class CreatePodcastSession(BaseModel):
    title: str = Field(..., example="Triadisk Etikk i Praksis")
    description: Optional[str] = Field(None, example="En dypdykk i Port 1, 2, og 3")
    topic: str = Field(..., example="Triadisk Etikk")
    series: str = Field(default="Homo Lumen Live")
    episode_number: Optional[int] = None

    host_agent: str = Field(default="orion", example="orion")
    active_agents: List[str] = Field(
        default=["lira", "nyra", "thalus", "aurora"],
        example=["lira", "nyra", "thalus", "aurora"]
    )

    scheduled_start: Optional[datetime] = None
    target_duration_minutes: int = Field(default=60, example=60)

    youtube_streaming: bool = Field(default=True)
    twitch_streaming: bool = Field(default=False)
    osvald_present: bool = Field(default=True)


class AgentMessage(BaseModel):
    speaker: str = Field(..., example="orion")
    content: str = Field(..., example="Velkommen til Homo Lumen Live! I dag skal vi snakke om Triadisk Etikk.")

    humor_intent: Optional[str] = Field(None, example="cosmic")
    emotional_tone: Optional[str] = Field(None, example="calm")

    responding_to_message_id: Optional[UUID] = None


class OsvaldInteraction(BaseModel):
    input_type: str = Field(..., example="text")  # "voice" or "text"

    # If text
    text_content: Optional[str] = Field(None, example="Hva mener dere med Port 1?")

    # If voice
    voice_audio_base64: Optional[str] = None  # Base64 encoded audio
    transcription: Optional[str] = None  # Pre-transcribed (optional)


class StreamingControl(BaseModel):
    action: str = Field(..., example="start")  # start, pause, resume, stop
    platform: Optional[str] = Field(None, example="youtube")  # youtube, twitch, all


class GenerateChaptersRequest(BaseModel):
    summary_agent: str = Field(default="orion", example="orion")


# ============================================================
# ACTIVE WEBSOCKET CONNECTIONS (for real-time updates)
# ============================================================

active_connections: Dict[str, List[WebSocket]] = {}

async def broadcast_to_session(session_id: str, message: Dict[str, Any]):
    """Broadcast message to all WebSocket clients watching this session."""
    if session_id in active_connections:
        for connection in active_connections[session_id]:
            try:
                await connection.send_json(message)
            except Exception:
                # Remove dead connections
                active_connections[session_id].remove(connection)

# ============================================================
# ENDPOINTS: SESSION MANAGEMENT
# ============================================================

@router.post("/create", response_model=Dict[str, Any])
async def create_podcast_session(session: CreatePodcastSession):
    """
    Create a new live podcast session.

    This prepares the database for a live stream, configures which
    agents will participate, and sets up streaming platforms.

    Workflow:
    1. Create podcast_sessions record
    2. Create agent_participation records for each active agent
    3. Pre-validate ethics (Thalus)
    4. Return session_id and streaming URLs
    """
    pool = await get_db_pool()

    async with pool.acquire() as conn:
        # 1. Create session
        session_id = await conn.fetchval(
            """
            INSERT INTO podcast_sessions (
                title, description, topic, series, episode_number,
                host_agent, active_agents, scheduled_start,
                target_duration_minutes, osvald_present, status
            ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, 'planning')
            RETURNING id
            """,
            session.title,
            session.description,
            session.topic,
            session.series,
            session.episode_number,
            session.host_agent,
            session.active_agents,
            session.scheduled_start,
            session.target_duration_minutes,
            session.osvald_present
        )

        # 2. Create agent participation records
        for agent_name in session.active_agents + [session.host_agent]:
            # Get agent voice profile
            voice_profile = await conn.fetchrow(
                "SELECT voice_id, voice_name FROM agent_voice_profiles WHERE agent_name = $1",
                agent_name
            )

            if not voice_profile:
                raise HTTPException(
                    status_code=400,
                    detail=f"Agent {agent_name} has no voice profile configured"
                )

            agent_role = "host" if agent_name == session.host_agent else "participant"

            await conn.execute(
                """
                INSERT INTO agent_participation (
                    session_id, agent_name, agent_role, voice_id, voice_name
                ) VALUES ($1, $2, $3, $4, $5)
                ON CONFLICT (session_id, agent_name) DO NOTHING
                """,
                session_id,
                agent_name,
                agent_role,
                voice_profile['voice_id'],
                voice_profile['voice_name']
            )

        # 3. TODO: Pre-validate ethics with Thalus
        # This would call Thalus agent to score the topic/description

        return {
            "session_id": str(session_id),
            "status": "planning",
            "title": session.title,
            "topic": session.topic,
            "host_agent": session.host_agent,
            "active_agents": session.active_agents,
            "next_step": "Call POST /podcast/{session_id}/start when ready to go live",
            "preview_url": f"http://localhost:8000/podcast/{session_id}/preview"
        }


@router.post("/{session_id}/start", response_model=Dict[str, Any])
async def start_podcast_stream(session_id: UUID, background_tasks: BackgroundTasks):
    """
    Start live streaming for a podcast session.

    Workflow:
    1. Validate session exists and is in 'planning' status
    2. Initialize YouTube Live stream (RTMP)
    3. Start OBS Studio (background process)
    4. Update session status to 'live'
    5. Send opening message from host (Orion)
    6. Return stream URLs
    """
    pool = await get_db_pool()

    async with pool.acquire() as conn:
        # 1. Validate session
        session = await conn.fetchrow(
            "SELECT * FROM podcast_sessions WHERE id = $1",
            session_id
        )

        if not session:
            raise HTTPException(status_code=404, detail="Session not found")

        if session['status'] != 'planning':
            raise HTTPException(
                status_code=400,
                detail=f"Session is already {session['status']}, cannot start"
            )

        # 2. TODO: Initialize YouTube Live API
        # This would create a live broadcast and get RTMP URL + stream key
        youtube_stream_url = "rtmp://a.rtmp.youtube.com/live2/"
        youtube_stream_key = "PLACEHOLDER_STREAM_KEY"  # From YouTube API
        youtube_video_id = "PLACEHOLDER_VIDEO_ID"

        # 3. Update session to 'live'
        await conn.execute(
            """
            UPDATE podcast_sessions
            SET status = 'live',
                actual_start = NOW(),
                youtube_stream_url = $2,
                youtube_stream_key = $3,
                youtube_video_id = $4
            WHERE id = $1
            """,
            session_id,
            youtube_stream_url,
            youtube_stream_key,
            youtube_video_id
        )

        # 4. Send opening message from host
        host_agent = session['host_agent']
        opening_message = f"Velkommen til {session['title']}! I dag skal vi utforske {session['topic']}."

        # Insert opening message
        await conn.execute(
            """
            INSERT INTO podcast_messages (
                session_id, speaker, speaker_type, content,
                timestamp_seconds, emotional_tone
            ) VALUES ($1, $2, 'agent', $3, 0.0, 'welcoming')
            """,
            session_id,
            host_agent,
            opening_message
        )

        # 5. TODO: Start background tasks
        # - OBS Studio controller
        # - TTS generation queue
        # - YouTube chat monitor
        background_tasks.add_task(monitor_stream_health, session_id)

        # Broadcast to WebSocket clients
        await broadcast_to_session(str(session_id), {
            "type": "stream_started",
            "session_id": str(session_id),
            "youtube_video_id": youtube_video_id
        })

        return {
            "session_id": str(session_id),
            "status": "live",
            "youtube_video_id": youtube_video_id,
            "youtube_watch_url": f"https://www.youtube.com/watch?v={youtube_video_id}",
            "rtmp_url": youtube_stream_url,
            "started_at": datetime.now().isoformat(),
            "message": "ðŸ”´ LIVE! Stream is now broadcasting to YouTube."
        }


@router.post("/{session_id}/message", response_model=Dict[str, Any])
async def send_agent_message(
    session_id: UUID,
    message: AgentMessage,
    background_tasks: BackgroundTasks
):
    """
    Agent sends a message during live podcast.

    Workflow:
    1. Validate session is 'live'
    2. Store message in podcast_messages
    3. Generate TTS audio (ElevenLabs) - background task
    4. Update agent participation stats
    5. Broadcast to WebSocket clients
    6. Return message_id
    """
    pool = await get_db_pool()

    async with pool.acquire() as conn:
        # 1. Validate session
        session = await conn.fetchrow(
            "SELECT status, actual_start FROM podcast_sessions WHERE id = $1",
            session_id
        )

        if not session or session['status'] != 'live':
            raise HTTPException(
                status_code=400,
                detail="Session is not live"
            )

        # 2. Calculate timestamp (seconds from session start)
        seconds_from_start = (datetime.now() - session['actual_start']).total_seconds()

        # 3. Get agent voice profile
        voice_profile = await conn.fetchrow(
            """
            SELECT voice_id, model, stability, similarity_boost
            FROM agent_voice_profiles
            WHERE agent_name = $1
            """,
            message.speaker
        )

        if not voice_profile:
            raise HTTPException(
                status_code=400,
                detail=f"No voice profile for agent {message.speaker}"
            )

        # 4. Insert message
        message_id = await conn.fetchval(
            """
            INSERT INTO podcast_messages (
                session_id, speaker, speaker_type, content,
                timestamp_seconds, voice_id, tts_model,
                humor_intent, emotional_tone, responding_to_message_id
            ) VALUES ($1, $2, 'agent', $3, $4, $5, $6, $7, $8, $9)
            RETURNING id
            """,
            session_id,
            message.speaker,
            message.content,
            Decimal(str(seconds_from_start)),
            voice_profile['voice_id'],
            voice_profile['model'],
            message.humor_intent,
            message.emotional_tone,
            message.responding_to_message_id
        )

        # 5. Update agent participation stats
        await conn.execute(
            """
            UPDATE agent_participation
            SET message_count = message_count + 1,
                humor_instances = humor_instances + CASE WHEN $3 IS NOT NULL THEN 1 ELSE 0 END
            WHERE session_id = $1 AND agent_name = $2
            """,
            session_id,
            message.speaker,
            message.humor_intent
        )

        # 6. Background task: Generate TTS audio
        background_tasks.add_task(
            generate_tts_audio,
            message_id,
            message.content,
            voice_profile
        )

        # 7. Broadcast to WebSocket
        await broadcast_to_session(str(session_id), {
            "type": "new_message",
            "message_id": str(message_id),
            "speaker": message.speaker,
            "content": message.content,
            "timestamp_seconds": seconds_from_start,
            "humor_intent": message.humor_intent,
            "emotional_tone": message.emotional_tone
        })

        return {
            "message_id": str(message_id),
            "speaker": message.speaker,
            "timestamp_seconds": seconds_from_start,
            "tts_status": "generating",
            "message": f"{message.speaker} spoke at {seconds_from_start:.1f}s"
        }


@router.post("/{session_id}/osvald-interact", response_model=Dict[str, Any])
async def osvald_interact(
    session_id: UUID,
    interaction: OsvaldInteraction,
    background_tasks: BackgroundTasks
):
    """
    Osvald interacts with agents (voice or text).

    Workflow:
    1. Validate session is 'live'
    2. Process input:
       - If voice: Transcribe with Whisper
       - If text: Use directly
    3. Store in osvald_interactions
    4. Trigger agent responses (Orion decides who responds)
    5. Broadcast to WebSocket
    """
    pool = await get_db_pool()

    async with pool.acquire() as conn:
        # 1. Validate session
        session = await conn.fetchrow(
            "SELECT status, actual_start, host_agent FROM podcast_sessions WHERE id = $1",
            session_id
        )

        if not session or session['status'] != 'live':
            raise HTTPException(status_code=400, detail="Session is not live")

        # 2. Process input
        if interaction.input_type == "voice":
            # TODO: Transcribe with Whisper
            if not interaction.transcription:
                raise HTTPException(
                    status_code=400,
                    detail="Voice transcription not yet implemented"
                )
            processed_content = interaction.transcription
            transcription_confidence = 0.95
        else:
            processed_content = interaction.text_content
            transcription_confidence = None

        # 3. Calculate timestamp
        seconds_from_start = (datetime.now() - session['actual_start']).total_seconds()

        # 4. Insert interaction
        interaction_id = await conn.fetchval(
            """
            INSERT INTO osvald_interactions (
                session_id, input_type, text_content, transcription,
                transcription_confidence, processed_content, timestamp_seconds
            ) VALUES ($1, $2, $3, $4, $5, $6, $7)
            RETURNING id
            """,
            session_id,
            interaction.input_type,
            interaction.text_content,
            interaction.transcription,
            transcription_confidence,
            processed_content,
            Decimal(str(seconds_from_start))
        )

        # 5. Insert as message (so it appears in transcript)
        message_id = await conn.fetchval(
            """
            INSERT INTO podcast_messages (
                session_id, speaker, speaker_type, content, timestamp_seconds
            ) VALUES ($1, 'osvald', 'human', $2, $3)
            RETURNING id
            """,
            session_id,
            processed_content,
            Decimal(str(seconds_from_start))
        )

        # 6. Broadcast to WebSocket
        await broadcast_to_session(str(session_id), {
            "type": "osvald_interaction",
            "interaction_id": str(interaction_id),
            "input_type": interaction.input_type,
            "content": processed_content,
            "timestamp_seconds": seconds_from_start
        })

        # 7. Background task: Trigger agent responses
        # Orion (host) decides who should respond
        background_tasks.add_task(
            orchestrate_agent_responses,
            session_id,
            interaction_id,
            processed_content,
            session['host_agent']
        )

        return {
            "interaction_id": str(interaction_id),
            "message_id": str(message_id),
            "timestamp_seconds": seconds_from_start,
            "processed_content": processed_content,
            "status": "agents_responding",
            "message": f"Osvald spoke: '{processed_content[:50]}...'"
        }


@router.post("/{session_id}/stop", response_model=Dict[str, Any])
async def stop_podcast_stream(session_id: UUID, background_tasks: BackgroundTasks):
    """
    Stop live streaming and begin post-processing.

    Workflow:
    1. Stop OBS Studio
    2. Stop YouTube stream
    3. Update session status to 'processing'
    4. Generate transcript
    5. Generate chapters (Orion)
    6. Publish VOD
    """
    pool = await get_db_pool()

    async with pool.acquire() as conn:
        # 1. Validate session
        session = await conn.fetchrow(
            "SELECT * FROM podcast_sessions WHERE id = $1",
            session_id
        )

        if not session or session['status'] != 'live':
            raise HTTPException(status_code=400, detail="Session is not live")

        # 2. Calculate duration
        duration_seconds = (datetime.now() - session['actual_start']).total_seconds()
        duration_minutes = int(duration_seconds / 60)

        # 3. Update session
        await conn.execute(
            """
            UPDATE podcast_sessions
            SET status = 'processing',
                ended_at = NOW(),
                duration_minutes = $2
            WHERE id = $1
            """,
            session_id,
            duration_minutes
        )

        # 4. TODO: Stop OBS and YouTube stream

        # 5. Background tasks: Post-processing
        background_tasks.add_task(generate_transcript, session_id)
        background_tasks.add_task(generate_chapters, session_id, "orion")
        background_tasks.add_task(publish_vod, session_id)

        # 6. Broadcast to WebSocket
        await broadcast_to_session(str(session_id), {
            "type": "stream_stopped",
            "session_id": str(session_id),
            "duration_minutes": duration_minutes
        })

        return {
            "session_id": str(session_id),
            "status": "processing",
            "duration_minutes": duration_minutes,
            "message": "ðŸ›‘ Stream stopped. Processing transcript, chapters, and VOD..."
        }


# ============================================================
# ENDPOINTS: QUERY & STATUS
# ============================================================

@router.get("/{session_id}/status", response_model=Dict[str, Any])
async def get_podcast_status(session_id: UUID):
    """Get current status of a podcast session."""
    pool = await get_db_pool()

    async with pool.acquire() as conn:
        session = await conn.fetchrow(
            "SELECT * FROM podcast_session_summary WHERE id = $1",
            session_id
        )

        if not session:
            raise HTTPException(status_code=404, detail="Session not found")

        return {
            "session_id": str(session['id']),
            "title": session['title'],
            "topic": session['topic'],
            "status": session['status'],
            "duration_minutes": session['duration_minutes'],
            "youtube_video_id": session['youtube_video_id'],
            "peak_viewers": session['peak_concurrent_viewers'],
            "total_messages": session['total_messages'],
            "osvald_messages": session['osvald_messages'],
            "participating_agents": session['participating_agents']
        }


@router.get("/{session_id}/messages", response_model=List[Dict[str, Any]])
async def get_podcast_messages(session_id: UUID, limit: int = 100):
    """Get all messages from a podcast session (transcript)."""
    pool = await get_db_pool()

    async with pool.acquire() as conn:
        messages = await conn.fetch(
            """
            SELECT
                id, speaker, speaker_type, content,
                timestamp_seconds, humor_intent, emotional_tone,
                created_at
            FROM podcast_messages
            WHERE session_id = $1
            ORDER BY timestamp_seconds ASC
            LIMIT $2
            """,
            session_id,
            limit
        )

        return [
            {
                "message_id": str(m['id']),
                "speaker": m['speaker'],
                "speaker_type": m['speaker_type'],
                "content": m['content'],
                "timestamp_seconds": float(m['timestamp_seconds']),
                "humor_intent": m['humor_intent'],
                "emotional_tone": m['emotional_tone']
            }
            for m in messages
        ]


@router.get("/{session_id}/chapters", response_model=List[Dict[str, Any]])
async def get_podcast_chapters(session_id: UUID):
    """Get auto-generated chapters for a podcast session."""
    pool = await get_db_pool()

    async with pool.acquire() as conn:
        chapters = await conn.fetch(
            """
            SELECT * FROM podcast_chapters
            WHERE session_id = $1
            ORDER BY chapter_number ASC
            """,
            session_id
        )

        return [
            {
                "chapter_number": c['chapter_number'],
                "title": c['title'],
                "description": c['description'],
                "start_timestamp": float(c['start_timestamp_seconds']),
                "end_timestamp": float(c['end_timestamp_seconds']),
                "duration_seconds": c['duration_seconds'],
                "key_topics": c['key_topics'],
                "agents_present": c['agents_present']
            }
            for c in chapters
        ]


# ============================================================
# WEBSOCKET: REAL-TIME UPDATES
# ============================================================

@router.websocket("/{session_id}/live")
async def websocket_live_updates(websocket: WebSocket, session_id: str):
    """
    WebSocket endpoint for real-time podcast updates.

    Clients connect here to receive:
    - New messages from agents
    - Osvald interactions
    - Stream health metrics
    - Chat messages
    """
    await websocket.accept()

    # Add to active connections
    if session_id not in active_connections:
        active_connections[session_id] = []
    active_connections[session_id].append(websocket)

    try:
        await websocket.send_json({
            "type": "connected",
            "session_id": session_id,
            "message": "Connected to live podcast stream"
        })

        # Keep connection alive
        while True:
            # Receive messages from client (e.g., chat commands)
            data = await websocket.receive_text()

            # Echo back for now
            await websocket.send_json({
                "type": "echo",
                "data": data
            })

    except WebSocketDisconnect:
        active_connections[session_id].remove(websocket)


# ============================================================
# BACKGROUND TASKS (Placeholder Implementations)
# ============================================================

async def generate_tts_audio(message_id: UUID, content: str, voice_profile: dict):
    """
    Generate TTS audio using ElevenLabs API.

    TODO: Implement actual ElevenLabs API call.
    """
    await asyncio.sleep(2)  # Simulate TTS generation

    # Update message with audio file path
    pool = await get_db_pool()
    async with pool.acquire() as conn:
        await conn.execute(
            """
            UPDATE podcast_messages
            SET audio_file_path = $2,
                audio_processing_status = 'completed',
                duration_seconds = $3
            WHERE id = $1
            """,
            message_id,
            f"/audio/{message_id}.mp3",
            5.0  # Placeholder duration
        )


async def orchestrate_agent_responses(
    session_id: UUID,
    interaction_id: UUID,
    content: str,
    host_agent: str
):
    """
    Orion (or host) decides which agents should respond to Osvald.

    TODO: Implement AI orchestration logic.
    """
    await asyncio.sleep(1)  # Simulate thinking

    # For now, let host respond
    pool = await get_db_pool()
    async with pool.acquire() as conn:
        await conn.execute(
            """
            INSERT INTO podcast_messages (
                session_id, speaker, speaker_type, content,
                timestamp_seconds, emotional_tone
            )
            SELECT
                $1, $2, 'agent', $3,
                (EXTRACT(EPOCH FROM NOW()) - EXTRACT(EPOCH FROM actual_start))::DECIMAL,
                'responsive'
            FROM podcast_sessions
            WHERE id = $1
            """,
            session_id,
            host_agent,
            f"Det er et godt spÃ¸rsmÃ¥l! La meg forklare..."
        )


async def monitor_stream_health(session_id: UUID):
    """
    Monitor stream health metrics every 5 seconds.

    TODO: Implement actual OBS/RTMP monitoring.
    """
    while True:
        await asyncio.sleep(5)

        pool = await get_db_pool()
        async with pool.acquire() as conn:
            # Check if session is still live
            status = await conn.fetchval(
                "SELECT status FROM podcast_sessions WHERE id = $1",
                session_id
            )

            if status != 'live':
                break

            # Insert health metric
            await conn.execute(
                """
                INSERT INTO streaming_health_metrics (
                    session_id, seconds_from_start, bitrate_kbps,
                    dropped_frames, concurrent_viewers, health_status
                )
                SELECT
                    $1,
                    (EXTRACT(EPOCH FROM NOW()) - EXTRACT(EPOCH FROM actual_start))::DECIMAL,
                    2500, 0, 42, 'healthy'
                FROM podcast_sessions
                WHERE id = $1
                """,
                session_id
            )


async def generate_transcript(session_id: UUID):
    """Generate full transcript of podcast session."""
    pool = await get_db_pool()
    async with pool.acquire() as conn:
        messages = await conn.fetch(
            """
            SELECT speaker, content, timestamp_seconds
            FROM podcast_messages
            WHERE session_id = $1
            ORDER BY timestamp_seconds ASC
            """,
            session_id
        )

        transcript = "\n\n".join([
            f"[{float(m['timestamp_seconds']):.1f}s] {m['speaker'].upper()}: {m['content']}"
            for m in messages
        ])

        transcript_path = f"/transcripts/{session_id}.txt"

        # TODO: Write to file

        await conn.execute(
            "UPDATE podcast_sessions SET transcript_file_path = $2 WHERE id = $1",
            session_id,
            transcript_path
        )


async def generate_chapters(session_id: UUID, summary_agent: str):
    """
    Generate auto-chapters using Orion (or specified agent).

    TODO: Implement AI chapter generation.
    """
    await asyncio.sleep(5)  # Simulate AI processing

    # Placeholder: Create 3 chapters
    pool = await get_db_pool()
    async with pool.acquire() as conn:
        chapters = [
            {"title": "Introduction", "start": 0, "end": 300},
            {"title": "Deep Dive", "start": 300, "end": 2400},
            {"title": "Conclusion & Q&A", "start": 2400, "end": 3600}
        ]

        for i, chapter in enumerate(chapters, 1):
            await conn.execute(
                """
                INSERT INTO podcast_chapters (
                    session_id, chapter_number, title,
                    start_timestamp_seconds, end_timestamp_seconds,
                    duration_seconds, generated_by
                ) VALUES ($1, $2, $3, $4, $5, $6, $7)
                """,
                session_id,
                i,
                chapter['title'],
                chapter['start'],
                chapter['end'],
                chapter['end'] - chapter['start'],
                summary_agent
            )


async def publish_vod(session_id: UUID):
    """
    Publish VOD to YouTube after stream ends.

    TODO: Implement YouTube VOD publishing.
    """
    await asyncio.sleep(10)  # Simulate processing

    pool = await get_db_pool()
    async with pool.acquire() as conn:
        await conn.execute(
            """
            UPDATE podcast_sessions
            SET status = 'published',
                vod_youtube_url = $2
            WHERE id = $1
            """,
            session_id,
            f"https://www.youtube.com/watch?v=PLACEHOLDER_VOD"
        )
