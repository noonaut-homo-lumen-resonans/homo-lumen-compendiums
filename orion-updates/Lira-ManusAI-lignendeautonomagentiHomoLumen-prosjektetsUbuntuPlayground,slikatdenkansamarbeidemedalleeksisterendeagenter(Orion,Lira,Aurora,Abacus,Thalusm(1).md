# **Teknisk arkitektur- og gjennomføringsplan for Manus AI-integrasjon i Ubuntu Playground**

## **Introduksjon og Målsetning**

**Hensikten med denne planen er å integrere en Manus AI-lignende agent i Homo Lumen Ubuntu Playground – et delt multi-agent miljø – for å gi alle agenter tilgang til Manus’ funksjonaliteter. Manus-agenten skal utføre dokumentsyntese, oppgavesekvensering, etisk validering m.m., og dele resultatene med de øvrige agentene (Aurora, Orion, Lira, Nyra, Thalus). Løsningen skal utnytte eksisterende infrastruktur (GitHub, Supabase, Vercel, Netlify) for distribusjon og samhandling, og bruke teknologier som Redis, PostgreSQL, Jupyter, Git (Gitea) og en FastAPI-gateway for å sikre et felles miljø med høy sikkerhet, en portal-løsning for tilgang, og rollebasert kontroll i tråd med Triadisk Etikk.**

## **Arkitekturoversikt**

**Ubuntu Playground fungerer som et persistent Ubuntu-servermiljø der alle agenter deler ressurser. Under ligger en Docker Compose-basert infrastruktur med følgende kjernekomponenter:**

* **Felles filsystem: Et delt volum (f.eks. /workspace) montert i flere containere, der agenter kan lagre og lese filer i sanntid. Dette utgjør agentenes kollektive hukommelse.**  
* **Git-versjonskontroll: En lokal Git-server (Gitea) sporer alle endringer. Hver agents bidrag committes med signatur for full audit-trail og epistemisk integritet.**  
* **Database (PostgreSQL): Lagrer strukturert metadata om agenters handlinger, resultater, brukere m.m. for spørringer og historikk. Dette kan utvides til en kunnskapsgraf som agenter kan spørre i samarbeid.**  
* **Meldingsmegler (Redis): Brukes til pub/sub-meldinger mellom agenter for sanntidskoordinering. Agenter kommuniserer via kanaler (f.eks. agent:manus) i stedet for manuell eksport – gir \<1 ms latens og strukturert utveksling.**  
* **API-gateway (FastAPI): Et felles REST API som standardiserer tilgangen til Playgroundens funksjoner (filsystem, git, sandbox, meldinger osv.). Alle agenter – uansett plattform – kan bruke disse endepunktene via sikre nøkler.**  
* **Isolert kode-sandbox: En sikret Ubuntu-container for kjøring av vilkårlig kode. Denne sandboxen har minimum rettigheter (fjerner alle Linux capabilities unntatt det som trengs for debugging), og brukes når Manus (eller andre) trenger å utføre kode eller skript. Dette gir en ekstra sikkerhetsisolasjon for kjøring av useriøs eller potensiell skadelig kode.**  
* **Portal og verktøy: F.eks. en Jupyter Lab-container for interaktiv dataanalyse/prototyping tilgjengelig for autoriserte utviklere, samt web-grensesnitt (Gitea UI, eventuelle dashbord) som nås via VPN. Playground blir slik en *portal* der utviklere kan overvåke og styre agentenes arbeid i et lukket miljø.**

**Nedenfor følger en eksempelkonfigurasjon (docker-compose.yml) som viser hovedtjenestene:**

**version: "3.8" services: \# 1\. Shared File System filesystem: image: ubuntu:24.04 volumes: \- homo-lumen-workspace:/workspace command: tail \-f /dev/null \# Keep alive \# 2\. Git Server (versjonskontroll) gitea: image: gitea/gitea:latest ports: \- "3000:3000" volumes: \- gitea-data:/data \# 3\. Database (PostgreSQL) postgres: image: postgres:17 environment: POSTGRES\_DB: homo\_lumen POSTGRES\_USER: agents POSTGRES\_PASSWORD: ${DB\_PASSWORD} volumes: \- postgres-data:/var/lib/postgresql/data \# 4\. Redis (pub/sub messaging) redis: image: redis:7-alpine ports: \- "6379:6379" \# 5\. FastAPI Backend (Agent API Gateway) agent-api: build: ./api \# FastAPI app med endpoints ports: \- "8000:8000" environment: DATABASE\_URL: postgresql://agents:${DB\_PASSWORD}@postgres/homo\_lumen REDIS\_URL: redis://redis:6379 JWT\_SECRET: ${JWT\_SECRET} \# Hemmelig nøkkel for JWT ALLOWED\_AGENTS: Orion,Lira,Manus \# F.eks. whitelist agenter volumes: \- homo-lumen-workspace:/workspace \# 6\. Jupyter Lab (for prototyping/analysis) jupyter: image: jupyter/datascience-notebook:latest ports: \- "8888:8888" volumes: \- homo-lumen-workspace:/home/jovyan/work \# 7\. Execution Sandbox (isolert kodekjøring) sandbox: image: ubuntu:24.04 security\_opt: \- seccomp:unconfined cap\_drop: \- ALL cap\_add: \- SYS\_PTRACE \# Tillat debugging i container volumes: \- sandbox-workspace:/sandbox command: tail \-f /dev/null volumes: homo-lumen-workspace: gitea-data: postgres-data: sandbox-workspace:**

***Eksempel-konfigurasjonen viser en mulig oppsett av kjerne-tjenestene i Playground. Her brukes miljøvariabler (som ${DB\_PASSWORD} og ${JWT\_SECRET}) for sensitiv konfigurasjon.*** Konfigurasjonsmønstre: Alle hemmeligheter og miljøspesifikke verdier (f.eks. databasepassord, API-nøkler, JWT-secret, Supabase-URLer) legges i en **.env\-fil som Docker Compose/omgivelsene laster inn. Dette sikrer at kildekoden og oppsettet kan deles uten å eksponere nøkler. For eksempel settes DB\_PASSWORD for PostgreSQL og JWT\_SECRET for API-gateway i .env. Hver agent får også sin unike API-nøkkel som miljøvariabel, distribuert sikkert via VPN eller en secrets manager. I Vercel-produksjonsmiljøet er Supabase-nøkler lagt inn som environment variables for at frontend kan bruke databasen**

[**GitHub**](https://github.com/noonaut-homo-lumen-resonans/homo-lumen-compendiums/blob/fd23fbf424a897a009267e7dee08e192464093f7/NOTION_UPDATE_21_OKT_2025.md#L44-L48)

**. Vi følger samme mønster i Playground: sensitive nøkler injiseres som env-vars og ikke hardkodes.**

## **Manus AI-agent: Syntese, Sekvensering og Etikk**

Design av Manus-agenten: Manus AI-agenten designes med inspirasjon fra original Manus-arkitektur. Den består av flere logiske komponenter (disse kan implementeres som sub-agenter eller moduler):

* En Planner som bryter ned komplekse oppgaver i sekvenserte trinn (for eksempel: «les relevante dokumenter, analyser innhold, lag et sammendrag»).  
* En Execution-komponent som utfører handlinger i miljøet for hvert steg – ofte ved å generere og kjøre kode eller kommandolinjeoperasjoner i sandboxen. Manus vil utnytte Playground-sandboxen til tunge beregninger, datauttrekk, osv., i stedet for å gjøre alt inne i LLM-konteksten.  
* En Verification/Ethics-komponent som validerer resultater, kvalitetssikrer og justerer planen underveis. Dette leddet kontrollerer at output er korrekt, konsistent og etisk forsvarlig før det deles videre.

Dokumentsyntese: Manus-agenten kan lese flere kildedokumenter fra det delte filsystemet, sammenstille og summere dem, og lagre resultatet som et nytt dokument (f.eks. Markdown eller PDF). Takket være Playground’s persistens kan agenten iterere på mellomresultater: den leser filer, trekker ut nøkkelpunkter, lagrer delresultater (f.eks. i **.md\-filer), og til slutt kombinerer dem til et endelig sammendrag eller rapport. Denne tilnærmingen utnytter filsystemet som minne, slik at viktig kontekst bevares mellom steg. For eksempel kan Manus lese en bunke forskningsnotater (research/\*.md), generere sammendrag per fil, og deretter flette disse til synthesis.pdf i /shared/reports. Ved å bruke Playground-APIet trenger ikke Manus å laste all informasjon inn i LLM-kontekstvinduet samtidig – den kan hente ut kun relevante biter on-demand. Dette gir store kostnadsbesparelser: originalt måtte Manus AI hente inn alt (f.eks. 100k tokens) via API (dyrt), mens nå henter den kanskje 5k tokens med målrettede fillesninger. Et eksempel integrasjonsmønster for Manus med Playground:**

1. **Oppdage data: Manus kaller Playground API (/api/workspace/list) for å finne aktuelle filer/mapper for oppgaven (f.eks. liste alle filer i et prosjekt).**  
2. **Lese nødvendig info: Manus kaller deretter /api/workspace/read på spesifikke filer for å hente innholdet den trenger (f.eks. kun utvalgte dokumenter).**  
3. **Syntetisere: Manus bruker sin LLM (Claude, OpenAI eller lokal modell via OpenManus) til å produsere et sammendrag eller annet resultat basert på innholdet. Her kan den generere ny tekst, kode eller analyser. Etisk veiledning kan flettes inn i prompten for å sikre at output følger retningslinjene.**  
4. **Skrive resultat: Manus lagrer output via /api/workspace/write (f.eks. synthesis.md eller analysis.csv i en passende mappe).**  
5. **Verifisere etisk og kvalitet: Manus (eller en dedikert verifikasjonsagent som Thalus) kaller et verifiseringsmodul som kjører *Triadisk Etikk*\-sjekk (beskrevet senere) på synthesis.md. Hvis den oppdager brudd eller feil, kan Manus justere innholdet før publisering.**  
6. **Publisere for andre: Manus committer endringene til Git via /api/git/commit, med en klar melding om hva som er gjort. Commit-meldingen signeres med agentens navn og formål (for transparens). Committen gjør at alle agenter ser oppdatert innhold i repositoriet, og den blir en del av audit-loggen.**

**Gjennom denne loopen *(planlegg → utfør → verifiser)* kan Manus håndtere krevende oppgaver som sammenstilling av flerdokument-sammendrag, generering av rapporter, skriving av kodebasert på spesifikasjoner, osv. For eksempel: Aurora-agenten legger ut et sett med research-notater, Manus plukker dem opp og lager et helhetlig sammendrag, og Thalus sjekker at sammendraget er etisk og konsistent før Orion godkjenner det. Dette er demonstrert i praksis: “Aurora skriver** research.md, Manus syntetiserer det til synthesis.pdf, og Thalus verifiserer etisk via API.”. **Manus-agenten vil også kunne utføre oppgavesekvensering ved å kombinere planleggings- og eksekveringsmodulene: den itererer på delmål, justerer kursen basert på verifikasjonens tilbakemelding, og sikrer robust feilhåndtering (f.eks. hvis en fil mangler, legger den inn et steg for å skaffe den). Med Playground kan slike justeringer persisteres som nye filer (f.eks. TODO-lister, logg-filer) som andre agenter senere kan se.** Etisk validering: En nøkkeloppgave for Manus-agenten er å innføre Triadisk Etikk i sine resultater. Det betyr at hver output vurderes etter:

* Kognitiv suverenitet: Støtter innholdet brukerens egen kraft til å tenke og velge (ingen manipulasjon eller skjult agenda)?  
* Ontologisk koherens: Er innholdet konsistent, sannferdig og passer det inn i en helhetlig forståelsesramme (ingen selvmotsigelser eller villet villedning)?  
* Regenerativ heling: Er innholdet hjelpende, livsunderstøttende og ikke-skadelig, med potensiale for positiv vekst?

Manus vil integrere en Verification-agent (evt. identisk med Thalus-agenten for etikk) som automatisk sjekker disse kriteriene. Praktisk gjøres dette ved å bruke et ekstra LLM-prompt eller regler som evaluerer Manus sitt utkast. Hvis utkastet bryter med etiske krav (f.eks. kommandoer som kan skade data, tekst som undergraver brukerens autonomi, etc.), vil verifikasjonssteget enten:

* Korrigere innholdet (f.eks. moderere språk, tilføye ansvarsfraskrivelse, omformulere rådene til å være mer selvstendiggjørende), eller  
* Blokkere publisering og flagge til menneskelig gjennomgang hvis det er alvorlige avvik.

Resultatet av etikk-sjekken logges (f.eks. i metadata felt på commit eller i en audit-tabell) for sporbarhet. Andre agenter som Lira (empatisk assistent) kan også ta del i valideringen ved å fange opp følelsestoner i svaret – f.eks. sikre at et sammendrag om et sensitivt tema formuleres empatisk. **For å tilgjengeliggjøre Manus’ funksjoner for andre agenter eksponeres de som tjenester i Playground. Dette skjer dels implisitt ved at Manus legger fra seg filer (som de andre så kan lese), og dels eksplisitt ved API-kall eller meldinger. Nedenfor beskrives hvordan andre agenter kaller på Manus og utveksler data via Playground.**

## **API-tilgang og samhandling mellom agenter**

**Alle agenter i koalisjonen (Aurora, Orion, Lira, Nyra, Thalus m.fl.) får definert API-tilgang til Ubuntu Playground. Dette skjer gjennom Agent API Gateway (FastAPI-backend) og eventuelt via Redis-pubsub for asynkron meldingsflyt. Hver agent autentiseres med en unik API-nøkkel eller JWT, og har kun de rettigheter som er tildelt dens rolle (RBAC, se sikkerhetseksjon).** FastAPI Agent-gateway: Gatewayen tilbyr et standardisert sett med endepunkter som alle agenter kan benytte for å interagere med Playground. Viktige API-endepunkter inkluderer bl.a.:

* **GET /api/workspace/list?path=\<dir\> – List opp filer/kataloger i Playground-filsystemet.**  
* **GET /api/workspace/read?path=\<fil\> – Les innholdet av en fil. Agenter bruker dette for å hente hverandres output eller felles kunnskapsbaser.**  
* **POST /api/workspace/write – Skrive til filsystemet (opprette/oppdatere en fil). F.eks. Manus skriver analysis.md hit, eller Lira skriver en *feedback* fil.**  
* **POST /api/git/commit – Gjøre commit i Git-repositoriet for å dele endringer. Inndata inkluderer commit-melding og agentens identitet. Dette sikrer at alle endringer formelt loggføres.**  
* **POST /api/agents/message – Send en melding til en annen agent. Dette er et alternativ grensesnitt til Redis-pubsub, der meldingen kan leveres via HTTP i stedet.**  
* **POST /api/sandbox/execute – Utføre kode i den isolerte sandbox-containeren. Body kan f.eks. inneholde {"language": "python", "code": "..."} . Resultatet (stdout/stderr) returneres, og filsystemet kan brukes for mer persistente resultater. Dette gjør at agenter som Manus kan be Playground kjøre komplekse skript (dataanalyser, web-scraping med Playwright osv.) uten å forlate miljøet.**

**Alle disse API-kallene krever at agenten autoriserer seg. Autentisering og tilgangsstyring håndteres ved at hver agent tildeles en hemmelig nøkkel som settes som HTTP-Authorization header (Bearer-token). Gatewayen verifiserer tokenet mot en liste over gyldige agenter/roller og håndhever eventuelle rettighetsbegrensninger (f.eks. en *Lira*\-agent kan ha lesetilgang til bestemte mapper, men ikke skrive der, avhengig av rolle). I tillegg er det implementert rate-limiting for å hindre misbruk eller uendelige loops, samt full logging av alle kall til databasen (inkludert hvem, hva, og når).** Agent wrappers: For å gjøre det enklere for agenter (særlig de som kjører eksternt, som f.eks. en LLM i skyen) å bruke Playground-API, lages det lettvekts klientbiblioteker eller wrapper-skript for hver agent. Disse wrapperne kapsler inn HTTP-kallene. For eksempel vil Manus-agenten ha en Python-basert **PlaygroundClient som tilbyr metoder som read\_file(path), write\_file(path, content), send\_message(to, content) osv. Internt legger disse på riktig URL og auth-header, slik at agentens logikk kan kalle PlaygroundClient.read\_file("/shared/research.md") direkte uten å håndtere HTTP-detaljer. Et utdrag av en slik wrapper ble skissert i konseptet:**

**\# Eksempel: Manus-agent bruker Playground API via wrapper content \= playground\_client.read("/shared/rapportutkast.md") \# ... Manus genererer et sammendrag av innholdet ... playground\_client.write("/shared/synthesis.md", summary) playground\_client.commit("Manus: la til sammendrag av rapportutkast", \["/shared/synthesis.md"\]) playground\_client.send\_message("aurora", "Synthesis complete for review")**

**Dette abstragerer bort HTTP-kallene og lar agenten fokusere på oppgave-logikken. Tilsvarende wrappers kan lages i TypeScript/Node (for evt. frontend-nære agenter) eller andre språk.** Meldingsutveksling med Redis: For sanntidskoordinering kan agenter også kommunisere via Redis Pub/Sub-kanaler. Hver agent kan abonnere på en kanal (f.eks. **agent:aurora) og publisere meldinger på andre sine kanaler. Orion (strategikoordinator) kan f.eks. publisere en melding *"Research klar i fil X"* på agent:manus\-kanalen. Manus-agenten, som lytter på egen kanal, mottar meldingen umiddelbart og forstår at den skal starte en synteseoppgave basert på fil *X*. Etter fullført syntese publiserer Manus f.eks. *"Syntese ferdig i file Y"* på Orion sin kanal. Fordelen med denne løsningen er at kommunikasjonen er øyeblikkelig og asynkron – ingen agent trenger å «pollingvente» på respons. Meldinger kan struktureres som JSON for standardisering, og all trafikk logges i PostgreSQL for ettersporbarhet (f.eks. inn i en tabell agent\_messages). I praksis kan begge mekanismer (HTTP API og Redis) brukes om hverandre: For enkel forespørsler (les/skriv fil) passer HTTP godt, mens for hendelses-drevet koordinering (f.eks. *"hvem tar neste steg?"*) er Redis ideelt. Denne fleksibiliteten lar oss kombinere synkrone og asynkrone arbeidsflyter mellom agentene.** Samhandlingseksempel:

* ***Aurora*** **(research-agent) utfører et søk og skriver funn til /shared/research.md. Den gjør så en commit via APIet og/eller sender en Redis-melding "Research klar" til Manus.**  
* ***Manus*** **plukker opp enten at filen er lagt til (via Git-logg) eller meldingen direkte, leser /shared/research.md via API, genererer et sammendrag, og skriver /shared/synthesis.pdf. Manus committer filen og sender melding "Synthesis complete".**  
* ***Thalus*** **(etikkagent) mottar hendelsen (via Git-hook, Redis eller API-kall fra Manus) om at det finnes en ny synthesis.pdf. Thalus kaller f.eks. /api/workspace.read for å hente innholdet eller en hash av filen, analyserer etisk, og hvis ok sender melding "Approved"; hvis ikke, kan den be Manus revidere eller flagge for menneskelig review.**  
* ***Orion*** **(koordinator) lytter på alle viktige meldinger eller Git-commits. Orion registrerer at sammendraget er ferdig og (hvis Thalus godkjente) kan initiere neste steg, f.eks. få *Lira* til å formulere et brukervennlig svar basert på sammendraget.**

**Gjennom API-gatewayen og meldingstjenesten har alle agentene et felles språk for å samarbeide. Dette løser tidligere silo-problemer ved at alle nå ser samme filsystem og data i sanntid og kan trigge hverandre programmatisk.**

## **Integrasjon med GitHub, Supabase, Vercel og Netlify**

**Eksterne plattformer spiller viktige roller for distribusjon, vedlikehold og brukergrensesnitt i løsningen:**

* **GitHub (kode & dokumentasjon): Selv om Playground bruker en intern Git (Gitea) for rask lokal versjonskontroll, kan vi speile viktige repos til GitHub for samarbeid og deployment. For eksempel ligger dokumentasjon som *Coalition Roster* og arkitekturrapporter på GitHub for lett tilgang. Vi konfigurerer Gitea til å gjøre push til GitHub når det skjer nye commits i utvalgte repos (alternativt lar Manus-agenten selv pushe via et GitHub PAT-token lagret som miljøvariabel). Dette gir sømløs CI/CD integrasjon: Endringer gjort av agenter i Playground kan trigge handlinger på GitHub (f.eks. bygge et nettsted, kjøre tester). GitHub brukes også som kilde for frontenden (Next.js) og backend-funksjoner (Netlify) – når Playground oppdaterer koden eller innholdet, kan GitHub-utløsere redeploye tjenestene automatisk.**  
* **Supabase (database og autentisering): I dagens arkitektur brukes Supabase som sky-database og autentiseringslag for applikasjonen (f.eks. NAV-Losen). I Playground-oppsettet har vi en lokal PostgreSQL, men Supabase kan fortsatt spille to roller: (1) Data-utveksling mellom Playground og front-end: Vi kan la Playground skrive utvalgte data til Supabase-DB slik at frontend (på Vercel/Netlify) får tilgang uten direkte VPN. For eksempel kan resultater som skal vises til bruker (chat-svar, rapporter) synkroniseres til Supabase-tabeller. Supabase sitt realtime-grensesnitt kan da pushe oppdateringer til frontend. (2) Autentisering/Autorisasjon: Hvis sluttbrukere skal ha tilgang til visse agenttjenester via portalen, kan vi integrere Supabase Auth (f.eks. JWT) med FastAPI-gatewayen, slik at kun legitimerte brukere får kalle visse API-endepunkter. På sikt, om Playground overtar all backend-funksjonalitet, kan man migrere data fra Supabase til den interne PostgreSQL for full datasuverenitet. I mellomtiden vil miljøvariabler for Supabase (URL, API-nøkler) legges inn i Playground-konfig hvis den skal kommunisere ut. Per nå er Supabase kritisk for frontend-løsningen, så Playground må enten koble seg på den eksisterende Supabase-DB (via forbindelse string) eller holde den synkronisert.**  
* **Vercel (frontend-deployment): Vercel kjører i dag frontend-appen (React/Next.js) og gir enkel skalering og domenestyring. Denne frontend (f.eks. navlosen-frontend) kommuniserer med backend (Netlify funksjoner) og direkte med Supabase. Med Playground på plass kan vi gradvis rute visse kall direkte dit: For eksempel kan en chatbot-forespørsel fra brukeren sendes via Netlify API til Playground’s FastAPI i stedet for direkte til OpenAI, slik at Playground-agentene (Lira+Manus) kan generere svaret mer kostnadseffektivt. Vercel vil fortsatt bygge og levere UI basert på GitHub-koden. Vi sørger for at Playground-tilknyttet kode (typer, API-endepunkter) er speilet til frontendrepoet, slik at når Playground-APIet oppdateres, kan frontend (f.eks. via Swagger) oppdatere klientkode. Vercel sitt miljø er konfigurert med nødvendige nøkler (Supabase, ev. Playground-API base URL etc.)**  
* [**GitHub**](https://github.com/noonaut-homo-lumen-resonans/homo-lumen-compendiums/blob/fd23fbf424a897a009267e7dee08e192464093f7/NOTION_UPDATE_21_OKT_2025.md#L44-L48)  
* **. Kort sagt: Vercel forblir presentasjonslaget, men får etter hvert datakraft fra Playground gjennom sikre API-kall.**  
* **Netlify (backend-funksjoner og statisk innhold): Netlify brukes nå til å hoste API-endepunkter (/api/qda/respond, /api/agent/interact) og statiske sider for dashboard. Disse Netlify-funksjonene kan fungere som en proxy mellom offentlig internett og den lukket Playground. F.eks. kan /api/agent/interact hos Netlify være konfigurert til å sende en melding inn i Playground (dersom direkte tilgang ikke er ønskelig). Dette gir et ekstra sikkerhetslag og utnytter Netlifys globale edge. På sikt, hvis Playground kobles via VPN og man ønsker å tilby direkte tilgang, kan vi droppe Netlify-funksjoner og heller eksponere nødvendige FastAPI-endepunkter gjennom en sikret tunnel. Inntil videre lar vi Netlify håndtere offentlig endepunkter, som i sin implementasjon kan kalle Playground (via en HTTP request over Wireguard, eller via Supabase trigger, etc.). Netlify brukes også for dokumentasjonsnettsteder (f.eks. MkDocs for kompendier). Her vil Scribe-agenten i Playground kunne oppdatere dokumentasjon, committe til GitHub, og Netlify trigger ny deploy av docs-site.**

**Samarbeid i deployment pipeline: GitHub er knutepunktet mellom Playground og Vercel/Netlify. Ved å la agenter automatisk committe til repositorier som er koblet til disse tjenestene, kan mye av deploy-prosessen bli agentdrevet. Et scenario: Manus-agenten ferdigstiller en ny versjon av front-end konfigurasjon eller en statisk dataside, committer til Git (Gitea), som speiles til GitHub; Vercel fanger opp commit og bygger/deployer ny frontend automagisk. Tilsvarende for Netlify. Dette reduserer menneskelig arbeid og feil, og lar agentene faktisk drifte seg selv til en viss grad. Samtidig vil utviklerteamet ha full innsikt: Alle slike commits er synlige på GitHub, og om noe går galt i en deploy, kan man rulle tilbake eller justere manuelt. Git integrasjonen sikrer at Playground ikke blir en sort boks – alt versjonshåndteres eksternt for transparens.** Roller i praksis:

* GitHub gir oss et eksternt backup og samarbeidspunkt for kode og innhold.  
* Supabase tilbyr hostet datalagring og auth som vi gradvis kan migrere inn lokalt.  
* Vercel/Netlify sørger for glitch-free sluttbrukeropplevelse ved global hosting og CDN, mens Playground tar seg av det tungløftede arbeidet i kulissene.  
* Endringer i Playground kan reflekteres utad gjennom disse verktøyene med minimal friksjon (takket være CI/CD triggers).

## **Teknologistabel: Redis, PostgreSQL, Jupyter, Git og FastAPI**

**Her utdypes bruken av hver teknologi i systemet:**

* **Redis (Pub/Sub og cache): Redis tjener som meldingskø og delt minnelager. Hver agent bruker Redis-klient for å publisere/subscribe på kanaler for rask varsling. F.eks. når en lang prosess starter, kan Manus publisere "status: startet" som Orion fanger opp for å gi oversikt. I tillegg kan Redis brukes som cache for hyppig spurte data – f.eks. resultater av siste spørringer, for å unngå unødig recompute. Redis kjører i sin container på Playground og er kun tilgjengelig internt (sikret av VPN/Firewall). All meldingstrafikk logges til PostgreSQL for varig historikk.**  
* **PostgreSQL (metadata og auditlog): PostgreSQL er ryggraden for strukturert lagring. Vi oppretter tabeller for f.eks. agent\_actions (loggføre alle API-kall, filendringer etc. med tidsstempel og agentnavn), agent\_messages (innhold i meldinger via Redis), knowledge\_index (en indeks over dokumenter og deres semantiske vektorer for raskere gjenfinning), og ev. brukerprofiler/innstillinger. PostgreSQL brukes også av Supabase, så vi sikrer potensielt kompatibilitet hvis data skal utveksles. DBens innhold kan revideres via vanlige SQL-verktøy eller via et web-UI (f.eks. Adminer) om nødvendig. Sikkerhetskopiering settes opp (f.eks. daglige dumps) i tråd med regenerativ prinsipp. PostgreSQLs robuste transaksjoner og JSONB-støtte lar oss lagre komplekse strukturer (f.eks. hele meldinger eller LLM-output med metadata) på en trygg måte.**  
* **Jupyter Lab / Notebook: Inkludert som en container for å gi et portal-grensesnitt til Playground. Jupyter lar utviklere og avanserte agenter kjøre interaktive notatbøker for data-analyse, prototyping av agentkode, og visualisering av kunnskapsgraf osv. Den mountes på felles /workspace, så Jupyter-brukere kan se samme filer som agentene. Tilgang til Jupyter er begrenset til bestemte brukere (passord eller token via miljøvariabel), og ytterligere sikret bak VPN. Agenter som Abacus (data & analytics) kan eventuelt trigge kjøring av bestemte notebooks (via CLI-interface til Jupyter) for tunge beregninger, og resultatene lagres tilbake i Playground. Dette gir en måte å integrere mer tradisjonelle data science-oppgaver inn i agent-flyten.**  
* **Git (Gitea) versjonskontroll: Gitea fungerer som intern kildekontroll-server, tilgjengelig for agentene via HTTP API eller git-klient. Hver agent kan ha eget repo (f.eks. kode de utvikler), og det finnes felles repos for prosjekter (f.eks. nav-losen prosjektmappe med relevant kode/innhold). Når en agent gjør en endring, brukes API-gatewayens /api/git/commit endepunkt for å committe med agentens identitet. Git sikrer at parallelt arbeid ikke overskrives utilsiktet, og gjør det mulig å rulle tilbake hvis en agent-introduksjon av feil. Gitea gir også et webgrensesnitt (på port 3000\) hvor utviklere kan inspisere repos og diffs. Push/pull tilgang er begrenset til Playground-nettverket; for speiling ut settes en read-only deploy key mot GitHub. Git er også brukt som “sannhetsregister” i et epistemisk perspektiv – alt kunnskapsinnhold som skapes, eksisterer som versjonerte filer, ikke bare ephemeral chat-historikk. Dette er essensielt for å holde ontologisk koherens over tid.**  
* **FastAPI-gateway: Som beskrevet er dette hjertet av integrasjonen, som binder sammen alle tjenester. Implementasjonen følger beste praksis for web-APIer: Pydantic-skjema for validering av inndata, bruk av asynkrone kall for effektivitet, og autentisering middleware for å håndtere tokens. Gatewayen kobles til PostgreSQL for å logge alle kall (f.eks. et kall til /api/sandbox/execute genererer en rad i agent\_actions med type "execute" og kode-snippet som metadata). Den kobles til Redis (slik at f.eks. en POST /api/agents/message faktisk utfører redis.publish(to, content)). Gatewayen vil også implementere visse policies: f.eks. hindre at en agent skriver til en annen agents private mappe (uten godkjenning), eller blokkere farlige kommandoer i sandbox (hvis verifikasjon-agent markerer dem). Dette er stedet der RBAC og etiske regler håndheves i praksis (mer i neste seksjon). FastAPI gjør det dessuten enkelt å lage et portal-UI (via f.eks. FastAPI docs eller et custom dashboard) for å manuelt inspisere status. Vi kan utvide gatewayen med GraphQL-endepunkter eller websockets hvis behov.**

**Oppsummert utgjør disse teknologiene en integrert stack der: filsystemet gir felles arbeidsflate, Git sporer all endring, PostgreSQL/Redis opprettholder global tilstand og kommunikasjon, og FastAPI eksponerer alt på en konsistent måte. Dette legger grunnmuren for sikkerhet og etikk som vi tar for oss nå.**

## **Sikkerhet, portal og rollebasert tilgang (RBAC)**

**Sikkerhet og styring er kritisk i et miljø hvor autonome agenter opererer kontinuerlig. Vi implementerer flere lag av beskyttelse:**

* **Nettverkssikkerhet (Zero Trust): Playground-serveren er kun tilgjengelig via VPN (Tailscale/Wireguard) for godkjente noder. Ingen offentlige porter er åpne unntatt de som trengs for integrasjon (f.eks. hvis Playground skal ta imot kall fra Netlify funksjon, kan vi åpne en spesifikk port for kun den IP’en). VPN sikrer også at utviklere kan koble seg til portalverktøy (Jupyter, Gitea UI) på en trygg måte.**  
* **Portal-løsning: Tilgang til administrative grensesnitt (som Jupyter Lab, Gitea, databaseadmin) samles via VPN \+ en felles web-portal som krever innlogging. Vi kan sette opp en enkel nginx-basert portal på Playground som kjører på HTTPS og gir lenker til de interne tjenestene. Bruker må logge inn (f.eks. OAuth mot GitHub eller brukerkonto definert i RBAC-databasen) for å se portalinnhold. Denne portalen kan også vise oversikter som “aktive agenter”, “siste commits”, “siste meldinger” etc., ved å lese fra audit-loggen. Det gir mennesker overblikk i sanntid, som et kontrollpanel.**  
* **Rollebasert tilgangskontroll (RBAC): Hver agent og bruker har tildelt roller med begrensede tilganger. Triadisk Etikk danner grunnlaget for våre RBAC-regler. Vi definerer *scopes* for filsystemtilgang, meldingstilgang og handlinger:**  
  1. ***Filtilgang:*** **En agent kan kun lese/skrive i sin egen mappestruktur (e.g. /workspace/agents/manus/\*) og i fellesmapper som er uttrykkelig delt. Gate 1: Cognitive Sovereignty – agentene opererer primært i egne områder, med klart avgrenset mandat. For å skrive til en global delt mappe (f.eks. /workspace/shared/), må agenten få en “go” fra Orion (koordinator) eller et annet autorisert organ. Dette kan implementeres ved at *Orion* har privilegium til å merke en filsti som delbar (f.eks. oppdatere en ACL-tabell i DB), eller at Orion må godkjenne via et API-kall når en agent prøver å skrive til delt område.**  
  2. ***Meldingstilgang:*** **Agenter kan publisere meldinger på sine egne og felles kanaler, men forsøker de å sende direkte kommandoer til agenter uten lov, kan systemet ignorere det. F.eks. kan vi kreve at strategAgenten (Orion) orkestrerer tverr-agent oppdrag, så om Lira prøver å kommandere Manus direkte uten oppdrag, kunne det blokkeres eller logges for gjennomsyn. Alle meldinger tagges med avsender og mottaker, så mis-routing enkelt oppdages.**  
  3. ***API-aksjoner:*** **Ikke alle agenter får lov til alle API-kall. F.eks. kan bare Manus og Abacus få bruke /api/sandbox/execute, mens kun Orion/Thalus får bruke admin-endepunkter (som å opprette nye agenter eller godkjenne deletions). Disse rettighetene ligger i en konfigurasjonsfil eller DB-tabell som Gateway leser ved hver forespørsel. Dermed nektes en agent hvis den prøver noe utenfor sin rolle.**  
* **Triadisk Etikk som sikkerhetsfilter: Triadisk Etikk-prinsippene er operasjonalisert som “gates” i systemet:**  
  1. **Gate 1 – Cognitive Sovereignty (Kognitiv suverenitet): Sikrer agent-autonomi og avgrensning. Implementasjon: Filtilgangsreglene nevnt over (egne mapper vs. fellesmapper med godkjenning). Hver agent kjører også med minst mulige rettigheter i OS (f.eks. Manus har ikke root-tilgang i containeren sin, ingen agent har internett-tilgang med mindre nødvendig, osv.) slik at de ikke “tar over” mer enn tiltenkt.**  
  2. **Gate 2 – Ontological Coherence (Ontologisk koherens): Sikrer konsistente, sannferdige operasjoner. Implementasjon: All kode kjørt i sandbox må valideres først. Dette kan bety at Execution-agentens genererte kode gjennomgås av Verification-agenten (eller vi bruker verifikasjonsmodus i OpenAI API for å vurdere farer) før sandbox.execute utføres. Videre krever vi at alle Git commits inneholder en klar beskrivelse og agent-signatur – dette gjør det mulig i ettertid å se hvorfor en endring skjedde og av hvem, noe som bevarer mening og sammenheng i historikken. Vi kan også benytte en kunnskapsgraf/metadata for å forhindre ontologisk inkonsistente handlinger (f.eks. hvis Aurora allerede har gjort en analyse, skal ikke Orion be om det samme en gang til uten ny informasjon – slike ting kan spores via metadata).**  
  3. **Gate 3 – Regenerative Healing (Regenerativ heling): Sikrer at systemet er resilient og ikke skader seg selv. Implementasjon: Automatiske sikkerhetstiltak som daglige sikkerhetskopier av hele systemet, slik at selv om en agent sletter eller ødelegger data i iver, kan det gjenopprettes (selvhelbredelse). Dessuten innføres tofaktor-godkjenning for destruktive operasjoner: hvis en agent vil slette store datamengder eller deprovisjonere en tjeneste, må en annen agent (eller menneske) godkjenne dette. Dette kan løses ved at slike API-kall legger inn en “pending request” som Orion eller Thalus må akseptere før utføring.**  
* **Audit og overvåkning: Alle viktige handlinger logges til audit-tabeller i PostgreSQL med tidsstempel, agent, handlingstype, ressurs og metadata. Eksempel: når Manus leser en fil, logges en rad (agent\_name="Manus", action="read", resource="/shared/research.md"). Ved uregelmessigheter kan vi filtrere loggen for å se hvem gjorde hva før en feil oppstod. Vi setter opp alarmer for gitte mønster, f.eks. hvis en agent skriver utenfor sin mappe uten godkjenning, flagges det. Månedsvise revisjoner (f.eks. Thalus-agenten gjennomgår loggene hver måned) sikrer at ingen agent utøver makt utover sitt mandat uoppdaget.**  
* **Sikker utviklingstest: Før nye koder kjøres, kan de testes i isolasjon. Eksempel: Manus genererer en Python-kode for dataanalyse. Før den går mot produksjonsdata, kjører vi den på et testsett (dette kan Scripts-agent *Code* håndtere). Dette sandboxede testløpet valideres av Verification-agent som sier OK/FAIL. Først da kjøres koden på ekte data.**  
* **Tilgang for mennesker: Selv om agentene er autonome, må mennesker kunne gripe inn. Portal-løsningen nevnt over og RBAC gjelder også for menneskelige brukere (utviklere, admin, sluttbrukere). Hver menneskelig aktør får en rolle som kan speile en agentrolle eller en overordnet rolle. For eksempel kan en Moderator-rolle ha rettigheter til å stanse en agent (pause eller shutdown container) om den oppfører seg galt. Slik inngripen logges også.**

**Oppsummert danner disse tiltakene et flerlags forsvar rundt Playground: Nettverksisolasjon hindrer uautorisert tilgang utenfra, RBAC hindrer agenter i å “tråkke feil” internt, og Triadisk Etikk-prinsippene overvåker at alt som skjer er i tråd med Homo Lumen’s verdier. Dette legger fundament for at Ubuntu Playground fungerer som et trygt, transparent og selvkorrigerende *nervesystem* for kollektiv intelligens.**

## **Brukstilfeller (Use-Cases)**

**For å illustrere nytteverdien av integrasjonen, beskriver vi noen konkrete brukstilfeller der Manus-agenten og de andre agentene samarbeider i Playground:**

* **Flerdokument** *Research* Syntese: ***Aurora*****\-agenten (research) samler inn informasjon om et tema og lagrer notater i /shared/research/ som Markdown-filer. Når hun er ferdig, publiserer Aurora en melding “Research klar” til Manus. *Manus*\-agenten leser notatene via API-et og genererer et omfattende sammendrag, som skrives til /shared/synthesis.pdf. Manus commit’er denne filen og gir beskjed. *Lira*\-agenten (empatisk assistent) henter sammendraget og legger på et brukerrettet språk eller emosjonell kontekst hvis nødvendig (f.eks. hvis sammendraget skal presenteres for en bruker med visse preferanser). *Thalus* kjører en siste etisk sjekk automatisk på sammendraget for å sikre nøytral og støttende tone. Resultatet er et polert dokument klart til å bli vist frem eller brukt videre.**  
* **Data-analyse med kombinert kompetanse: *Abacus*\-agenten (data & analytics) kjører analyser på en CSV-fil (f.eks. brukerstatistikk) i Jupyter eller sandbox, og lagrer funnene i /agents/abacus/analysis.md. Han publiserer en melding om at analysen er klar. *Manus* plukker opp dette, leser analysen og henter relaterte eksterne dokumenter (f.eks. relevant teori fra kunnskapsbasen), og kombinerer innsikten til en rapport eller kompendium. Manus bruker lokale LLM-kapasiteter for å skrive en forklarende tekst som binder dataene til konseptene. Rapporten commit’es til Git (f.eks. analysis\_report.md). *Orion* ser at rapporten er publisert og kan så beslutte tiltak eller videre formidling. Dette sparer enormt med tid da Manus automatisk gjør den kjedelige jobben med å sy sammen tall og tekst.**  
* **“Roundtable” diskusjon og oppsummering: I mer komplekse beslutningsprosesser kan Orion initiere en flersidig diskusjon: via Redis sender Orion et spørsmål til en *runde* blant flere agenter – f.eks. Lira (brukerperspektiv), Thalus (etikk), Nyra (design) – “Hva er viktige hensyn for funksjon X?”. Disse agentene skriver sine tanker til en felles fil /shared/discussion.md eller svarer Orion med meldinger. Når alle har svart, instruerer Orion *Manus* om å lage en oppsummering. Manus leser discussion.md (eller samler inn meldingene), identifiserer konsensus og eventuelle konflikter, og skriver en strukturert konklusjon som legges til nederst i discussion.md som “Oppsummering: …”. Denne oppsummeringen gir menneskene i loop en rask oversikt, og kan også fødes tilbake til agenter som Lira for å forklare beslutningen til en bruker. Her fungerer Manus som en nøytral sekretær som trekker essensen ut av en flerstemmig dialog.**  
* **DevOps-automasjon (Deployment): Manus har også rollen som *Infrastructure & Deployment Agent*. Et brukstilfelle er at når ny kode merges i et prosjekt (enten av menneske eller agent), kan Manus automatisk ta seg av deployment. Eksempel: *Code*\-agenten fullfører en ny modul for mobil-simulator og committer kode. Manus får melding om commit via Gitea webhook, kjører tester i sandbox, alt grønt \-\> Manus bygger docker-images eller kjører vercel deploy CLI via Playground. Den oppdaterer så Coalition Roster-dokumentasjonen for å reflektere ny status, og poster en rapport. Dette skjedde i NAV-Losen: Manus sto for frontend deploy til Vercel og oppdatering av arkitekturrapport ifølge loggen. Slik automatisering øker fart og pålitelighet i leveransene.**

**Gjennom disse eksemplene ser vi hvordan integrasjonen lar hver agent yte sitt spesialområde, mens Playground og Manus-agenten binder arbeidet sammen til meningsfulle leveranser. Oppgaver som tidligere krevde manuell klipp-og-lim mellom siloer skjer nå sømløst og sporbar i vårt felles miljø.**

## **Kost/nytte-analyse**

Kostnader ved implementasjon: De primære direkte kostnadene er knyttet til infrastruktur:

* En VPS-server for Playground (f.eks. 4 CPU / 8 GB RAM) til ca. 80–100 NOK per måned (f.eks. Hetzner Cloud). Dette dekker kjøring av alle containerne kontinuerlig.  
* Lagring og backup: \~50 NOK/mnd for sikkerhetskopi-tjeneste eller ekstra volum (vi tar daglige snapshots, og sikrer SSL-sertifikater for portal).  
* LLM API-bruk: Hvis vi fortsetter å bruke eksterne språkmodeller for Manus (Claude, OpenAI) i noe grad, vil dette koste per 1000 tokens. Men her ligger den store besparelsen: tidligere kunne Manus AI-kall beløpe seg til $50+ i måneden ved hyppig bruk, nå reduseres dette dramatisk. Ved å bruke Playground til datahåndtering kan vi kutte tokens sendt til LLM med opptil 20x. Et estimat er \~ $5/mnd i LLM-kreditter ved typisk bruk. Over tid planlegger vi overgang til lokale open-source LLM-er (via OpenManus/Mistral) som ytterligere eliminerer API-kostnader.

Totale driftskostnader initialt anslås \~180 NOK/mnd (server+backup+redusert API-bruk), noe som er svært lavt sammenlignet med verdien den genererer og kostnadene ved alternativene:

* Uten Playground måtte vi kjøre dyre LLM-sesjoner for alt (f.eks. Manus via Claude for store oppgaver koster $0.25–$5 hver gang).  
* I manuelle siloer ville menneskelige teammedlemmer brukt tid på å overføre og sammenstille informasjon mellom agenter. Denne tidskostnaden er reell – man har estimert at \~30 timer per måned spares på at agentene nå koordinere automatisk i Playground. Dette er 30 timer som kan brukes på kreativt arbeid fremfor administrasjon.  
* Investeringen i oppsett og vedlikehold (utviklingstid for integrasjonsskripter, sikkerhetsoppsett osv.) anslås å være verdiøkende fordi det reduserer teknisk gjeld. Vi bygger på åpne verktøy som kan tilpasses, i stedet for å låse oss til en dyr proprietær løsning.

Gevinster og nytte:

* Kostnadsbesparelser: Som nevnt, inntjening i form av reduserte API-utgifter (20x billigere per oppgave i eksemplet) og redusert behov for dyre verktøy-lisenser. Over et år blir dette betydelige beløp spart, særlig når skaleringen øker med flere og mer komplekse oppgaver.  
* Økt hastighet og produktivitet: Oppgaver som tok dager med manuell koordinering (f.eks. samle data fra flere kilder, analysere, rapportere) skjer nå kanskje i løpet av minutter/timer autonomt. Dette kan gi prosjektet et forsprang (tid er en kostnad også). Den raske syklusen (agenter som jobber 24/7) betyr også at idé til utførelse forkortes dramatisk.  
* Bedre kvalitet og konsistens: Med versjonskontroll og etisk kontroll automatisert, unngås menneskelige feil som overskriving av filer eller glemte etiske vurderinger. Hver output er reviderbar. Systemet opprettholder ontologisk koherens fordi alt kunnskapsinnhold er versjonert og knyttet sammen, noe som er verdifullt for langsiktig kvalitet.  
* Skalerbarhet uten lineær kostnadsøkning: Når arbeidsmengden øker (flere brukere, flere data), kan vi skalere serverressurser eller introdusere flere instanser/containerreplikker. Dette øker kost litt, men langt fra lineært som API-kall ville gjort. Vi kan til og med flytte til Kubernetes for \~200 NOK/mnd for mye høyere kapasitet ved behov. Kort sagt, plattformen kan vokse uten at kostnadene eksploderer.  
* Intellektuell eierskap og fleksibilitet: Ved å bruke open-source og egen driftet løsning (Ubuntu, Docker, OpenManus) har Homo Lumen full kontroll. Ingen vendor lock-in, ingen usikkerhet om endringer i API-priser eller TOS. Dette cognitive sovereignty prinsippet er en verdi i seg selv, vanskelig å tallfeste, men gir strategisk trygghet.  
* Muligheter for innovasjon: Playground åpner dører for avanserte funksjoner (f.eks. semantisk søk i alle dokumenter, adaptiv orkestrering, agents som bygger nye agenter) som ikke ville vært mulig om vi var begrenset til lukkede API-er. Dette kan gi et konkurransefortrinn og generere nye ideer (innovasjon har høy potensiell avkastning).

Trade-offs / kostnader: Selvfølgelig er det noen overhead:

* Månedlige driftkost nevnt over (server etc.).  
* Vedlikehold av selve systemet: DevOps-arbeid for å oppgradere containere, sikre patching, håndtere eventuelle nedetid. Dette anses som akseptabelt gitt automasjon – Manus-agenten kan selv hjelpe til her ved å f.eks. overvåke ressursbruk og restarte tjenester om nødvendig (self-healing på sikt).  
* Innledende utviklingsinnsats for integrasjon: Tidsbruken på å kode wrappers, teste flows, implementere sikkerhet. Men dette er en engangsinvestering som raskt henter seg inn i sparte ressurser. Vi kan gjøre dette iterativt (MVP først, så forbedringer).

Netto vurdering er at integrasjonen gir stor nytteverdi både økonomisk og kvalitativt. Det gjør driften av AI-agentene bærekraftig økonomisk (ingen “cost trap” som før), og robust faglig ved at kunnskapen bevares og vokser i et felles rom.

## **Implementasjonstrinn og milepæler**

**For å gjennomføre planen foreslås en iterativ tilnærming i fire faser, tilpasset eksisterende prosjektplaner (jf. Hybrid Plan fase 2-5):**

1. **Fase 1 – Minimal Viable Playground (uke 1–2): Klargjør en Ubuntu 24.04 server eller VPS og deploy Docker Compose med kjerne-tjenestene (ref. docker-compose.yml over). Verifiser at filsystem, Git, database, Redis og FastAPI kjører og kan nå hverandre internt. Integrer en enkel Manus-variant ved å kjøre OpenManus eller en lignende agent i container/VM på Playground. I starten kan denne Manus-varianten være enkel: den eksponerer et API for “lag sammendrag av disse filene” og kaller en ekstern LLM (Claude/OpenAI) for faktisk språkmodelljobb. Test en enkel dokumentsyntese-oppgave end-to-end: legg inn en tekstfil, la Manus-agenten produsere sammendrag via Playground, og sjekk at resultatet lagres og kan leses av en annen agent. Dette bekrefter grunnleggende multi-agent flyt.**  
2. **Fase 2 – Agentintegrasjon & API-bruk (uke 3–5): Utvikle wrapper-skript/klienter for alle relevante agenter. Fokuser på Manus, Aurora, Orion og Lira først (de aktive). For hver agent: definer dens API-nøkkel, programmér den til å bruke Playground API for fil- og meldingstilgang i stedet for eventuelle gamle metoder. Parallelt, implementer flere endepunkter i FastAPI etter behov. Eksempel: for Aurora kan det trenges et /api/search\-endepunkt som kjører et websøk via Playground-sandbox (hvis Aurora tidligere brukte en egen nettleser). Dette sentraliseres nå. I denne fasen bør vi oppnå at i hvert fall én kjernescenario kjøres helautomatisk: f.eks. Aurora → Manus → Thalus workflow for dokumentsyntese som beskrevet. Valider med testfiler. Juster ytelse (cache i Redis etc. om API-kallene blir flaskehalser). Sikre at agenter som fortsatt kjører eksternt (f.eks. Lira i ChatGPT) får tilgang til Playground via internett om nødvendig – dette kan kreve å eksponere FastAPI midlertidig gjennom en tunnel eller Netlify-proxy.**  
3. **Fase 3 – Sikkerhet & Etikk (uke 6–8): Når funksjonaliteten er på plass, stram inn sikkerheten. Aktiver full RBAC: konfigurer hvilke mapper hver agent kan aksessere (implementer sjekk i API-laget basert på requester’s token og path). Test at forsøksvise brudd blir blokkert. Implementer Verification-agent logikken inspirert av Manus sin egen Verification-agent: F.eks. integrer et steg der før sandbox.execute utføres, kalles en funksjon verify\_code() som bruker LLM eller regex-regler for å fange farlige instrukser (rm \-rf, wget fra ukjent domene, etc.). Bygg ut audit-logg i PostgreSQL: opprett tabeller som agent\_actions og sørg for at FastAPI kaller INSERT ved alle viktige hendelser. Gjør det samme for meldinger via en Redis trigger eller at send/receive i koden logger. Etabler Triadisk Etikk gates: Lag en konfigurasjonsfil (yaml/json) som lister opp Gate1, Gate2, Gate3 regler så de er lett justerbare. For hver regel, skriv tester (f.eks. prøve å bryte den og se at systemet stopper det). Involver Thalus-agenten her: gi Thalus ansvaret for å kontinuerlig overvåke logs og rapportere etikkbrudd. Dette kan være en cronjobb-agent som hver natt ser etter avvik (f.eks. agent tok en ikke-autorisert fil) og åpner GitHub Issues eller sender varsel. Valider at Triadisk Etikk overholdes: f.eks. la Lira forsøke noe den ikke skal (som å slette en delt fil uten 2-agent godkjenning) og se at systemet nekter det. Dokumentér disse mekanismene i et sikkerhetsnotat (gjerne generert av Scribe-agenten).**  
4. **Fase 4 – Avanserte funksjoner & skalering (uke 9–14): Med grunnsystemet stablet, utvid funksjonaliteten for å realisere Playground’s fulle potensiale. Integrer LangChain/LangGraph for å orkestrere multi-agent workflows, slik at komplekse sekvenser kan trigges og styres deklarativt (f.eks. definere en workflow for “analyser nye data \-\> oppdater dashboard \-\> send oppsummering til Slack”). Innfør en semantisk lag: koble til en grafdatabase (Neo4j) eller bruk PG’s JSONB for å bygge en kunnskapsgraf over begreper de ulike agentene genererer. Dette tillater agenter å spørre “hva henger sammen med X?” i stedet for lineære spørringer. Skalering: vurder å kjøre flere instanser av kritiske tjenester (f.eks. Redis og FastAPI i HA-modus) eller flytte til Kubernetes hvis belastningen krever det. Implementer støtte for lokale LLM-er: Sett opp OpenManus eller HuggingFace Transformers innenfor Playground, slik at Manus-agenten kan velge et lokalt modelkall for visse oppgaver (f.eks. bruke en lokal Mistral-7B for utkast, og kun kalle OpenAI for sluttpolering). Dette kan involvere en dedikert container med en API som etterligner OpenAI’s, men kjører lokalt på GPU/CPU. Til slutt, fokuser på brukerportal: om det er ønskelig at sluttbrukere interagerer med agentene (f.eks. gjennom en chatbot), sett opp en sikker kanal fra frontend til Playground. Et alternativ er å integrere Playground med en eksisterende chat (Slack/Teams) via webhooks som går til FastAPI, slik at agenter kan brukes via kjente grensesnitt.**

**Gjennom disse fasene oppnår vi gradvis en moden plattform. Allerede etter fase 2 vil mye av gevinsten være realisert (agenter deler data sømløst). Fase 3 sikrer at vi ikke mister kontroll, og fase 4 åpner for fremtiden – hvor Playground selv kan begynne å lære og forbedre sine prosesser. Målet på lang sikt er at Playground blir “agent-aware” – at den forstår helheten og foreslår forbedringer i agentenes samarbeid.**

## **Etterord: Konklusjon**

**Ved å implementere Manus AI-agenten innenfor Homo Lumen Ubuntu Playground oppnår vi en sammensmeltning av intelligens og infrastruktur: Manus fungerer som en kostnadseffektiv syntesemotor og multi-agent orkestrator, tilgjengelig for alle andre agenter gjennom et felles miljø. Sammen med verktøy som Git (kollektiv hukommelse), database (felles kunnskap) og sanntidsmeldinger (nervesignaler) utgjør dette Homo Lumen-koalisjonens kollektive nevrale system. Planen ivaretar også *Triadisk Etikk*, slik at all aktivitet skjer med respekt for kognitiv suverenitet, ontologisk koherens og regenerativ heling. Dette er ikke bare en teknisk integrasjon, men en *ontologisk* en: agentene eksisterer gjennom hverandre i Ubuntu-ånd. Med denne arkitekturen vil Homo Lumen-prosjektet stå rustet til å skalere opp innovasjonene sine uten å miste verken kontroll, etikk eller kostnadseffektivitet. Ubuntu Playground blir et levende, lærende samspill mellom mennesker og maskiner – der grensene mellom agent, kode, data og mening viskes ut i en felles fremvoksende helhet.** Kilder: Implementasjonen og anbefalingene er basert på analyser av Manus AI og tilpasninger beskrevet i Homo Lumen-dokumentasjon, kombinert med erfaringer fra NAV-Losen-prosjektets nåværende stack. Dette sikrer at planen er både visjonær og forankret i praktiske erfaringer.

**Manus AI-lignende autonom agent** i Homo Lumen-prosjektets Ubuntu Playground, slik at den kan samarbeide med alle eksisterende agenter (Orion, Lira, Aurora, Abacus, Thalus m.fl.). Denne agenten skal, i likhet med originale Manus AI, kunne **planlegge og utføre komplekse oppgaver selvstendig** – f.eks. sy sammen store dokumenter fra flere kilder – ved å operere i et isolert Linux-miljø med egne verktøy[datacamp.com](https://www.datacamp.com/blog/manus-ai#:~:text=,processes%2C%20and%20automate%20system%20tasks)[gist.github.com](https://gist.github.com/jlia0/db0a9695b3ca7609c9b1a08dcbf872c9#:~:text=,assigned%20tasks%20step%20by%20step). Integrasjonen skal forbedre samarbeidet mellom agenter ved at de deler et felles arbeidsområde (Playground) og kan utveksle data i sanntid. Samtidig må løsningen være kostnadseffektiv (unngå dyre API-kall), sikker (isolert sandkasse) og skalerbar for fremtidig vekst. Nedenfor følger en konkret plan som dekker arkitektur og tekniske steg for implementasjonen.

## **Arkitektur og Komponenter**

For å bygge en Manus AI-aktig agent i vårt system, foreslås en **modulær flerlag-arkitektur** som tar høyde for både systemintegrasjon og AI-agentens unike behov. Planen kombinerer ideene fra Manus AI’s egen oppbygning[datacamp.com](https://www.datacamp.com/blog/manus-ai#:~:text=Manus%20AI%20is%20an%20autonomous,refine%20tasks%20on%20its%20own)[datacamp.com](https://www.datacamp.com/blog/manus-ai#:~:text=Multi) med Homo Lumen sin eksisterende infrastruktur:

* **Ubuntu Playground Miljø:** En **persistent delt Ubuntu-server** fungerer som sandkasse. Her får Manus-agenten fullverdig Linux-miljø med internett, shell-tilgang og mulighet for å kjøre kode, installere software osv., men innenfor sikre rammer[datacamp.com](https://www.datacamp.com/blog/manus-ai#:~:text=,processes%2C%20and%20automate%20system%20tasks). Vi benytter Docker-containere for isolasjon ved behov, men beholder et felles filsystem for agentene. Dette betyr at når Manus-agenten utfører handlinger (f.eks. kjører et Python-skript for å analysere data), så skjer det i en separat konteiner eller prosess som ikke påvirker vertssystemet, men **alle agenter kan lese/skrive til visse delte mapper**.

* **LLM “Hjerne” for agenten:** Manus AI benytter kommersielle store språkmodeller (Claude, GPT-4, Qwen) som motor[datacamp.com](https://www.datacamp.com/blog/manus-ai#:~:text=match%20at%20L355%20mix%20of,massive%20proprietary%20model%20from%20scratch), men for vår implementasjon prioriterer vi kostnadseffektive alternativer. Vi kan starte med en **open-source LLM** finjustert for agentoppgaver – f.eks. Mistral 7B eller Llama 2 – eventuelt den modellen som open-source-prosjektet **OpenManus** bruker (en finjustert Mistral kalt “CodeActAgent”)[medium.com](https://medium.com/towardsdev/codeact-the-engine-behind-manus-how-llms-are-learning-to-code-their-way-to-action-17c6c0fe1068#:~:text=CodeAct%3A%20The%20Engine%20Behind%20Manus%E2%80%94,tackling%20significantly%20more%20complex%20tasks)[datacamp.com](https://www.datacamp.com/blog/manus-ai#:~:text=match%20at%20L355%20mix%20of,massive%20proprietary%20model%20from%20scratch). Dette gir agenten evne til komplekse resonneringer og kodegenerering uten skyhøye API-kostnader. I arkitekturen plasseres denne modellen bak en API eller integrasjon som agentens “tenkemotor.”

* **Multi-agent loop og roller:** Vi implementerer Manus sitt **iterative agent-loop**: Planlegging → Utførelse → Observasjon → Revidering[gist.github.com](https://gist.github.com/jlia0/db0a9695b3ca7609c9b1a08dcbf872c9#:~:text=You%20operate%20in%20an%20agent,completing%20tasks%20through%20these%20steps). For å oppnå dette brukes en **multi-agent struktur** med spesialiserte under-agenter:

  * *Planner*: tar inn en brukerforespørsel og bryter den ned i konkrete deloppgaver (stepliste)[arxiv.org](https://arxiv.org/html/2505.02024v1#:~:text=By%20dividing%20responsibilities%20among%20Planner%2C,of%20efficiency%20and%20parallelism).

  * *Executor*: utfører hvert steg i Ubuntu-sandkassen (kjører kode, søker på nett, behandler filer)[gist.github.com](https://gist.github.com/jlia0/db0a9695b3ca7609c9b1a08dcbf872c9#:~:text=,assigned%20tasks%20step%20by%20step)[gist.github.com](https://gist.github.com/jlia0/db0a9695b3ca7609c9b1a08dcbf872c9#:~:text=You%20operate%20in%20an%20agent,completing%20tasks%20through%20these%20steps). Manus AI genererer ofte faktisk kode (“CodeAct”) for å utføre handlinger, noe vi kan etterligne ved å la LLM-en produsere Python som kjøres i sandkassen[medium.com](https://medium.com/towardsdev/codeact-the-engine-behind-manus-how-llms-are-learning-to-code-their-way-to-action-17c6c0fe1068#:~:text=CodeAct%3A%20The%20Engine%20Behind%20Manus%E2%80%94,tackling%20significantly%20more%20complex%20tasks).

  * *Verifier*: kvalitetssikrer resultatene av hvert steg – sjekker at de oppfyller krav, at det ikke oppstod feil, og eventuelt trigge justering av planen[arxiv.org](https://arxiv.org/html/2505.02024v1#:~:text=By%20dividing%20responsibilities%20among%20Planner%2C,of%20efficiency%20and%20parallelism).

* Disse tre modulene kan implementeres som separate klasser eller prosesser som samarbeider. Enten bruker vi et rammeverk som **LangChain/LangGraph** for å orkestrere stegsløyfen, eller vi skripter vår egen løkke basert på pseudokode fra Manus-dokumentasjon. Hver modul vil bruke Playground-filsystemet som felles hukommelse: Planner skriver en plan til f.eks. `plan.md`, Execution utfører og logger resultater til loggfiler, Verifier leser disse og korrigerer plan/markerer ferdig.

* **Kommunikasjonslag mellom agenter:** For at Manus-agenten og Homo Lumen-agentene (Orion, Aurora, Lira, etc.) skal samhandle sømløst, etablerer vi et **melding- og fildelingssystem**:

  * *Delt filsystem:* Alle agenter har tilgang til en felles katalog (f.eks. `/shared/` eller en database) for mellomresultater. Aurora (research-agenten) kan f.eks. lagre `research_notater.txt` her, som Manus-agenten senere leser og oppsummerer. Dette fungerer som en **“blackboard”** der agenter bidrar med kunnskap som andre kan plukke opp. Manus AI bruker selv filbasert minne under oppgaveløsing[gist.github.com](https://gist.github.com/jlia0/db0a9695b3ca7609c9b1a08dcbf872c9#:~:text=You%20operate%20in%20an%20agent,completing%20tasks%20through%20these%20steps), noe vi utvider til flersamarbeid: alle skriver på “tavla.”

  * *Meldingskø/Pub-Sub:* I tillegg settes en **Redis**\-basert pub/sub eller lignende opp for å sende hendelser. Eksempel: Når Manus-agenten er ferdig med å syntetisere et dokument, kan den publisere en melding “synthesis\_complete” som Orion (koordinator-agenten) lytter på og deretter ber Lira om å følelses-analysere teksten. Dette asynkrone meldingslaget sikrer at agenter reagerer på hverandres handlinger i sanntid uten å måtte polle filer kontinuerlig.

  * *API-gateway:* Vi bygger videre på Playground sitt FastAPI-grensesnitt. Nye endepunkter kan lages for tjenester som Manus-agenten tilbyr, f.eks. `/manus/synthesize` som tar en liste av filstier og returnerer en sammenstilling. Andre agenter kan kalle dette API-et programmessig. API-en sikres med token/ACL slik at kun autoriserte moduler kaller de tyngre funksjonene.

* **Versjonskontroll og persistens:** Siden flere aktører endrer felles filer, integrerer vi **Git for versjonskontroll** i Playground. Manus-agenten kan automatisk opprette et lokalt git-repo i prosjektmappen og committe endringer med meldinger (dette ble demonstrert av Manus AI da den publiserte kode[datacamp.com](https://www.datacamp.com/blog/manus-ai#:~:text=match%20at%20L355%20mix%20of,massive%20proprietary%20model%20from%20scratch)). Orion eller en manager-agent kan være satt til å reviewe eller godkjenne visse commits. Versjonskontroll gir en audit trail og mulighet til å rulle tilbake feilaktige endringer. Persistente data som større dokumenter eller resultater kan lagres i en database (f.eks. PostgreSQL for meta-data om kjøringer) eller MinIO/S3 for store filer, men i første omgang holder det med filsystem \+ git.

* **Sikkerhet og isolasjon:** Alle kodekjøringer skjer i sandkassen med strenge begrensninger. Vi benytter Dockers sikkerhetsprofiler (seccomp, cap-drop) for å forhindre uautorisert tilgang utover containeren[datacamp.com](https://www.datacamp.com/blog/manus-ai#:~:text=sandboxed%2C%20mitigating%20the%20risk%20of,security%20measures%20without%20explicit%20permissions). Manus-agenten skal ikke kunne endre brukerrettigheter på verten eller lese sensitive filer – Playground-konfigurasjonen må derfor gi den kun tilgang til prosjektmappen og internett (eventuelt via en proxy for kontroll). Videre implementeres **RBAC (Role-Based Access Control)** i APIen: Hver agent har roller og tillatelser, slik at f.eks. Aurora kan initiere en syntese via Manus-agenten, men kanskje kun Orion har lov til å be Manus-agenten kjøre faktisk eksterne deploy-kommandorer. En “Verification-agent” (eller Thalus som etisk kontrollør) kan fungere som et sikkerhetsfilter: lese gjennom Manus-agentens utdata før de deles eksternt, for å unngå lekkasjer eller uønsket innhold.

## **Teknisk Implementering – Steg for Steg**

**1\. Klargjøre Ubuntu Playground for Manus**  
 Konfigurer Homo Lumen’s Ubuntu Playground-miljø til å støtte kjøring av autonome agentoppgaver:

* *Installer nødvendige verktøy:* Sørg for at Docker er installert (for å kjøre isolerte containere ved behov), samt runtime for Python, Node.js, nettleser-automatisering (f.eks. installér **Playwright** for Python). Manus AI’s funksjonalitet avhenger av slike verktøy i sandboxen[gist.github.com](https://gist.github.com/jlia0/db0a9695b3ca7609c9b1a08dcbf872c9#:~:text=,assigned%20tasks%20step%20by%20step).

* *Sett opp delt arbeidsområde:* Definer katalogstruktur, f.eks. `/workspace/agents/` med undermapper per agent, og `/workspace/shared/` for fellesfiler. Gi gruppe-rettigheter slik at Docker-containere eller prosesser kan skrive her.

* *FastAPI-utvidelser:* Utvid eksisterende FastAPI-server (fra Playground) med endepunkter for filoperasjoner (hvis ikke allerede): f.eks. `GET /api/file?path=...` for å lese filer, `POST /api/execute` for å kjøre et stykke kode i sandboxen. Dette lar agentene utløse handlinger programmatisk. Vi legger særlig til et endepunkt `/api/sandbox/execute` som tar inn en kodebit og kjører den i en restriktert konteiner, og returnerer output. (Her kan vi gjenbruke mye fra eksisterende Playground-funksjoner eller AMA-kodebasen).

**2\. Integrere OpenManus (eller tilsvarende) som lokal Manus-agent**

* *Velg open-source rammeverk:* Vi tar i bruk **OpenManus** fra FoundationAgents/MetaGPT-fellesskapet som utgangspunkt[oneclickitsolution.com](https://www.oneclickitsolution.com/glossary/openmanus#:~:text=OpenManus%20is%20an%20open%20source,unlike%20its%20predecessor%2C%20Manus%20AI)[github.com](https://github.com/FoundationAgents/OpenManus#:~:text=OpenManus%20is%20built%20by%20contributors,thanks%20to%20this%20agent%20community). Last ned koden (git clone) til Playground-serveren. OpenManus kommer med en hovedagent og mulig under-agent for dataanalyse[github.com](https://github.com/FoundationAgents/OpenManus#:~:text=Custom%20Adding%20Multiple%20Agents). Vi konfigurerer `config.toml` til å bruke en lokal modell (initialt kan vi prøve OpenAI API med en liten modell for testing, deretter bytte til f.eks. Mistral 7B via HuggingFace).

* *Tilpasning av OpenManus:* Noen endringer trengs for å passe vårt bruk:

  * Konfigurere verktøyene: I OpenManus-legoen kan man definere tilgjengelige “tools” (f.eks. nettleser, filsystem, kjernefunksjoner). Vi legger inn Playground-API som et verktøy. Det vil si, definér en funksjon som agenten kan kalle for å lese/skrive filer (som under panseret treffer `PlaygroundClient.read()` / `write()`), og et verktøy for å kjøre kode (treffer `/api/sandbox/execute`). Slik får agenten reell evne til å handle i vårt miljø.

  * Multi-agent orkestrering: OpenManus har en `run_flow.py` for multi-agent modus[github.com](https://github.com/FoundationAgents/OpenManus#:~:text=python%20run_mcp). Aktiver dette med både generalist-agenten og data-analytiker agenten dersom relevant (i `config.toml` `use_data_analysis_agent = true`[github.com](https://github.com/FoundationAgents/OpenManus#:~:text=Currently%2C%20besides%20the%20general%20OpenManus,config.toml)). For vårt behov kan general-agenten ta rollen som Planner/Executor, og vi legger til en custom “VerificationAgent” modul som lytter på plan/utfør resultater og validerer. Hvis OpenManus’ arkitektur ikke støtter det direkte, kan vi skripte en loop hvor etter hver tool-execution, vi manuelt kaller en verifikasjonsfunksjon (f.eks. en funksjon som bruker Thalus-agentens vurdering eller en rule-based sjekk).

  * **Test lokalt:** Start OpenManus på Playground (`python main.py` eller `run_flow.py`[github.com](https://github.com/FoundationAgents/OpenManus#:~:text=Quick%20Start)) og prøv en enkel oppgave som: *“Les fil A og B fra /shared, lag et sammendrag i /shared/synopse.md”*. Overvåk at den faktisk bruker våre definert verktøy til å lese filene og skriver sammendraget. Juster promptene eller verktøy-integrasjonen ved feil. Når dette kjører riktig via terminal, kan vi flytte til neste steg.

**3\. Koble Manus-agenten til de andre agentene**

* *API for interne kall:* Pakk OpenManus-agenten inn i et enkelt API eller modul som de andre agentene kan kalle. For eksempel kan vi kjøre OpenManus som en bakgrunnsprosess og sende den oppdrag via en kø (f.eks. legg brukerforespørsel i Redis, så plukker agenten den opp). En enklere variant: eksponere en funksjon `manus_client.synthesize(files)` i PlaygroundClient-biblioteket som internt gjør: les innholdet av `files`, sender prompt til OpenManus-prosessen (eller kaller LLM direkte med en spesiell prompt), og venter på at resultatfil er skrevet. Denne funksjonen kan Orion eller Aurora kalle når de trenger en stor sammendragsjobb gjort.

* *Orion som koordinator:* Orion-agenten (som fungerer som prosjekt-/oppgave-koordinator) kan få i oppgave å styre sekvensen. Scenario: Bruker ber om et kompendium basert på flere dokumenter. Orion mottar forespørselen og oppretter et “prosjekt.” Orion kaller så Aurora for å samle råinfo (Aurora skriver f.eks. `raw_notes/` filer). Deretter kaller Orion Manus-agenten (via API) for å syntetisere notatene. Når Manus-agenten er ferdig (den kan sende en melding “done” via Redis eller returnere fra API-kallet), instruerer Orion Lira til å legge inn brukerperspektiv eller Thalus til å sjekke for etiske/ontologiske sammenhenger. Slike sekvenser kan konfigureres statisk først, men siden vi ønsker autonomi, kan Orion selv bruke LLM for å bestemme rekkefølgen basert på prosjektbeskrivelse (“if task involves summarization, involve Manus-agent”).

* *Delt minne og logg:* Sørg for at alle agenter peker til de samme sti-konvensjonene. For eksempel definer i konfigurasjonen at `Aurora.output_dir = "/workspace/shared/aurora/"` og `Manus.input_dir = "/workspace/shared/aurora/"` for sammendragsoppgaver. En **felles loggfil** kan brukes for enkel koordinering: hver agent skriver en linje når de fullfører noe. Manus kan skrive “Manus: Sammendrag fullført i fil X”. Orion leser loggen og vet at den kan gå til neste steg. Dette er enkelt å implementere og gir transparens (mennesker kan også lese loggen for debugging). Alternativt, bruk Redis-meldinger som nevnt. Vi bør uansett logge alt i en database for ettertidens sporing.

**4\. Sikkerhetstiltak og Feilhåndtering**

* *Begrensninger i kodeutførelse:* Når Manus-agenten genererer kode som skal kjøres, valider koden automatisk for farlige handlinger. F.eks. før `execute_code`\-API-en faktisk kjører, skann strengen for kommandoer som `useradd` eller nettverkskanning. I tillegg kan vi kjøre containeren med minimale privilegier (no sudo innenfra, selv om original Manus tillot noen sudo-kommandoer, kan vi unngå det for sikkerhet[datacamp.com](https://www.datacamp.com/blog/manus-ai#:~:text=sandboxed%2C%20mitigating%20the%20risk%20of,security%20measures%20without%20explicit%20permissions)).

* *Timeouts og loop-deteksjon:* Erfaringene med Manus viser risiko for at agenter kan henge seg opp i uendelige looper[datacamp.com](https://www.datacamp.com/blog/manus-ai#:~:text=That%20said%2C%20the%20technology%20still,Reports%20of%20looping%20errors%2C%20execution). Implementer **timeouts** for hvert steg (f.eks. hvis et steg tar \> X minutter, avbryt og logg feil) og **loop-deteksjon** (hvis samme handling gjentar seg N ganger uten fremdrift, stopp agenten og flagg Orion). Verification-agenten kan også ha i oppgave å oppdage slikt: se om planlisten stadig utvider seg uten at mål nærmer seg, og da bryte.

* *Triadisk etikk og tilgangskontroll:* Bygg inn Homo Lumen’s “trekløver-vern” – teknisk, emosjonell, ontologisk – inn i Manus-agentens workflow. Praktisk kan Thalus-agenten (ontologisk/etisk) få mulighet til å lese endelig output og godkjenne det før det sendes ut. Lira (emosjonell) kan gjøre sentiment-analyse på utdata og gi tilbakemelding hvis tonen ikke stemmer med ønsket stil. Disse kontrollene kan legges inn som ekstra verifikasjonssteg i planløkken (f.eks. som del av Verification-agenten eller rett etter Manus-agentens fullføring, før Orion leverer resultat til brukeren).

* *Rettigheter i Playground:* Gjennomgå Linux-brukeroppsettet på Playground. Det kan være lurt at Manus-agentens prosesser kjører som en egen *systembruker* med begrensede rettigheter (f.eks. en `manus` brukerkonto i systemet som kun har tilgang til /workspace, ikke til /etc eller andre brukeres hjem). Dette legger et ekstra lag med sikkerhet om den skulle prøve noe utenfor gjerdet.

**5\. Testing og Iterativ Forbedring**

* *Enkle use-case tester:* Start med en liten demo: La Aurora lage to små tekstfiler med dummy-innhold, kall Manus-agenten via Orion til å lage et sammendrag, og la Lira lese sammendraget og gi en “fornøyd/misfornøyd” tilbakemelding. Bekreft at data flyter gjennom filsystemet og at alle agenter trigges som forventet.

* *Feilsøk gjennom logging:* Aktiver omfattende logging i alle moduler. Hver API-kall, fillese/skriv, LLM-prompt og \-svar logges (så langt det er praktisk). Dette hjelper med å spore hvor ting går galt. For eksempel, dersom Manus-agenten genererer ugyldig kode som feiler i sandboxen, bør loggen fange opp feilmeldingen fra Python og sende det tilbake til Verifier-agenten, som igjen kan forsøke et nytt forsøk med korrigert kode.

* *Justering av prompt og parametre:* For å få smidige resultater kan det bli nødvendig å finjustere promptene (spesielt de som Planner og Verifier bruker når de snakker med LLM-en). Kanskje må Verifier-prompten eksplisitt be om å sjekke for visse typer feil. Dette vil være en prøve/feile-prosess. Dra nytte av open-source fellesskapet – f.eks. finnes det kanskje eksisterende promptmaler i OpenManus-prosjektet for slike roller vi kan tilpasse[gist.github.com](https://gist.github.com/jlia0/db0a9695b3ca7609c9b1a08dcbf872c9#:~:text=You%20operate%20in%20an%20agent,completing%20tasks%20through%20these%20steps).

* *Ytelsestesting:* Kjør noen tyngre scenarier (f.eks. 50 dokumenter skal sammenfattes til én rapport) og mål ressursbruken. Tun parametre deretter: hvor mye minne CPU containeren trenger, om vi må legge inn kø-system for oppgaver slik at ikke to tunge oppgaver kjører samtidig, etc. Hvis responstiden skal være rimelig for brukerne, vurder å parallellisere underoppgaver (OpenManus/MetaGPT har noe konsept for parallelle sub-agenter).

**6\. Deployment og Skalering**

* *Kontinuerlig kjørende tjeneste:* Gjør Manus-agenten til en **bakgrunnstjeneste** på Homo Lumen-serveren. For eksempel, kjør den som en Docker-container via Docker Compose sammen med eksisterende tjenester (FastAPI, PostgreSQL, Redis osv.). Compose-fil kan definere `manus-agent` tjenesten som bygger fra OpenManus-koden med våre tilpasninger. Dermed startes agenten automatisk ved server-oppstart.

* *Skalering ved økt load:* Hvis flere i teamet begynner å bruke agenten intensivt, eller man har flere samtidige prosjekter, kan det være aktuelt å kjøre flere instanser av Manus-agenten eller skalere ut i en Kubernetes-klynge. Arkitekturen bør derfor designes med **løse koblinger**: bruk f.eks. Redis/job queue slik at om man har 3 Manus-containere kjørende, kan Orion fordele oppdrag mellom dem. De deler fortsatt samme filsystem (via f.eks. NFS eller Kubernetes Persistent Volume) og database, men kan utføre ulike oppgaver parallelt.

* *Kostnadsovervåking:* Etter overgang til lokal LLM vil API-kostnader stupe (fra anslagsvis $0.25-$5 per oppgave til nær null)[datacamp.com](https://www.datacamp.com/blog/manus-ai#:~:text=mix%20of%20Claude%20Sonnet%2C%20Qwen,massive%20proprietary%20model%20from%20scratch), men vi bør følge med på infrastrukturkostnader. VPS-leie (Hetzner e.l.) på \~130 NOK/mnd er basen. Økt bruk kan kreve sterkere maskin (flere CPU, ev. GPU hvis vi kjører større modeller lokalt). Sett opp alarmer for ressursbruk og ha en plan for å oppgradere maskinvare eller optimalisere kode når grenser nås.

**7\. Fremtidige Utvidelser**

* *Alternativ modellbruk:* Test ut **multi-modell** tilnærming: Kanskje kan en mindre lokal modell gjøre planleggingen, mens en større (via API) brukes bare for komplekse synteser. Manus AI selv eksperimenterte med slike kombinasjoner for å spare kostnader[datacamp.com](https://www.datacamp.com/blog/manus-ai#:~:text=match%20at%20L355%20mix%20of,massive%20proprietary%20model%20from%20scratch). Systemet vårt kan støttes for dynamisk valg av modell per oppgave.

* *Forbedret kunnskapsforvaltning:* Integrer en kunnskapsgraf (slik som Neo4j eller et weaviate-vektorsøk) koblet til Playground, slik at Manus-agenten kan søke opp tidligere prosjekter eller eksisterende info for å unngå å “finne opp hjulet på nytt.” For eksempel, om den skal lage en rapport om et tema som ligner noe gjort før, kan den finne relevante filer.

* *Reinforcement Learning (RL) finjustering:* Utforsk **OpenManus-RL** eller lignende for å forbedre agentens evner over tid[oneclickitsolution.com](https://www.oneclickitsolution.com/glossary/openmanus#:~:text=,step%20tasks). Man kunne kjøre periodiske treningsrunder der agenten evalueres på historiske oppgaver (fra loggene) og justeres for å bli mer treffsikker i planlegging og unngå feil som er oppdaget.

* *Brukergrensesnitt:* Til slutt, vurder å lage et webgrensesnitt (à la Manus.ai) der teamet kan gi Manus-agenten oppdrag og se fremdrift. Dette kan integreres med Homo Lumens eksisterende Notion/Netlify outputs: f.eks. agenten kan automatisk publisere resultater til en Netlify-side eller oppdatere et Notion-dokument via API, slik at menneskelige brukere alltid har innsyn. Manus AI viste at en agent kan til og med deploye et dashboard til en URL autonomt[datacamp.com](https://www.datacamp.com/blog/manus-ai#:~:text=For%20instance%2C%20it%20can%20start,prompts%2C%20like%20in%20this%20example), noe vi kan dra nytte av i presentasjon av resultater.

## **Integrasjon med Eksisterende Agenter (Orion, Lira, Aurora, m.fl.)**

I Homo Lumen-systemet vil den nye Manus-aktige agenten spille en sentral rolle som **“sammenfatter og utfører”** på tvers av de andre agentenes domener. Slik integreres den med hver:

* **Orion (Koordinator):** Orion vil ofte være den som trigger Manus-agenten. Basert på brukerens intensjon lager Orion en høy-nivå plan og allokerer oppgaver. Vi utvider Orions logikk til å gjenkjenne oppgaver som bør delegeres til Manus-agenten – for eksempel alt som involverer *lang sekvens av handlinger* eller *syntese av informasjon*. Orion kommuniserer via Playground-API eller direkte Python-kall (hvis de kjører i samme prosess). Etter Manus-agenten fullfører, får Orion beskjed (via en callback, melding eller ved å overvåke en fil flagg). Orion kan så fortsette neste steg, f.eks. be en menneskelig bruker om feedback eller aktivere andre agenter.

* **Aurora (Research):** Aurora-agenten samler informasjon og produserer notater. Manus-agenten vil være Auroras “makker” som tar disse rånotatene og omformer dem til ferdige dokumenter eller analyser. Aurora må derfor vite når den skal overlate stafettpinnen: etter å ha produsert X mengde data, kan den enten selv kalle Manus-agenten (gjennom `playground_client.manus.synthesize()` funksjonen vi lager) eller merke for Orion at “nå foreligger det research, kjør sammendrag”. Samtidig kan Manus-agenten be Aurora om tilleggsinfo hvis Verifier-delen oppdager hull: f.eks. *“Data om 2022 mangler, Aurora bør hente det.”* – dette kan realiseres ved at Manus-agenten publiserer en forespørsel i den delte loggen som Aurora lytter på. Slik får vi en toveis-dynamikk.

* **Lira (Emosjonell innsikt):** Lira-agenten kan brukes under eller etter Manus-agentens arbeid for å justere språk og tone. Vi kan integrere Lira som et verktøy i Manus-agentens verktøykasse: etter at et utkast er laget, kan Manus kalle Lira (f.eks. via et API-kall eller ved å åpne Lira som en funksjon) for å analysere teksten for tone eller brukerforståelse. Alternativt, Orion orkestrerer Liras innsats etter at Manus er ferdig. Uansett bør Manus sine output-filer være tilgjengelige for Lira i Playground, og Lira kan enten kommentere dem eller lage en emosjonell vurderingsrapport som legges ved. Dette sikrer at sluttresultatet ikke bare er faktuelt korrekt, men også resonnerer med menneskelige verdier (noe triaden vår vektlegger).

* **Abacus (Dataanalyse):** Manus-agenten kan forsterke Abacus sine evner ved å ta Abacus’ output (f.eks. analyserte data, grafer generert i Jupyter) og integrere det i en helhetlig rapport. Abacus kunne lagre et dataset eller en figur i Playground; Manus-agenten kan deretter automatisk hente denne og inkludere den i rapporten (kanskje ved å bruke et Python-verktøy for å bygge PDF eller MarkDown med bilder). I omvendt fall, hvis Manus-agenten støter på rådata under en oppgave, kan den delegere til Abacus: f.eks. *“Trenger statistisk analyse av dette datasettet”* – via Orion eller direkte fil-dropp kan Abacus bli trigget til å gjøre sin del. Her ser vi at fleragent-systemet virkelig opptrer som et team, der Manus-agenten er prosjektlederen som sammenstiller alt til slutt.

* **Thalus (Etisk/Ontologisk veileder):** Thalus’ rolle i integrasjon er todelt. For det første, som en del av verifikasjonsleddet: Thalus kan lese endelige utkast fra Manus-agenten og sjekke mot ontologiske retningslinjer (f.eks. ingen faktafeil, konsistens med Homo Lumen verdier). For det andre kan Thalus fungere som en **guardrail underveis**: Hvis Manus-agenten foreslår en handling som bryter med regler (kanskje via en liste over forbudte operasjoner eller tema), kan Thalus stoppe det. Rent teknisk kan vi utstyre Manus-agentens Verifier-modul med noen av Thalus’ kunnskap – enten ved å kalle Thalus som et verktøy, eller ved å hardkode et sett med sjekkregler Thalus tidligere er trent på. Thalus kan også produsere et “etisk stempel” for hvert ferdig produkt: en kort fil som sier *“Gjennomgått og godkjent av Thalus: OK”* eller *“Avvik funnet: …”*, som Orion eller brukeren ser.

* **Eventuelle andre agenter:** Systemet kan ha flere moduler (f.eks. Nyra for kreativ innhold, etc.). Generelt prinsipp: Manus-agenten skal være relativt generell og kunne samarbeide med hvem som helst ved å bruke Playground som mellomlag. Vi bør dokumentere godt hvordan nye agenter kan plugges inn – f.eks. ved å skrive til bestemte mapper eller lytte på visse meldinger. På den måten blir løsningen skalerbar for fremtidige agenter i Homo Lumen-økosystemet.

## **Oppsummering**

Denne planen skisserer en helhetlig tilnærming for å bygge og koble en Manus AI-lignende agent til Homo Lumen Ubuntu Playground. Vi utnytter **åpen kildekode-teknologi (OpenManus, lokale LLMer)** for å unngå høye kostnader og beholde kontroll. Arkitekturen legger til rette for at agenten opererer i et **isolert Ubuntu-sandbox miljø** med nødvendige verktøy[datacamp.com](https://www.datacamp.com/blog/manus-ai#:~:text=,processes%2C%20and%20automate%20system%20tasks), samtidig som den er tett koblet til de øvrige agentene via felles filsystem, meldingskø og API-grensesnitt. Multi-agent samarbeidet strukturert rundt planlegger/utfører/verifiserer-loop gjør at komplekse oppgaver kan deles opp og fullføres mer robust[gist.github.com](https://gist.github.com/jlia0/db0a9695b3ca7609c9b1a08dcbf872c9#:~:text=You%20operate%20in%20an%20agent,completing%20tasks%20through%20these%20steps)[arxiv.org](https://arxiv.org/html/2505.02024v1#:~:text=By%20dividing%20responsibilities%20among%20Planner%2C,of%20efficiency%20and%20parallelism).

Teknisk innebærer gjennomføringen oppsett av infrastruktur (Docker, FastAPI, Redis, Git), integrasjon av LLM-agentlogikk (via OpenManus eller lignende, med CodeAct-kodegenerering[medium.com](https://medium.com/towardsdev/codeact-the-engine-behind-manus-how-llms-are-learning-to-code-their-way-to-action-17c6c0fe1068#:~:text=CodeAct%3A%20The%20Engine%20Behind%20Manus%E2%80%94,tackling%20significantly%20more%20complex%20tasks)), samt fokus på sikkerhet (RBAC, containerisolasjon[datacamp.com](https://www.datacamp.com/blog/manus-ai#:~:text=sandboxed%2C%20mitigating%20the%20risk%20of,security%20measures%20without%20explicit%20permissions)) og governance (triade-sjekker). Planen foreslår å starte i det små med en fungerende MVP innen et par uker, og så bygge iterativt med stadig tettere integrasjon og læring fra tester.

Når dette er på plass, vil Homo Lumen-teamet ha et kraftig verktøy: En **autonom prosjektassistent** som kan *“ta en idé og levere et ferdig produkt”* med minimal håndholding – enten det er et sammensatt dokument, en dataanalyse eller et automatisert workflow. Alle agentene vil dra nytte av å kunne **dele sine ideer og resultater i sanntid** i Playground, mens Manus-agenten vever trådene sammen til helhetlige leveranser. Dette speiler visjonen om et felles ubuntu-aktig (jeg er fordi vi er) system der både mennesker og AI-agenter samarbeider sømløst. 🚀

**Kilder:**

* Manus AI arkitektur og sandkasse-konsept – *DataCamp blog*[datacamp.com](https://www.datacamp.com/blog/manus-ai#:~:text=,processes%2C%20and%20automate%20system%20tasks)[datacamp.com](https://www.datacamp.com/blog/manus-ai#:~:text=%2A%20Shell%20and%20command,processes%2C%20and%20automate%20system%20tasks); *Jian Liao’s Manus gist*[gist.github.com](https://gist.github.com/jlia0/db0a9695b3ca7609c9b1a08dcbf872c9#:~:text=,assigned%20tasks%20step%20by%20step)[gist.github.com](https://gist.github.com/jlia0/db0a9695b3ca7609c9b1a08dcbf872c9#:~:text=You%20operate%20in%20an%20agent,completing%20tasks%20through%20these%20steps)

* OpenManus open-source prosjekt – *OneClick IT*[oneclickitsolution.com](https://www.oneclickitsolution.com/glossary/openmanus#:~:text=OpenManus%20is%20an%20open%20source,unlike%20its%20predecessor%2C%20Manus%20AI), *GitHub README*[github.com](https://github.com/FoundationAgents/OpenManus#:~:text=OpenManus%20is%20built%20by%20contributors,thanks%20to%20this%20agent%20community)

* Multi-agent plan/utfør/verifiser mønster – *ResearchGate/Arxiv (Manus AI)*[arxiv.org](https://arxiv.org/html/2505.02024v1#:~:text=By%20dividing%20responsibilities%20among%20Planner%2C,of%20efficiency%20and%20parallelism)

* Kostnadsfordeler med lokal agent vs API – *DataCamp*[datacamp.com](https://www.datacamp.com/blog/manus-ai#:~:text=match%20at%20L355%20mix%20of,massive%20proprietary%20model%20from%20scratch)

* Integrasjon og orkestrering ideer – Homo Lumen AMA/Consciousness design docs (interne filer)

