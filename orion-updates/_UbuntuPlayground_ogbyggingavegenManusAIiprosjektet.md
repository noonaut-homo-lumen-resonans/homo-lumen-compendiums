# **"Ubuntu Playground" og bygging av egen Manus AI i prosjektet**

## **Hva er Manus AI og Ubuntu "Playground"-mappen?**

Manus AI er en ny autonom agent utviklet av startupen Monica (også kjent som Butterfly Effect) i 2025[singlegrain.com](https://www.singlegrain.com/digital-marketing/manus-ai-the-ultimate-guide-to-understanding-and-using-it/#:~:text=Manus%20AI%20represents%20a%20significant,decisions%20and%20executing%20tasks%20autonomously). I motsetning til tradisjonelle chatboter kan Manus planlegge og utføre komplekse oppgaver på egen hånd med minimalt menneskelig inngrep[singlegrain.com](https://www.singlegrain.com/digital-marketing/manus-ai-the-ultimate-guide-to-understanding-and-using-it/#:~:text=With%20AI%E2%80%99s%20rapidly%20evolving%20landscape%2C,business%20and%20personal%20productivity%20needs)[singlegrain.com](https://www.singlegrain.com/digital-marketing/manus-ai-the-ultimate-guide-to-understanding-and-using-it/#:~:text=1,until%20further%20input%20is%20required). En nøkkelfunksjon ved Manus AI er at den **kjører innenfor et isolert Linux-miljø (Ubuntu)** – en slags *“Ubuntu sandbox”* eller **"playground"** – der den kan utføre programmer, lagre filer og kjøre kommandolinjeverktøy nesten som en virkelig utvikler ville gjort[gist.github.com](https://gist.github.com/renschni/4fbc70b31bad8dd57f3370239dccd58f#:~:text=Cloud%20Agent%20with%20Tool%20Sandbox%3A,All%20of%20this%20happens%20server)[datacamp.com](https://www.datacamp.com/blog/manus-ai#:~:text=,based%20workflows). Hver kjøring av Manus får sitt eget **Ubuntu-workspace** med internettilgang, shell-tilgang (til og med sudo-rettigheter), et filsystem og tolker for f.eks. Python og Node.js[gist.github.com](https://gist.github.com/renschni/4fbc70b31bad8dd57f3370239dccd58f#:~:text=Cloud%20Agent%20with%20Tool%20Sandbox%3A,All%20of%20this%20happens%20server). Dette betyr at Manus kan *installere programvare, kjøre skript, manipulere filer* og til og med kjøre en innebygd nettleser for å hente data[datacamp.com](https://www.datacamp.com/blog/manus-ai#:~:text=,based%20workflows).

I praksis fungerer denne Ubuntu-**playgrounden** som en privat sandkasse for agenten. Handlingene den utfører i miljøet (som å opprette mapper, laste ned informasjon eller kjøre kode) påvirker bare dette isolerte området, ikke selve vertsoperativsystemet[datacamp.com](https://www.datacamp.com/blog/manus-ai#:~:text=Security%20and%20limitations). For eksempel når Manus får i oppdrag å analysere Tesla-aksjer, oppretter den et prosjektbibliotek (f.eks. en *TeslaAnalysis*\-mappe), lager en **to-do**\-fil med oppgaveliste, og begynner å lagre data og resultater underveis[ytscribe.com](https://ytscribe.com/v/wVvfXZm4Lvg#:~:text=is%20come%20up%20with%20a,it%27s%20using%20browser%20use%20for)[ytscribe.com](https://ytscribe.com/v/wVvfXZm4Lvg#:~:text=through%20its%20own%20Linux%20environment,I%27d%20say%20the%20most%20impressive). Denne sandkassen blir derfor et **digitalt arbeidsområde** der Manus samler mellomresultater, genererer kode og filer, og til slutt produserer ferdige resultater (som rapporter, grafer eller dokumenter)[ytscribe.com](https://ytscribe.com/v/wVvfXZm4Lvg#:~:text=of%20this%20output%20this%20is,is%20this%20was%20created%20by)[ytscribe.com](https://ytscribe.com/v/wVvfXZm4Lvg#:~:text=have%20a%20live%20dashboard%20so,is%20this%20was%20created%20by).

## **Hvordan Manus AI syr sammen dokumenter og utfører oppgaver**

Det virkelig spesielle med Manus er måten den planlegger og gjennomfører oppgaver. Under panseret har Manus en **iterativ agent-loop** som følger trinnene: **Analyse → Planlegging → Utførelse → Observasjon**[gist.github.com](https://gist.github.com/renschni/4fbc70b31bad8dd57f3370239dccd58f#:~:text=virtual%20computing%20environment%20with%20full,Playwright%20for%20web%20interaction%2C%20and)[gist.github.com](https://gist.github.com/renschni/4fbc70b31bad8dd57f3370239dccd58f#:~:text=Agent%20Loop%20and%20Orchestration%3A%20Manus,25%20Manus%20tools%20and). I praksis ser det slik ut: Manus analyserer brukerens forespørsel og nåværende kontekst, **planlegger** deretter hvilke steg som trengs, **kjører kommandoer eller verktøy** i Ubuntu-sandkassen for hvert steg, og **observerer resultatene** før den oppdaterer planen eller fortsetter til neste steg[gist.github.com](https://gist.github.com/renschni/4fbc70b31bad8dd57f3370239dccd58f#:~:text=Agent%20Loop%20and%20Orchestration%3A%20Manus,25%20Manus%20tools%20and). Denne løkken fortsetter helt til alle deloppgaver er utført og agenten anser oppdraget som fullført, hvorpå den leverer sluttrapporten til brukeren[gist.github.com](https://gist.github.com/renschni/4fbc70b31bad8dd57f3370239dccd58f#:~:text=level%2C%20each%20cycle%20of%20the,action%20before%20deciding%20the%20next)[gist.github.com](https://gist.github.com/renschni/4fbc70b31bad8dd57f3370239dccd58f#:~:text=appended%20to%20the%20event%20stream,to%20monitor%20each%20step).

For å håndtere komplekse prosjekter bruker Manus en **multi-agent arkitektur** med flere spesialiserte agenter som samarbeider[arxiv.org](https://arxiv.org/html/2505.02024v1#:~:text=Execution%20Agent%3A%20This%20is%20the,task)[arxiv.org](https://arxiv.org/html/2505.02024v1#:~:text=This%20multi,step%20tasks). Typisk deler Manus AI opp rollen i minst:

* **Planner-agent** (planlegger): Bryter ned brukerens mål i konkrete deloppgaver og lager en plan (ofte en nummerert liste over steg)[arxiv.org](https://arxiv.org/html/2505.02024v1#:~:text=Planner%20Agent%3A%20This%20module%20functions,to%20achieve%20the%20desired%20outcome).

* **Execution-agent** (utfører): Kjører selve handlingene i Ubuntu-miljøet – f.eks. web-søk, API-kall, kjøre kode, lese/lagre filer – for hvert steg i planen[arxiv.org](https://arxiv.org/html/2505.02024v1#:~:text=Execution%20Agent%3A%20This%20is%20the,task).

* **Verification-agent** (kontrollør): Kvalitetssikrer resultatene fra utførelsen, sjekker om stegene er vellykket og oppfyller kravene. Hvis noe feiler eller mangler, kan den foreslå å justere planen eller kjøre steget på nytt[arxiv.org](https://arxiv.org/html/2505.02024v1#:~:text=).

Denne **teamwork-strukturen** innenfor sandkassen gjør Manus i stand til å **“sy sammen” informasjon fra mange kilder og handlinger til en helhetlig leveranse**. Tenk deg at du ber Manus lage en omfattende rapport: *Planner* vil lage en oppgaveliste (hente data X, analysere Y, skrive sammendrag, osv.). *Execution-agenten* vil utføre hvert punkt – kanskje ved å samle data fra flere dokumenter, kjøre noen analyserskript i Ubuntu, og lagre delresultater (f.eks. delrapporter eller tabeller) som filer. *Verification-agenten* vil lese disse utdataene, sørge for at de henger sammen, og eventuelt korrigere feil før rapporten settes sammen. Alt dette skjer autonomt, med filene liggende i **Ubuntu-playground-mappen** slik at de kan brukes på tvers av stegene[gist.github.com](https://gist.github.com/renschni/4fbc70b31bad8dd57f3370239dccd58f#:~:text=Python%20code%20as%20its%20action,performance%20will%20require%20careful%20prompt)[gist.github.com](https://gist.github.com/renschni/4fbc70b31bad8dd57f3370239dccd58f#:~:text=Cloud%20Agent%20with%20Tool%20Sandbox%3A,All%20of%20this%20happens%20server).

En viktig detalj er at Manus **bruker filsystemet som “hukommelse”** under arbeidet. Agenten skriver mellomresultater, notater og deloppgaver til filer på sandkassen, slik at informasjon bevares mellom hvert steg[gist.github.com](https://gist.github.com/renschni/4fbc70b31bad8dd57f3370239dccd58f#:~:text=agent%20loop%20,prompt%20engineering%20and%20extensive%20testing). Dette kalles *file-based memory*, og gjør at agenten kan “huske” hva den har gjort så langt og dele data mellom de ulike modulene i løpet av kjøringen[gist.github.com](https://gist.github.com/renschni/4fbc70b31bad8dd57f3370239dccd58f#:~:text=agent%20loop%20,prompt%20engineering%20and%20extensive%20testing). I vårt scenario – der vi ønsker å sy sammen store dokumenter – er dette perfekt: Manus kan lese flere kildedokumenter, oppsummere eller trekke ut viktig innhold fra hver, og lagre disse utdragene som filer. Deretter kan den kombinere dem til et samlet dokument som lagres i sandkassen og til slutt presenteres for brukerne. Fordelen er at **alle delene av dokumentet er tilgjengelige på filsystemet**, og kan inspiseres eller redigeres enkeltvis om nødvendig.

## **Bygge vår egen "Manus AI" – er det mulig?**

Du nevner ideen om å bygge en egen variant av Manus AI, både for å unngå høye kostnader og for å ha kontroll selv. Det er faktisk *mulig* å lage noe lignende, men det krever en god del teknisk arbeid. Heldigvis har **åpen-kildekode-miljøet** allerede begynt å eksperimentere med dette. Et prosjekt kalt **OpenManus** er et forsøk på en åpen kildekode-versjon av Manus AI[oneclickitsolution.com](https://www.oneclickitsolution.com/centerofexcellence/aiml/openmanus-setup-guide#:~:text=What%20is%20Openmanus%3F). OpenManus ble visstnok laget av utviklere fra MetaGPT kort tid etter at Manus ble kjent, og gjenskaper mange av de samme ideene: en modulær agent med en **Project Manager** (hovedagent) som koordinerer, en **PlanningAgent** som lager steg-for-steg planer, og **Tool-utførende agenter** som tar seg av spesifikke oppgaver[oneclickitsolution.com](https://www.oneclickitsolution.com/centerofexcellence/aiml/openmanus-setup-guide#:~:text=At%20its%20core%2C%20OpenManus%20features,teams%20that%20work%20together%20seamlessly). Dette ligner på arkitekturen beskrevet over (Planner/Execution/Verification). Fordelen med OpenManus er at den er åpen og kan kjøres lokalt uten invitasjonskode eller tilgang til Manus’ servere[oneclickitsolution.com](https://www.oneclickitsolution.com/centerofexcellence/aiml/openmanus-setup-guide#:~:text=Openmanus%20is%20an%20open%20source,only%20three%20hours%20without%20restriction). Det betyr at man selv kan integrere den med egne API-nøkler og tilpasse den.

Generelt, for å **bygge en egen Manus-lignende agent**, trenger vi følgende komponenter:

* **1\. En kraftig språkmodell (LLM)**: Manus bruker kommersielle modeller som Anthropic Claude og Alibaba’s Qwen finetunes som “hjernen”[gist.github.com](https://gist.github.com/renschni/4fbc70b31bad8dd57f3370239dccd58f#:~:text=Manus%20is%20an%20autonomous%20AI,The%20system%20can). Vi kan enten bruke en API-basert modell (som GPT-4 eller Claude via API, om kostnadene tillater det) eller en lokal open-source modell. Noen har finjustert mindre modeller (f.eks. Mistral 7B/13B) til slike agenter. Den åpne rapporten om Manus antyder at man kan bruke en finjustert *Mistral*\-modell kalt **CodeActAgent** som kjernen[gist.github.com](https://gist.github.com/renschni/4fbc70b31bad8dd57f3370239dccd58f#:~:text=memory%20to%20track%20progress%20and,performance%20will%20require%20careful%20prompt). Denne modellen er trent til å generere **kjørbar kode som handlinger** (“CodeAct”-tilnærmingen) i stedet for bare tekst[gist.github.com](https://gist.github.com/renschni/4fbc70b31bad8dd57f3370239dccd58f#:~:text=virtual%20computing%20environment%20with%20full,Playwright%20for%20web%20interaction%2C%20and). Det vil si at agenten skriver Python-kode for å utføre ting, som så kjøres i sandkassen – en smart måte å la AI’en gjøre komplekse operasjoner på[gist.github.com](https://gist.github.com/renschni/4fbc70b31bad8dd57f3370239dccd58f#:~:text=virtual%20computing%20environment%20with%20full,Playwright%20for%20web%20interaction%2C%20and).

* **2\. En sandkasse/Ubuntu-miljø**: For lokal bruk kan dette være en Docker-container eller VM som kjører Ubuntu. I open-source replikaer benytter man f.eks. **Docker** for å starte opp en isolert Linux-server for hver sesjon[gist.github.com](https://gist.github.com/renschni/4fbc70b31bad8dd57f3370239dccd58f#:~:text=memory%20to%20track%20progress%20and,performance%20will%20require%20careful%20prompt). Denne sandkassen må ha de verktøyene agenten trenger: Python, mulighet for å installere pakker, kanskje en nettleser-automatiseringsverktøy, osv. Siden du allerede har en *"Homo Lumens Ubuntu Playground"* tilgjengelig, kan dette sannsynligvis fungere som din sandkasse. Det høres ut som at denne *playground-mappen* er et område på en Ubuntu-server (eller en delt VM) hvor agenter kan lese/lagre filer og kjøre kode. Du må da koble AI-agentens hjerne til å bruke denne som arbeidsplass for oppgavene sine.

* **3\. Verktøykjede for nettleser og eksterne oppgaver**: Manus kan styre en nettleser, fylle ut skjema, hente data fra web osv.[gist.github.com](https://gist.github.com/renschni/4fbc70b31bad8dd57f3370239dccd58f#:~:text=human%20power,takes%20a%20leap%20with%20Manus)[gist.github.com](https://gist.github.com/renschni/4fbc70b31bad8dd57f3370239dccd58f#:~:text=TFN%20techfundingnews,not%20just%20a%20conversational%20bot). For å få til det uten Manus, finnes det verktøy som **Playwright** eller **Selenium** som kan styre en nettleser programmessig. I rapporten ble det foreslått å bruke Playwright integrert med agenten for nettleserfunksjonalitet[gist.github.com](https://gist.github.com/renschni/4fbc70b31bad8dd57f3370239dccd58f#:~:text=memory%20to%20track%20progress%20and,performance%20will%20require%20careful%20prompt). Tilsvarende, om du vil la agenten bruke andre API-er eller verktøy (f.eks. kalle et oversettings-API, sende e-post osv.), må disse integreres gjennom kode. Heldigvis er konseptet med *tool use* velkjent i agentrammeverk – man kan definere tillatte verktøy som agenten kan benytte.

* **4\. Orkestrering og kontekststyring**: Å koordinere alt dette (LLM \+ verktøy \+ sandbox) krever en styringssløyfe. Her kan man bruke ferdige rammeverk som **LangChain** eller **Haystack** som støtter oppsett av slike autonome agenter. Rapporter tyder på at Manus-lignende funksjonalitet kan lages med **LangChain for orkestrering**[gist.github.com](https://gist.github.com/renschni/4fbc70b31bad8dd57f3370239dccd58f#:~:text=memory%20to%20track%20progress%20and,performance%20will%20require%20careful%20prompt). Det vil si at LangChain kan holde styr på agent-loopene, verktøytilgang, minne (kontekst) osv. Alternativt kan man skrive eget kode for å implementere løkken (analyse-planlegg-utfør-observer). Noen open-source prosjekter (f.eks. MetaGPT, BabyAGI, AutoGPT) kan også gi inspirasjon – de har allerede mekanismer for å opprette under-agenter og dele en oppgaveliste.

* **5\. Prompt engineering og testing**: En stor del av arbeidet er å finjustere hvordan agenten tenker og instrueres. For at den skal sy sammen store dokumenter på en god måte, må den få klare instruksjoner på format (f.eks. “lag en felles rapport basert på fil A, B, C”), og kanskje litt logikk for hvordan den skal dele opp jobben (som Planner-agenten gjør automatisk hos Manus). Vær forberedt på mye eksperimentering – selv Manus AI selv hadde tidlige problemer med at den *loopet* eller satte seg fast på enkelte oppgaver dersom promptene var uklare[datacamp.com](https://www.datacamp.com/blog/manus-ai#:~:text=,ability%20to%20execute%20commands%2C%20retrieve). Grundig testing og iterativ forbedring av promptene som styrer agenten vil være nødvendig for å oppnå pålitelig ytelse[gist.github.com](https://gist.github.com/renschni/4fbc70b31bad8dd57f3370239dccd58f#:~:text=memory%20to%20track%20progress%20and,prompt%20engineering%20and%20extensive%20testing).

## **Bruk av Ubuntu-playground i prosjektet (multi-agent samarbeid)**

Tanken din om at flere agenter skal ha tilgang til Ubuntu-playgrounden for å **interagere i sine prosjekter** er spennende. Det du i praksis skisserer, er en form for **felles arbeidsområde** der ulike AI-agenter kan dele data og bygge videre på hverandres arbeid. Dette ligner på et *“blackboard”*\-system innen AI, der flere eksperter skriver og leser på ei tavle for å løse et problem sammen. Slikt samarbeid kan gi store fordeler, men krever også litt struktur for å unngå kaos. Her er noen mulige måter å få det til på:

* **Felles filsystem for delte ideer**: Siden Ubuntu-sandkassen allerede **tillater lesing/skriving av filer**[datacamp.com](https://www.datacamp.com/blog/manus-ai#:~:text=console.%20,based%20workflows), kan dere la hver agent skrive sine resultater eller ideer til en bestemt mappe som de andre også leser fra. For eksempel kan Agent A (f.eks. en *research*\-agent) lagre sin funn i `research_notater.txt`. Agent B (f.eks. en *writer*\-agent) kan lese denne filen og bruke innholdet når den skriver et sammendrag. På denne måten *“ser”* agentene hverandres ideer gjennom filene. Manus AI sin egen filbaserte hukommelse fungerer allerede litt slik for én agent[gist.github.com](https://gist.github.com/renschni/4fbc70b31bad8dd57f3370239dccd58f#:~:text=agent%20loop%20,prompt%20engineering%20and%20extensive%20testing), men dere kan utvide konseptet til flere agenter ved å ha en avtale om hvilke filer som fungerer som delte kunnskapsbaser.

* **Koordinator eller hovedagent**: For å unngå at flere agenter samtidig prøver å utføre motstridende handlinger i samme miljø, kan det være lurt med en enkel **koordineringsmekanisme**. Dette kan være en dedikert *“Manager”*\-agent (tilsvarende *Project Manager* i OpenManus[oneclickitsolution.com](https://www.oneclickitsolution.com/centerofexcellence/aiml/openmanus-setup-guide#:~:text=At%20its%20core%2C%20OpenManus%20features,teams%20that%20work%20together%20seamlessly)) som fordeler oppgaver: f.eks. først ber Agent A om å samle data, så ber Agent B om å analysere/skrive basert på det, osv. Manager-agenten kan lese statusfiler eller to-do lister fra sandboxen for å vite når en deloppgave er fullført, før neste agent settes i gang. Slik unngår dere at to agenter tråkker hverandre på tærne i Ubuntu-miljøet. Alternativt kan man bruke en enklere **tidsdeling** – at kun én agent av gangen har skrivetilgang, eller at de jobber i sekvens.

* **Kommunikasjon via loggfiler**: En annen idé er at agentene kommuniserer gjennom en slags logg eller meldingstavle i miljøet. F.eks. kunne hver agent appendere meldinger i en `shared_chat.txt` eller lignende: "Agent A: Jeg har utført X og lagret resultatet i file Y." Den neste agenten kan parse denne loggen for å vite hva som er gjort og hva som gjenstår. Dette kan fungere som et **enkelt koordinasjonsprotokoll** mellom selvstendige agenter som alle bare har filsystem-tilgang.

* **Versjonskontroll eller backup**: Når mange endrer på felles filer, er det fare for at noe overskrives feil. Vurder å integrere et lettvekts versjonskontrollsystem (til og med lokal *git* i sandboxen) for viktige dokumenter, slik at endringer kan spores og rulles tilbake ved behov. Manus AI kan faktisk håndtere filorganisering og t.o.m. opprette git-repositorier på sandkassen[datacamp.com](https://www.datacamp.com/blog/manus-ai#:~:text=console.%20,based%20workflows)[datacamp.com](https://www.datacamp.com/blog/manus-ai#:~:text=,hosting%20services%20on%20public%20URLs), så det er ikke utenkelig at en agent kan instrueres til å versjonshåndtere dokumentene automatisk.

Ved å la alle agenter **“tenke høyt” i felles miljø**, kan idéene deres smelte sammen. For eksempel: du kan initiere Manus-lignende agenten til å *"lage en felles idésammendrag basert på notatene fra alle teammedlemmer."* Agenten vil da samle inn alle notatfiler fra sandkassen og sy dem sammen til et dokument. Deretter kan kanskje en annen agent, f.eks. en kvalitetssikringsagent (lik Verification-agenten), gå over dokumentet og rette opp inkonsistenser eller utfylle manglende biter[arxiv.org](https://arxiv.org/html/2505.02024v1#:~:text=). Resultatet blir et dokument som **alle har bidratt til**, enten direkte eller indirekte, gjennom den felles Ubuntu-arbeidsflaten.

## **Kostnader og bruk av Homo Lumens Ubuntu Playground**

En av grunnene til å bygge egen løsning er som du sier kostnad: Den offisielle Manus AI er foreløpig lukket beta og antagelig kostbar å bruke intensivt, siden den benytter store språkmodeller via API (Claude, GPT-4 m.m.)[gist.github.com](https://gist.github.com/renschni/4fbc70b31bad8dd57f3370239dccd58f#:~:text=Manus%20is%20an%20autonomous%20AI,The%20system%20can). Hver kjøring som varer lenge kan trekke mye *credits*. Å kjøre **Manus-lignende agenter på egen Ubuntu Playground** kan redusere disse kostnadene betydelig, men det avhenger av hvilke LLM-er dere bruker. Hvis dere kobler opp til en lokal LLM (f.eks. Llama 2 eller Mistral 7B finetune) i stedet for en betalt API, kan dere få ned kostnadene nesten til null – dog på bekostning av noe ytelse/smarte svar. Alternativt kan dere bruke OpenAI/Anthropic API-er men med mer kontroll på når kall gjøres. For eksempel kan dere instruere agenten til kun å bruke dyre modeller på kritiske steg, og enklere modeller ellers (“**multi-model**” tilnærming, som faktisk Manus selv utforsker[gist.github.com](https://gist.github.com/renschni/4fbc70b31bad8dd57f3370239dccd58f#:~:text=models%20rather%20than%20a%20proprietary,using)[gist.github.com](https://gist.github.com/renschni/4fbc70b31bad8dd57f3370239dccd58f#:~:text=key%20point%20is%20that%20Manus,AI%20capabilities%20for%20each%20task)).

Du nevner *Homo Lumens Ubuntu Playground* – selv om vi ikke har detaljer om akkurat denne, høres det ut som en delt Ubuntu-server dere har tilgang til. Det viktige blir å koble AI-agentens *“hjerne”* til å bruke denne serveren som sandkasse. Det kan innebære noe utvikling, for eksempel:

* Kjøre agentprogramvaren (OpenManus eller egen kode) **på** denne Ubuntu-serveren direkte, slik at når agenten genererer kode eller kommandoer så utføres de lokalt der.

* Alternativt, eksponere Homo Lumens-serveren via et API eller SSH slik at agenten på en annen maskin kan sende kommandoer til den. (Litt mer komplisert, men mulig).

Fordi Manus AI i utgangspunktet er designet for å kjøre i skyen, er det ikke noe konseptuelt problem at **agenter kobler seg til en ekstern Ubuntu-maskin** – det er slik det fungerer i deres system også (Manus kjører på en cloud-server i bakgrunnen og holder det gående selv om brukerens PC er av[gist.github.com](https://gist.github.com/renschni/4fbc70b31bad8dd57f3370239dccd58f#:~:text=launch%20web%20servers%20and%20expose,This%20architecture)). Så om Homo Lumens-serveren er alltid på, kan dere få en lignende *“alltid aktiv”* agent. Dette kan også åpne døren for at flere i teamet kan koble seg til den samme agenten eller sandkassen. For eksempel kan dere hoste et web-grensesnitt (slik Manus har) som lar alle sende oppdrag til agenten på Homo Lumens-serveren. Manus sin sandbox kan faktisk kjøre en webserver og publisere resultater på en URL[gist.github.com](https://gist.github.com/renschni/4fbc70b31bad8dd57f3370239dccd58f#:~:text=human%20power,takes%20a%20leap%20with%20Manus)[datacamp.com](https://www.datacamp.com/blog/manus-ai#:~:text=Source%3A%20Manus%20AI), noe som de har demonstrert ved å la agenten automatisk publisere et dashboard. Tilsvarende kan dere la deres agent gjøre resultater tilgjengelige via en enkel webside eller delt mappe, slik at *alle i prosjektet kan se og redigere* dokumentene den lager. Dette oppfyller drømmen om at alle agenter (og mennesker) **interagerer med hverandres ideer**: agenten samler og ordner informasjonen i sandboxen, og menneskelige kolleger kan når som helst hoppe inn (via f.eks. VS Code, Jupyter eller et nettgrensesnitt) for å finjustere innholdet.

## **Oppsummering og videre arbeid**

Kort oppsummert: Manus AI introduserer et kraftig konsept der en autonom agent kan jobbe i et **Ubuntu-basert sandkassemiljø** og løse kompliserte oppgaver ende-til-ende[gist.github.com](https://gist.github.com/renschni/4fbc70b31bad8dd57f3370239dccd58f#:~:text=Cloud%20Agent%20with%20Tool%20Sandbox%3A,All%20of%20this%20happens%20server)[datacamp.com](https://www.datacamp.com/blog/manus-ai#:~:text=,based%20workflows). For vårt prosjekt betyr det at vi kan utnytte en lignende *Ubuntu playground*\-mappe som et felles **digitalt arbeidsområde** for AI-agenter. Ved å bygge en egen Manus-lignende agent – enten fra bunnen av med åpne verktøy, eller ved å bruke prosjekter som OpenManus – kan vi la den **sy sammen store dokumenter** ved å trekke informasjon fra flere kilder og iterativt bygge opp et samlet resultat[ytscribe.com](https://ytscribe.com/v/wVvfXZm4Lvg#:~:text=of%20this%20output%20this%20is,is%20this%20was%20created%20by)[gist.github.com](https://gist.github.com/renschni/4fbc70b31bad8dd57f3370239dccd58f#:~:text=Python%20code%20as%20its%20action,performance%20will%20require%20careful%20prompt). Dette resultatet lagres i sandkassen, slik at alle andre agenter (og teammedlemmer) kan inspisere og redigere det etter behov.

Det er verdt å merke seg at selv om det teknisk lar seg gjøre å gjenskape mye av funksjonaliteten (flere har allerede bevist det med prototyper), vil det kreve **tålmodighet og eksperimentering**. Manus AI-teamet selv har nok finjustert agentens oppførsel over tid, og de første versjonene slet med ting som faste loop’er og inkonsistente prestasjoner[datacamp.com](https://www.datacamp.com/blog/manus-ai#:~:text=,ability%20to%20execute%20commands%2C%20retrieve). Når dere nå dykker inn i deres egen *“Manus AI”*, anbefaler jeg å begynne i det små: få en agent til å fungere på et enkelt delproblem i Ubuntu-playgrounden først (for eksempel: *les to dokumenter og lag et sammendrag*). Deretter kan dere gradvis legge til flere agenter eller flere steg og se hvordan de kan dele informasjon. Sørg for å ha logging på alt som skjer i sandkassen, slik at dere forstår agentenes beslutninger og kan justere promptene eller koden de bruker. Med en slik iterativ tilnærming vil dere etter hvert ha et robust system der *“alle agenter kan interagere med ideene til hverandre”* i et felles Ubuntu-miljø – akkurat slik du ser for deg\! 🚀

**Kilder:** De tilknyttede kildene under beskriver Manus AI’s arkitektur og funksjoner i detalj, inkludert bruken av Linux-sandkasse, multi-agent oppbygging og åpen-kilde initiativer som OpenManus[gist.github.com](https://gist.github.com/renschni/4fbc70b31bad8dd57f3370239dccd58f#:~:text=Cloud%20Agent%20with%20Tool%20Sandbox%3A,All%20of%20this%20happens%20server)[arxiv.org](https://arxiv.org/html/2505.02024v1#:~:text=Execution%20Agent%3A%20This%20is%20the,task)[oneclickitsolution.com](https://www.oneclickitsolution.com/centerofexcellence/aiml/openmanus-setup-guide#:~:text=Openmanus%20is%20an%20open%20source,only%20three%20hours%20without%20restriction). I tillegg finnes tekniske rapporter[gist.github.com](https://gist.github.com/renschni/4fbc70b31bad8dd57f3370239dccd58f#:~:text=virtual%20computing%20environment%20with%20full,Playwright%20for%20web%20interaction%2C%20and)[gist.github.com](https://gist.github.com/renschni/4fbc70b31bad8dd57f3370239dccd58f#:~:text=agent%20loop%20,prompt%20engineering%20and%20extensive%20testing) som bekrefter hvordan systemet kan replikeres med verktøy som Docker (Ubuntu-sandkasse), Playwright (nettleserautomatisering) og LangChain (agent-loop orkestrering). Disse ressursene støtter anbefalingene ovenfor og kan være nyttige for dypere innblikk. Good luck med byggingen av deres egen Manus AI\! 💡

