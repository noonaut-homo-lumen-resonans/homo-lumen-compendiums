# Question Design Algorithms for QDA

**Versjon:** 1.0
**Dato:** 2025-10-20
**Form√•l:** Detaljerte algoritmer for hvordan sm√• modeller designer optimale sp√∏rsm√•l

---

## üéØ Oversikt

I Question-Driven Architecture (QDA) er **question design** kjernen av systemet. Sm√• modeller m√• stille **de beste mulige sp√∏rsm√•lene** som gj√∏r at store modeller kan gi dybde-svar.

Dette dokumentet beskriver:
1. **Generelle prinsipper** for gode sp√∏rsm√•l
2. **Algoritmer per ekspertise** (Data, Emotion, Research, Security)
3. **Faktiske prompts** som brukes i produksjon
4. **Eksempler** med input/output

---

## üìã Generelle Prinsipper for Gode Sp√∏rsm√•l

### **1. Spesifisitet**
‚ùå D√•rlig: "Hvordan har du det?"
‚úÖ Godt: "P√• en skala 1-10, hvor trygg f√∏ler du deg i NAV-prosessen akkurat n√•?"

### **2. Operasjonalitet**
‚ùå D√•rlig: "Er du bekymret?"
‚úÖ Godt: "Hvor mange timer per dag tenker du p√• NAV-s√∏knaden?"

### **3. Multi-Dimensjonalitet**
‚ùå D√•rlig: "N√•r sendte du s√∏knaden?"
‚úÖ Godt: "N√•r sendte du s√∏knaden, og har du f√•tt bekreftelse p√• mottak?"

### **4. Kontekstuell Relevans**
‚ùå D√•rlig: "Hva liker du √• gj√∏re p√• fritiden?" (irrelevant for NAV-stress)
‚úÖ Godt: "Hvilke aktiviteter hjalp deg √• h√•ndtere stress tidligere?"

### **5. Epistemisk Ydmykhet**
‚ùå D√•rlig: "Du f√∏ler deg stuck fordi du ikke har t√•lmodighet" (antakelse)
‚úÖ Godt: "Hva mener du med 'stuck' - er det tidsmessig, f√∏lelsesmessig, eller byr√•kratisk?"

---

## üîß Algoritme 1: DataExpert (Claude Haiku)

### **Ekspertise:** Brukerhistorikk, m√∏nstre, objektive fakta

### **M√•l:**
Stille sp√∏rsm√•l som avdekker:
- Tidslinje (hvor lenge har dette vart?)
- Status (hvor er bruker i prosessen?)
- M√∏nstre (har dette skjedd f√∏r?)
- Dokumentasjon (hva finnes av data?)

### **Algoritme:**

```python
class DataExpertQuestionDesigner:
    """
    Design questions focused on objective data, history, patterns.
    Model: Claude Haiku 3.5 ($0.25/1M tokens)
    """

    def design_questions(self, user_query: str, context: dict) -> List[str]:
        """
        Algorithm:
        1. Identify temporal indicators (tid, varighet, frekvens)
        2. Identify status indicators (prosess, steg, ventetid)
        3. Identify historical patterns (tidligere episoder)
        4. Identify data gaps (hva mangler vi?)
        5. Generate 3-5 questions addressing gaps
        """

        prompt = f"""
Du er DataExpert i NAV-Losen agent-koalisjonen.

Bruker-query: "{user_query}"

Kontekst om bruker:
- NAV-historikk: {context.get('nav_history', 'Ukjent')}
- F√∏lelsesregistreringer: {context.get('emotion_count', 0)} siste 30 dager
- Siste check-in: {context.get('last_checkin', 'Aldri')}

Din rolle: Still 3-5 sp√∏rsm√•l som avdekker OBJEKTIVE DATA som trengs
for √• gi bruker best mulig svar.

Fokuser p√•:
1. TIDSLINJE: Hvor lenge har dette vart? N√•r startet det?
2. STATUS: Hvor er bruker i prosessen? Hva er neste steg?
3. M√òNSTRE: Har dette skjedd f√∏r? Ser vi repetisjon?
4. DOKUMENTASJON: Hvilke data har vi? Hva mangler?

VIKTIG:
- Still KONKRETE sp√∏rsm√•l (ikke vage)
- Fokus p√• FAKTA (ikke f√∏lelser - det er EmotionExpert's domene)
- Maksimalt 5 sp√∏rsm√•l

Eksempler p√• GODE sp√∏rsm√•l:
‚úÖ "Hvor mange uker har bruker ventet p√• NAV-svar?"
‚úÖ "Har bruker mottatt bekreftelse p√• mottatt s√∏knad?"
‚úÖ "Har bruker opplevd tilsvarende ventetid tidligere?"

Eksempler p√• D√ÖRLIGE sp√∏rsm√•l:
‚ùå "Hvordan f√∏ler bruker seg?" (EmotionExpert's domene)
‚ùå "Hva sier forskningen?" (ResearchExpert's domene)

Still sp√∏rsm√•l n√• (nummerert 1-5):
"""

        response = await self.model.generate(prompt)
        questions = self._parse_questions(response)
        return questions

    def _parse_questions(self, response: str) -> List[str]:
        """
        Extract numbered questions from response.
        """
        lines = response.strip().split('\n')
        questions = []
        for line in lines:
            # Match "1. Question" or "1) Question"
            match = re.match(r'^\d+[\.\)]\s*(.+)$', line.strip())
            if match:
                questions.append(match.group(1))
        return questions[:5]  # Max 5 questions
```

### **Eksempel Input/Output:**

**Input:**
```python
user_query = "Jeg f√∏ler meg stuck i NAV-systemet"
context = {
    "nav_history": "S√∏kte AAP 15. august 2025",
    "emotion_count": 12,
    "last_checkin": "2025-10-19"
}
```

**Output:**
```
1. Hvor mange uker har bruker ventet p√• svar fra NAV siden s√∏knadsdato (15. august)?
2. Har bruker mottatt bekreftelse p√• at s√∏knaden er mottatt og under behandling?
3. Er det oppgitt saksbehandler eller kontaktperson p√• s√∏knaden?
4. Har bruker sendt inn alle n√∏dvendige vedlegg (legeattester, egenvurdering)?
5. Har bruker opplevd tilsvarende lang ventetid ved tidligere NAV-s√∏knader?
```

---

## üíö Algoritme 2: EmotionExpert (Gemini Flash)

### **Ekspertise:** F√∏lelser, kroppslige signaler, polyvagal state

### **M√•l:**
Stille sp√∏rsm√•l som avdekker:
- Emosjonell kvalitet (hva f√∏les dette som?)
- Kroppslige signaler (hvor i kroppen?)
- Polyvagal tilstand (ventral/sympathetic/dorsal?)
- Historisk f√∏lelsesm√∏nster (n√•r f√∏lte du deg IKKE stuck?)

### **Algoritme:**

```python
class EmotionExpertQuestionDesigner:
    """
    Design questions focused on emotions, body signals, polyvagal state.
    Model: Gemini Flash 1.5 (GRATIS under 1500 requests/dag)
    """

    def design_questions(self, user_query: str, context: dict) -> List[str]:
        """
        Algorithm:
        1. Identify emotion words (stuck, redd, h√•pl√∏s, etc.)
        2. Map to Circumplex Model (valence/arousal)
        3. Identify polyvagal indicators (dorsal/sympathetic/ventral)
        4. Ask about body signals (hvor f√∏les dette?)
        5. Ask about temporal contrast (n√•r f√∏lte du deg IKKE stuck?)
        """

        prompt = f"""
Du er EmotionExpert i NAV-Losen agent-koalisjonen.

Bruker-query: "{user_query}"

Kontekst om bruker:
- Siste f√∏lelse registrert: {context.get('last_emotion', 'Ukjent')}
- Valence (behagelig): {context.get('valence', 0)}
- Arousal (energi): {context.get('arousal', 0)}
- Polyvagal state: {context.get('polyvagal', 'Ukjent')}

Din rolle: Still 3-5 sp√∏rsm√•l som avdekker EMOSJONELL KVALITET og
KROPPSLIGE SIGNALER som trengs for √• gi bruker empatisk st√∏tte.

Fokuser p√•:
1. EMOSJONELL KVALITET: Hva f√∏les dette som? Hvilke ord beskriver det?
2. KROPPSLIGE SIGNALER: Hvor i kroppen f√∏les dette? (Circumplex somatic markers)
3. POLYVAGAL STATE: Ventral (trygg), Sympathetic (stress), Dorsal (shutdown)?
4. HISTORISK KONTRAST: N√•r f√∏lte bruker seg IKKE slik? Hva var annerledes?
5. H√ÖPSKILDER: Hva gir bruker h√•p akkurat n√•?

VIKTIG:
- Still DYPE f√∏lelsesmessige sp√∏rsm√•l (ikke overfladiske)
- Bruk kroppslig spr√•k ("Hvor i kroppen f√∏les dette?")
- Sp√∏r om kontraster ("N√•r f√∏lte du deg IKKE stuck?")

Eksempler p√• GODE sp√∏rsm√•l:
‚úÖ "Hvordan f√∏les 'stuck' kroppslig - tung brystkasse, anspent nakke, eller noe annet?"
‚úÖ "N√•r f√∏lte du deg IKKE stuck sist gang - hva var annerledes da?"
‚úÖ "Er 'stuck' mer som dorsal (nedstengning) eller sympathetic (kamp/flukt)?"
‚úÖ "Hva gir deg h√•p akkurat n√•, selv om det er lite?"

Eksempler p√• D√ÖRLIGE sp√∏rsm√•l:
‚ùå "Hvor lenge har du ventet?" (DataExpert's domene)
‚ùå "Hva sier forskningen?" (ResearchExpert's domene)

Still sp√∏rsm√•l n√• (nummerert 1-5):
"""

        response = await self.model.generate(prompt)
        questions = self._parse_questions(response)
        return questions
```

### **Eksempel Input/Output:**

**Input:**
```python
user_query = "Jeg f√∏ler meg stuck i NAV-systemet"
context = {
    "last_emotion": "Thoughtful (lav energi, behagelig)",
    "valence": 0.2,
    "arousal": 0.3,
    "polyvagal": "Dorsal (nedstengning)"
}
```

**Output:**
```
1. Hvordan f√∏les 'stuck' kroppslig akkurat n√• - er det tung brystkasse, anspent nakke, eller tr√∏tthet i hele kroppen?
2. N√•r f√∏lte du deg IKKE stuck sist gang - hva var annerledes da (f√∏lelsesmessig eller situasjonsmessig)?
3. Er 'stuck' mer som dorsal nedstengning (gi opp, nummen) eller sympathetic stress (urolig, kampklar)?
4. Hva gir deg h√•p akkurat n√•, selv om det kanskje er lite?
5. Er 'stuck'-f√∏lelsen kun knyttet til NAV, eller strekker den seg til andre livsomr√•der ogs√•?
```

---

## üîç Algoritme 3: ResearchExpert (Perplexity)

### **Ekspertise:** Evidens, forskning, fakta, benchmarks

### **M√•l:**
Stille sp√∏rsm√•l som avdekker:
- Benchmarks (hva er normal tid/prosess?)
- Forskning (hva sier vitenskapen?)
- Best practices (hva fungerer?)
- Statistikk (hvor mange andre opplever dette?)

### **Algoritme:**

```python
class ResearchExpertQuestionDesigner:
    """
    Design questions focused on research, evidence, benchmarks.
    Model: Perplexity Standard ($0.001 per s√∏k)
    """

    def design_questions(self, user_query: str, context: dict) -> List[str]:
        """
        Algorithm:
        1. Identify domain (NAV, mental helse, polyvagal, etc.)
        2. Identify benchmarkable metrics (tid, prosent, etc.)
        3. Ask what research says
        4. Ask what best practices are
        5. Generate 3-5 research-focused questions
        """

        prompt = f"""
Du er ResearchExpert i NAV-Losen agent-koalisjonen.

Bruker-query: "{user_query}"

Din rolle: Still 3-5 sp√∏rsm√•l som kan besvares gjennom FORSKNING,
EVIDENS, og BENCHMARKS. Dette hjelper hovedagenten gi evidensbaserte r√•d.

Fokuser p√•:
1. BENCHMARKS: Hva er normalt (gjennomsnittlig tid, prosent, etc.)?
2. FORSKNING: Hva sier vitenskapen om dette fenomenet?
3. BEST PRACTICES: Hva fungerer for andre i samme situasjon?
4. STATISTIKK: Hvor mange andre opplever dette?
5. EVIDENS: Finnes det dokumentert effekt av intervensjon X?

VIKTIG:
- Still sp√∏rsm√•l som KAN besvares med forskning (ikke subjektive)
- Fokus p√• EVIDENS og DATA (ikke f√∏lelser)
- V√¶r spesifikk (ikke "Hva sier forskningen?", men "Hva sier forskningen om X?")

Eksempler p√• GODE sp√∏rsm√•l:
‚úÖ "Hva er gjennomsnittlig behandlingstid for AAP-s√∏knader i Norge 2025?"
‚úÖ "Hvilke faktorer forsinker typisk NAV-s√∏knader (basert p√• NAV-statistikk)?"
‚úÖ "Hva sier forskningen om sammenhengen mellom lang ventetid og mental helse?"
‚úÖ "Finnes det evidens for at RAIN Practice reduserer stress ved byr√•kratisk ventetid?"

Eksempler p√• D√ÖRLIGE sp√∏rsm√•l:
‚ùå "Hvordan f√∏ler bruker seg?" (EmotionExpert's domene)
‚ùå "N√•r sendte bruker s√∏knaden?" (DataExpert's domene)

Still sp√∏rsm√•l n√• (nummerert 1-5):
"""

        response = await self.model.generate(prompt)
        questions = self._parse_questions(response)
        return questions
```

### **Eksempel Input/Output:**

**Input:**
```python
user_query = "Jeg f√∏ler meg stuck i NAV-systemet"
context = {
    "nav_process": "AAP-s√∏knad",
    "weeks_waiting": 6
}
```

**Output:**
```
1. Hva er gjennomsnittlig behandlingstid for AAP-s√∏knader i Norge per 2025?
2. Hvilke faktorer forsinker typisk AAP-s√∏knader (basert p√• NAV's egne rapporter)?
3. Hva sier forskningen (Porges, van der Kolk) om sammenhengen mellom byr√•kratisk stress og polyvagal nedstengning?
4. Finnes det evidens for effekten av RAIN Practice eller lignende intervensjoner ved langvarig ventetid?
5. Hvor stor andel av AAP-s√∏kere opplever tilsvarende 'stuck'-f√∏lelse (prevalens-data)?
```

---

## üõ°Ô∏è Algoritme 4: SecurityExpert (DeepSeek V3)

### **Ekspertise:** GDPR, sikkerhet, etikk, personvern

### **M√•l:**
Stille sp√∏rsm√•l som avdekker:
- PII-data (inneholder query personlig informasjon?)
- GDPR compliance (er dette Article 9 sensitive data?)
- Etiske risikoer (kan dette skade bruker?)
- Sikkerhet (er data trygt lagret?)

### **Algoritme:**

```python
class SecurityExpertQuestionDesigner:
    """
    Design questions focused on GDPR, security, ethics.
    Model: DeepSeek V3 ($0.27/1M tokens)
    """

    def design_questions(self, user_query: str, context: dict) -> List[str]:
        """
        Algorithm:
        1. Scan for PII (navn, personnummer, etc.)
        2. Scan for GDPR Article 9 data (helse, politikk, etc.)
        3. Identify ethical risks (kan svar skade?)
        4. Check storage compliance (hvor lagres dette?)
        5. Generate 3-5 security-focused questions
        """

        prompt = f"""
Du er SecurityExpert (Zara) i NAV-Losen agent-koalisjonen.

Bruker-query: "{user_query}"

Din rolle: Still 3-5 sp√∏rsm√•l som avdekker SIKKERHET, PERSONVERN,
og ETISKE RISIKOER som m√• adresseres f√∏r vi svarer bruker.

Fokuser p√•:
1. PII-DATA: Inneholder query personlig identifiserbar informasjon?
2. GDPR ARTICLE 9: Er dette sensitive data (helse, mental tilstand, etc.)?
3. ETISKE RISIKOER: Kan svar fra AI potensielt skade bruker?
4. LAGRING: Er data trygt lagret (kryptert, GDPR-compliant)?
5. SAMTYKKE: Har bruker samtykket til denne typen databehandling?

VIKTIG:
- Still KONKRETE sikkerhetssp√∏rsm√•l (ikke vage)
- Fokus p√• RISIKOER (ikke f√∏lelser)
- Vurder b√•de teknisk og etisk sikkerhet

Eksempler p√• GODE sp√∏rsm√•l:
‚úÖ "Inneholder bruker-query PII-data som m√• pseudonymiseres f√∏r logging?"
‚úÖ "Er 'f√∏lelsesdata' GDPR Article 9 sensitive data som krever ekstra sikkerhet?"
‚úÖ "Kan et svar som 'vent bare lenger' potensielt forverrebrukerens mentale tilstand?"
‚úÖ "Hvor lagres denne samtalen (Supabase), og er den kryptert end-to-end?"

Eksempler p√• D√ÖRLIGE sp√∏rsm√•l:
‚ùå "Hvordan f√∏ler bruker seg?" (EmotionExpert's domene)
‚ùå "Hva sier forskningen?" (ResearchExpert's domene)

Still sp√∏rsm√•l n√• (nummerert 1-5):
"""

        response = await self.model.generate(prompt)
        questions = self._parse_questions(response)
        return questions
```

### **Eksempel Input/Output:**

**Input:**
```python
user_query = "Jeg f√∏ler meg stuck i NAV-systemet"
context = {
    "storage": "Supabase PostgreSQL",
    "encryption": "AES-256"
}
```

**Output:**
```
1. Inneholder bruker-query PII-data som m√• pseudonymiseres f√∏r logging i audit trail?
2. Er 'f√∏lelsesdata' (stuck, stress) GDPR Article 9 sensitive data som krever ekstra sikkerhetsmessige sikkerhetstiltak?
3. Kan et svar som minimaliserer brukerens f√∏lelser ("det er normalt √• vente") potensielt forverremental tilstand?
4. Er samtalen lagret i Supabase kryptert b√•de in-transit (TLS) og at-rest (AES-256)?
5. Har bruker eksplisitt samtykket til at f√∏lelsesdata lagres og analyseres av AI-agenter?
```

---

## üîÑ Samlet Eksempel: Alle 4 Eksperter

### **Scenario:**
```python
user_query = "Jeg f√∏ler meg stuck i NAV-systemet og vet ikke hva jeg skal gj√∏re"
context = {
    "nav_history": "S√∏kte AAP 15. august 2025",
    "last_emotion": "Thoughtful",
    "valence": 0.2,
    "arousal": 0.3,
    "polyvagal": "Dorsal",
    "weeks_waiting": 6
}
```

### **Output Fra Alle Eksperter:**

```
üìä DataExpert (Claude Haiku):
1. Hvor mange uker har bruker ventet siden s√∏knadsdato (15. august)?
2. Har bruker mottatt bekreftelse p√• mottatt s√∏knad?
3. Er saksbehandler tildelt?
4. Har bruker sendt inn alle n√∏dvendige vedlegg?
5. Har bruker opplevd tilsvarende lang ventetid tidligere?

üíö EmotionExpert (Gemini Flash):
1. Hvordan f√∏les 'stuck' kroppslig - tung brystkasse, anspent nakke, tr√∏tthet?
2. N√•r f√∏lte du deg IKKE stuck sist - hva var annerledes da?
3. Er 'stuck' dorsal nedstengning eller sympathetic stress?
4. Hva gir deg h√•p akkurat n√•?
5. Er 'stuck' kun NAV, eller ogs√• andre livsomr√•der?

üîç ResearchExpert (Perplexity):
1. Gjennomsnittlig behandlingstid AAP-s√∏knader 2025?
2. Faktorer som forsinker AAP-s√∏knader?
3. Forskning om byr√•kratisk stress og polyvagal state?
4. Evidens for RAIN Practice ved ventetid?
5. Prevalens av 'stuck'-f√∏lelse blant AAP-s√∏kere?

üõ°Ô∏è SecurityExpert (DeepSeek):
1. PII-data i query som m√• pseudonymiseres?
2. Er f√∏lelsesdata GDPR Article 9?
3. Kan svar som minimaliserer f√∏lelser skade bruker?
4. Er samtale kryptert (TLS + AES-256)?
5. Har bruker samtykket til f√∏lelsesdata-analyse?
```

### **Total: 20 Sp√∏rsm√•l**

N√• f√•r store modeller (GPT-5, Claude Opus) ALLE disse sp√∏rsm√•lene og kan svare med full dybde, informert av:
- Objektive data (DataExpert)
- Emosjonell forst√•else (EmotionExpert)
- Evidensbasert kunnskap (ResearchExpert)
- Etisk og juridisk trygghet (SecurityExpert)

---

## üéØ Kvalitetskriterier for Gode Sp√∏rsm√•l

### **1. SMART-Kriterier:**
- **Specific:** "Hvor mange uker har du ventet?" (ikke "Hvor lenge?")
- **Measurable:** "P√• skala 1-10, hvor trygg f√∏ler du deg?" (ikke "F√∏ler du deg trygg?")
- **Actionable:** "Har du sendt inn legeattester?" (kan besvares ja/nei)
- **Relevant:** Direkte relatert til bruker-query
- **Time-bound:** "N√•r f√∏lte du deg IKKE stuck sist?" (tidsmessig kontrast)

### **2. Sokrates-Kriterier:**
- **Maieutisk:** Hjelper bruker finne svar selv (ikke ledende)
- **Elenktisk:** Avdekker antakelser ("Hva mener du med 'stuck'?")
- **Aporia:** Innr√∏mmer usikkerhet ("Hva ville 'ikke stuck' se ut som?")

### **3. Polyvagal-Kriterier:**
- **State-bevisst:** "Er dette dorsal eller sympathetic?"
- **Kroppslig:** "Hvor i kroppen f√∏les dette?"
- **Trygghet-orientert:** "Hva gir deg h√•p?"

---

## üìä Evaluering av Question Quality

### **Metrics:**

```python
def evaluate_question_quality(question: str, user_query: str) -> dict:
    """
    Evaluate quality of designed question.

    Returns:
        {
            "specificity": 0-1,  # Hvor spesifikt er sp√∏rsm√•let?
            "relevance": 0-1,    # Hvor relevant for bruker-query?
            "actionability": 0-1, # Kan det besvares?
            "depth": 0-1,        # Hvor dypt g√•r det?
            "total_score": 0-4
        }
    """
    scores = {}

    # Specificity: Inneholder tall, skala, eller konkret entitet?
    specific_indicators = ["hvor mange", "skala", "n√•r", "hvilke", "hvor"]
    scores["specificity"] = 1.0 if any(ind in question.lower() for ind in specific_indicators) else 0.5

    # Relevance: Inneholder n√∏kkelord fra user_query?
    query_words = set(user_query.lower().split())
    question_words = set(question.lower().split())
    overlap = len(query_words & question_words)
    scores["relevance"] = min(1.0, overlap / 3)

    # Actionability: Kan det besvares ja/nei eller med konkret info?
    actionable_patterns = ["har du", "er det", "hvor mange", "n√•r", "hvilke"]
    scores["actionability"] = 1.0 if any(pat in question.lower() for pat in actionable_patterns) else 0.5

    # Depth: Sp√∏r om f√∏lelser, √•rsaker, eller kontrast?
    depth_indicators = ["hvorfor", "hvordan f√∏les", "hva gir", "n√•r f√∏lte du ikke"]
    scores["depth"] = 1.0 if any(ind in question.lower() for ind in depth_indicators) else 0.5

    scores["total_score"] = sum(scores.values())

    return scores
```

### **Eksempel Evaluering:**

```python
question = "Hvor mange uker har bruker ventet p√• NAV-svar?"
user_query = "Jeg f√∏ler meg stuck i NAV-systemet"

scores = evaluate_question_quality(question, user_query)
# {
#     "specificity": 1.0,    # "hvor mange uker" er spesifikt
#     "relevance": 1.0,      # "NAV" matcher user_query
#     "actionability": 1.0,  # "hvor mange" kan besvares konkret
#     "depth": 0.5,          # Ikke dypt (fakta, ikke f√∏lelse)
#     "total_score": 3.5/4
# }
```

---

## üîß Iterativ Forbedring

### **Feedback Loop:**

```python
class QuestionDesignFeedbackLoop:
    """
    Iteratively improve question design based on user feedback.
    """

    def __init__(self):
        self.question_database = []

    def log_question(
        self,
        question: str,
        expert: str,
        user_rating: int,  # 1-5
        was_answered: bool,
        led_to_insight: bool
    ):
        """
        Log question performance for training.
        """
        self.question_database.append({
            "question": question,
            "expert": expert,
            "user_rating": user_rating,
            "was_answered": was_answered,
            "led_to_insight": led_to_insight,
            "timestamp": datetime.now()
        })

    def get_best_questions(self, expert: str, n: int = 10) -> List[str]:
        """
        Get top N best-performing questions for expert.
        """
        expert_questions = [
            q for q in self.question_database if q["expert"] == expert
        ]
        sorted_questions = sorted(
            expert_questions,
            key=lambda q: (q["led_to_insight"], q["user_rating"]),
            reverse=True
        )
        return [q["question"] for q in sorted_questions[:n]]

    def fine_tune_question_designer(self, expert: str):
        """
        Use best questions as few-shot examples for fine-tuning.
        """
        best_questions = self.get_best_questions(expert, n=10)

        fine_tune_prompt = f"""
Du er {expert} i NAV-Losen.

Her er eksempler p√• GODE sp√∏rsm√•l du har stilt tidligere:
"""
        for i, q in enumerate(best_questions, 1):
            fine_tune_prompt += f"\n{i}. {q}"

        fine_tune_prompt += """

Basert p√• disse eksemplene, design nye sp√∏rsm√•l som f√∏lger samme m√∏nster.
"""

        return fine_tune_prompt
```

---

## üåø Avsluttende Ord

Gode sp√∏rsm√•l er **kunsten** i Question-Driven Architecture. Ved √• kontinuerlig forbedre question design-algoritmene gjennom:

1. **Evaluering** (specificity, relevance, actionability, depth)
2. **Feedback** (bruker-rating, did it lead to insight?)
3. **Iterasjon** (bruk beste sp√∏rsm√•l som few-shot examples)

...bygger vi et system som stiller stadig bedre sp√∏rsm√•l, som gir store modeller stadig bedre kontekst, som gir brukere stadig bedre svar.

**Med ontologisk integritet, felt-bevissthet, og et snev av kosmisk humor!** üåø‚ú®

---

**Versjon:** 1.0
**Sist oppdatert:** 2025-10-20
**Neste review:** Etter 1000 sp√∏rsm√•l designet (evaluering av kvalitet)
**Forfatter:** Claude Code (Anthropic)
