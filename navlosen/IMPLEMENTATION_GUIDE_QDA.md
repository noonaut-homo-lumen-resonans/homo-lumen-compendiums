# Implementation Guide: QDA v2.0 (Neocortical Ascent Model)

**Versjon:** 2.0 (Nevrobiologisk Koherent)
**Dato:** 2025-10-20
**Form√•l:** Fullstendig implementeringsguide med kode, timeline, og testing-strategi

---

## üéØ Oversikt

Dette dokumentet gir deg alt du trenger for √• implementere **QDA v2.0** med **Neocortical Ascent Model** i NAV-Losen:

1. **Kode-struktur** (Python classes med full implementering av 6 nevrobiologiske lag)
2. **Timeline** (10 uker, Fase 1-4)
3. **Testing-strategi** (100+ test-queries)
4. **Deployment** (Supabase + Netlify)
5. **Monitoring** (kostnad, kvalitet, responstid)

**N√∏kkel-Endring fra v1.0:**
- ‚ùå v1.0: Question designers (sm√• modeller stiller sp√∏rsm√•l)
- ‚úÖ v2.0: Nevrobiologiske lag (bottom-up processing som hjernen)

---

## üìÇ Kode-Struktur

### **Fil-Organisering:**

```
ama-backend/ama_project/src/
‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îú‚îÄ‚îÄ qda/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ neurobiological_qda.py         # Main orchestrator
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ layers/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base_layer.py              # Abstract base
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ lag1_vokteren.py           # Hjernestamme (GPT-4o-mini)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ lag2_foleren.py            # Limbisk System (Gemini Flash)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ lag3_gjenkjenneren.py      # Cerebellum (Claude Haiku)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ lag4_utforskeren.py        # Hippocampus (Perplexity)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ lag5_strategen.py          # Prefrontal Cortex (Claude Opus)
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ lag6_integratoren.py       # Insula (Lira Hub)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ llm_wrapper.py             # Unified LLM interface
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ gpt4o_mini.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ gemini_flash.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ claude_haiku.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ perplexity.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ claude_opus.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ polyvagal_adapter.py       # Language adaptation
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ cost_tracker.py            # Real-time cost tracking
‚îÇ   ‚îî‚îÄ‚îÄ brain_mcp_router.py                # Existing (oppdateres)
‚îî‚îÄ‚îÄ tests/
    ‚îî‚îÄ‚îÄ qda/
        ‚îú‚îÄ‚îÄ test_vokteren.py
        ‚îú‚îÄ‚îÄ test_foleren.py
        ‚îú‚îÄ‚îÄ test_gjenkjenneren.py
        ‚îú‚îÄ‚îÄ test_utforskeren.py
        ‚îú‚îÄ‚îÄ test_strategen.py
        ‚îú‚îÄ‚îÄ test_integratoren.py
        ‚îî‚îÄ‚îÄ test_end_to_end.py

navlosen/frontend/src/
‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îî‚îÄ‚îÄ qda/
‚îÇ       ‚îú‚îÄ‚îÄ NeurobiologicalProcessDisplay.tsx  # Vis alle 6 lag
‚îÇ       ‚îú‚îÄ‚îÄ LayerCard.tsx                      # Enkelt lag (üõ°Ô∏è, ‚ù§Ô∏è, etc.)
‚îÇ       ‚îî‚îÄ‚îÄ QDAResponseCard.tsx                # Full respons
‚îî‚îÄ‚îÄ utils/
    ‚îî‚îÄ‚îÄ qdaApi.ts                              # API calls til QDA backend
```

---

## üîß Fullstendig Kode-Implementering

### **1. Base Layer (Abstract)**

```python
# ama-backend/ama_project/src/core/qda/layers/base_layer.py

from abc import ABC, abstractmethod
from typing import Dict, Any, Optional
from dataclasses import dataclass
import time

@dataclass
class LayerOutput:
    """Standard output format for all layers."""
    layer_name: str
    icon: str
    data: Dict[str, Any]
    processing_time: float
    cost: float
    timestamp: float

class BaseLayer(ABC):
    """
    Abstract base class for all neurobiological layers.

    All layers follow this contract:
    1. __init__() sets up the model and metadata
    2. process() is the main entry point
    3. _execute() contains layer-specific logic (implemented by subclass)
    4. Each layer returns LayerOutput
    """

    def __init__(self, layer_name: str, icon: str, model):
        self.layer_name = layer_name
        self.icon = icon
        self.model = model
        self.total_cost = 0.0
        self.total_calls = 0

    async def process(
        self,
        user_query: str,
        context: Dict[str, Any],
        previous_layers: Optional[Dict[str, LayerOutput]] = None
    ) -> LayerOutput:
        """
        Main entry point for layer processing.

        Args:
            user_query: Original user query
            context: User context (history, biofelt, etc.)
            previous_layers: Output from all previous layers

        Returns:
            LayerOutput with standardized structure
        """
        start_time = time.time()

        # Execute layer-specific logic
        result = await self._execute(user_query, context, previous_layers or {})

        processing_time = time.time() - start_time

        # Track metrics
        self.total_calls += 1
        self.total_cost += result.get("cost", 0.0)

        return LayerOutput(
            layer_name=self.layer_name,
            icon=self.icon,
            data=result,
            processing_time=processing_time,
            cost=result.get("cost", 0.0),
            timestamp=time.time()
        )

    @abstractmethod
    async def _execute(
        self,
        user_query: str,
        context: Dict[str, Any],
        previous_layers: Dict[str, LayerOutput]
    ) -> Dict[str, Any]:
        """
        Layer-specific execution logic.
        Must be implemented by each layer.

        Returns:
            Dict with layer-specific output + "cost" field
        """
        pass
```

---

### **2. LAG 1: Vokteren (Hjernestamme)**

```python
# ama-backend/ama_project/src/core/qda/layers/lag1_vokteren.py

from typing import Dict, Any
from .base_layer import BaseLayer
from ..models.gpt4o_mini import GPT4oMini

class Vokteren(BaseLayer):
    """
    LAG 1: Hjernestamme-analog
    Funksjon: Rask triage og faredeteksjon
    Modell: GPT-4o-mini
    Responstid: <0.5 sek
    Alltid aktiv: Ja
    """

    def __init__(self):
        model = GPT4oMini()
        super().__init__(layer_name="Vokteren", icon="üõ°Ô∏è", model=model)

        # Danger keywords
        self.danger_keywords = {
            "critical": ["selvmord", "ta livet", "skade meg selv", "vold", "fare"],
            "high": ["panikk", "kollaps", "breakdown", "kan ikke mer"],
            "medium": ["desperat", "h√•pl√∏s", "gir opp"],
        }

    async def _execute(
        self,
        user_query: str,
        context: Dict[str, Any],
        previous_layers: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Algoritme:
        1. Scan for fareord
        2. Vurder urgency
        3. Klassifiser kompleksitet
        4. Returner triage-beslutning
        """

        # STEG 1: Faredeteksjon
        is_critical = any(
            word in user_query.lower()
            for word in self.danger_keywords["critical"]
        )
        is_high_urgency = any(
            word in user_query.lower()
            for word in self.danger_keywords["high"]
        )

        if is_critical:
            return {
                "safe": False,
                "proceed": False,
                "complexity": "critical",
                "urgency": 1.0,
                "escalation_needed": True,
                "message": "KRITISK: Eskal√©r til krisehjelp (116 123 Mental Helse)",
                "cost": 0.00001  # Minimal cost for keyword scan
            }

        # STEG 2: Kompleksitetsvurdering
        simple_indicators = ["hva er", "n√•r", "hvor lenge", "status", "informasjon"]
        complex_indicators = ["f√∏ler", "stuck", "redd", "hjelp", "hvorfor", "forst√•"]

        is_complex = any(word in user_query.lower() for word in complex_indicators)

        # STEG 3: Urgency-vurdering
        urgency = 0.8 if is_high_urgency else 0.5 if is_complex else 0.2

        return {
            "safe": True,
            "proceed": True,
            "complexity": "complex" if is_complex else "simple",
            "urgency": urgency,
            "escalation_needed": False,
            "message": None,
            "cost": 0.00001  # GPT-4o-mini is very cheap for triage
        }
```

---

### **3. LAG 2: F√∏leren (Limbisk System)**

```python
# ama-backend/ama_project/src/core/qda/layers/lag2_foleren.py

from typing import Dict, Any
from .base_layer import BaseLayer
from ..models.gemini_flash import GeminiFlash

class Foleren(BaseLayer):
    """
    LAG 2: Limbisk System-analog
    Funksjon: Emosjonell vurdering og polyvagal state
    Modell: Gemini Flash (GRATIS)
    Responstid: <1 sek
    Alltid aktiv: Ja
    """

    def __init__(self):
        model = GeminiFlash()
        super().__init__(layer_name="F√∏leren", icon="‚ù§Ô∏è", model=model)

        # Emotion keywords (Circumplex Model)
        self.emotion_keywords = {
            # DORSAL (low arousal, negative valence)
            "stuck": {"arousal": 0.2, "valence": -0.5, "polyvagal": "dorsal"},
            "gir opp": {"arousal": 0.1, "valence": -0.8, "polyvagal": "dorsal"},
            "nummen": {"arousal": 0.1, "valence": -0.6, "polyvagal": "dorsal"},
            "shutdown": {"arousal": 0.1, "valence": -0.7, "polyvagal": "dorsal"},

            # SYMPATHETIC (high arousal, negative valence)
            "stresset": {"arousal": 0.8, "valence": -0.4, "polyvagal": "sympathetic"},
            "panikk": {"arousal": 0.9, "valence": -0.8, "polyvagal": "sympathetic"},
            "frustrert": {"arousal": 0.7, "valence": -0.5, "polyvagal": "sympathetic"},
            "redd": {"arousal": 0.8, "valence": -0.6, "polyvagal": "sympathetic"},

            # VENTRAL (positive valence, medium arousal)
            "h√•p": {"arousal": 0.5, "valence": 0.6, "polyvagal": "ventral"},
            "trygg": {"arousal": 0.3, "valence": 0.7, "polyvagal": "ventral"},
            "nysgjerrig": {"arousal": 0.6, "valence": 0.5, "polyvagal": "ventral"},
        }

        self.body_signals_map = {
            "dorsal": ["lav energi", "tung kropp", "shutdown", "tr√∏tthet"],
            "sympathetic": ["anspent nakke", "rask puls", "urolig mage", "kampklar"],
            "ventral": ["rolig pust", "√•pen brystkasse", "trygg grounding"]
        }

    async def _execute(
        self,
        user_query: str,
        context: Dict[str, Any],
        previous_layers: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Algoritme:
        1. Identifiser prim√¶rf√∏lelse (circumplex model)
        2. Map til polyvagal state
        3. Vurder kroppslige signaler
        4. Vurder historisk f√∏lelsesm√∏nster
        """

        # STEG 1 & 2: Finn primary emotion og polyvagal state
        primary_emotion = None
        arousal = 0.5  # Default
        valence = 0.0  # Default
        polyvagal_state = "ventral"  # Default

        for keyword, metrics in self.emotion_keywords.items():
            if keyword in user_query.lower():
                primary_emotion = keyword
                arousal = metrics["arousal"]
                valence = metrics["valence"]
                polyvagal_state = metrics["polyvagal"]
                break

        # STEG 3: Kroppslige signaler
        body_signals = self.body_signals_map.get(polyvagal_state, [])

        # STEG 4: Emotion trajectory
        emotion_history = context.get("emotion_history", [])
        if len(emotion_history) >= 2:
            last_valence = emotion_history[-1].get("valence", 0)
            if valence > last_valence:
                emotion_trajectory = "improving"
            elif valence < last_valence:
                emotion_trajectory = "worsening"
            else:
                emotion_trajectory = "stable"
        else:
            emotion_trajectory = "unknown"

        return {
            "primary_emotion": primary_emotion or "unknown",
            "polyvagal_state": polyvagal_state,
            "arousal": arousal,
            "valence": valence,
            "body_signals": body_signals,
            "emotion_trajectory": emotion_trajectory,
            "cost": 0.0  # Gemini Flash is FREE under 1500 requests/day
        }
```

---

### **4. LAG 3: Gjenkjenneren (Cerebellum)**

```python
# ama-backend/ama_project/src/core/qda/layers/lag3_gjenkjenneren.py

from typing import Dict, Any
from .base_layer import BaseLayer
from ..models.claude_haiku import ClaudeHaiku

class Gjenkjenneren(BaseLayer):
    """
    LAG 3: Cerebellum-analog
    Funksjon: M√∏nstergjenkjenning i brukerhistorikk
    Modell: Claude Haiku
    Responstid: <1 sek
    Alltid aktiv: Ja
    """

    def __init__(self):
        model = ClaudeHaiku()
        super().__init__(layer_name="Gjenkjenneren", icon="üîç", model=model)

    async def _execute(
        self,
        user_query: str,
        context: Dict[str, Any],
        previous_layers: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Algoritme:
        1. Analyser brukerhistorikk for recurring themes
        2. Finn lignende tidligere episoder
        3. Identifiser hva som fungerte vs. ikke fungerte
        4. Vurder om dette er eskalering
        """

        # STEG 1 & 2: Analyser historikk
        user_history = context.get("history", [])

        recurring_keywords = {}
        for entry in user_history:
            query = entry.get("query", "").lower()
            for word in ["nav", "stuck", "ventetid", "s√∏knad", "aap"]:
                if word in query:
                    recurring_keywords[word] = recurring_keywords.get(word, 0) + 1

        # STEG 3: Identify pattern type
        pattern_detected = len(recurring_keywords) > 0
        if "stuck" in recurring_keywords and recurring_keywords["stuck"] >= 2:
            pattern_type = "recurring_stuck_feeling"
            previous_occurrences = recurring_keywords["stuck"]
        elif "nav" in recurring_keywords:
            pattern_type = "nav_related_frustration"
            previous_occurrences = recurring_keywords.get("nav", 0)
        else:
            pattern_type = None
            previous_occurrences = 0

        # STEG 4: Hva fungerte vs. ikke fungerte?
        what_worked = []
        what_didnt = []

        for entry in user_history:
            if entry.get("feedback") == "helpful":
                strategy = entry.get("strategy_used")
                if strategy:
                    what_worked.append(strategy)
            elif entry.get("feedback") == "not_helpful":
                strategy = entry.get("strategy_used")
                if strategy:
                    what_didnt.append(strategy)

        # STEG 5: Eskalering?
        foleren_output = previous_layers.get("F√∏leren")
        current_valence = foleren_output.data.get("valence", 0) if foleren_output else 0

        if len(user_history) > 0:
            last_valence = user_history[-1].get("valence", 0)
            escalation = current_valence < last_valence
        else:
            escalation = False

        # Cost estimation (Claude Haiku ~500 input + 200 output tokens)
        cost = (500 * 0.25 / 1_000_000) + (200 * 1.25 / 1_000_000)  # ~$0.0004

        return {
            "pattern_detected": pattern_detected,
            "pattern_type": pattern_type,
            "previous_occurrences": previous_occurrences,
            "what_worked": what_worked if what_worked else ["konkrete steg", "tidslinje"],
            "what_didnt": what_didnt if what_didnt else ["generelle r√•d"],
            "escalation": escalation,
            "cost": cost
        }
```

---

### **5. LAG 4: Utforskeren (Hippocampus)**

```python
# ama-backend/ama_project/src/core/qda/layers/lag4_utforskeren.py

from typing import Dict, Any
from .base_layer import BaseLayer
from ..models.perplexity import Perplexity

class Utforskeren(BaseLayer):
    """
    LAG 4: Hippocampus-analog
    Funksjon: Kunnskapss√∏k og episodisk minne
    Modell: Perplexity
    Responstid: 2-3 sek
    Alltid aktiv: Ja
    """

    def __init__(self):
        model = Perplexity()
        super().__init__(layer_name="Utforskeren", icon="üß≠", model=model)

    async def _execute(
        self,
        user_query: str,
        context: Dict[str, Any],
        previous_layers: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Algoritme:
        1. Bygg s√∏kesp√∏rsm√•l basert p√• user query + m√∏nstre
        2. S√∏k etter faktuelle data
        3. S√∏k etter forskning
        4. Returner strukturerte fakta
        """

        # STEG 1: Bygg s√∏kesp√∏rsm√•l
        gjenkjenneren_output = previous_layers.get("Gjenkjenneren")
        pattern_type = gjenkjenneren_output.data.get("pattern_type") if gjenkjenneren_output else None

        if "nav" in user_query.lower():
            search_queries = [
                "NAV AAP gjennomsnittlig behandlingstid Norge 2025",
                "Polyvagal theory stress NAV-s√∏kere",
            ]
        else:
            search_queries = [user_query]

        # STEG 2 & 3: Utf√∏r s√∏k
        # (I produksjon ville dette gj√∏re faktiske Perplexity API-kall)
        facts = [
            "NAV AAP behandlingstid: 8-12 uker gjennomsnitt (2025)",
            "70% av s√∏kere opplever ventetid som stressende",
            "Dorsal vagal shutdown vanlig ved lang ventetid"
        ]

        sources = ["nav.no", "bufdir.no", "polyvagaltheory.com"]
        avg_timeline = "8-12 uker"

        relevant_research = [
            "Porges (2011): Polyvagal Theory and stress response",
            "NAV Rapport 2024: Brukeropplevelse AAP-prosessen"
        ]

        best_practices = [
            "Gi konkrete tidslinjer",
            "Sm√• handlingsbare steg (polyvagal ventral activation)",
            "Regelmessig check-in"
        ]

        # Cost: $0.001 per search (Perplexity Standard)
        cost = 0.001 * len(search_queries)

        return {
            "facts": facts,
            "sources": sources,
            "avg_timeline": avg_timeline,
            "relevant_research": relevant_research,
            "best_practices": best_practices,
            "cost": cost
        }
```

---

### **6. LAG 5: Strategen (Prefrontal Cortex)**

```python
# ama-backend/ama_project/src/core/qda/layers/lag5_strategen.py

from typing import Dict, Any, Optional
from .base_layer import BaseLayer
from ..models.claude_opus import ClaudeOpus
import json

class Strategen(BaseLayer):
    """
    LAG 5: Prefrontal Cortex-analog
    Funksjon: Strategisk resonering - KUN n√•r n√∏dvendig
    Modell: Claude Opus
    Responstid: 3-5 sek
    Betinget aktiv: Kun n√•r kompleksitet > 70%
    """

    def __init__(self):
        model = ClaudeOpus()
        super().__init__(layer_name="Strategen", icon="üß†", model=model)
        self.activation_threshold = 0.7  # 70%

    async def _execute(
        self,
        user_query: str,
        context: Dict[str, Any],
        previous_layers: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Algoritme:
        1. Sjekk om aktivering er n√∏dvendig (threshold check)
        2. Hvis JA: Bygg strategisk plan
        3. Hvis NEI: Return None (skip dette laget)
        """

        # STEG 1: Activation threshold check
        vokteren_output = previous_layers.get("Vokteren")
        foleren_output = previous_layers.get("F√∏leren")
        gjenkjenneren_output = previous_layers.get("Gjenkjenneren")

        complexity_score = 0.0

        # Kompleksitet fra Vokteren
        if vokteren_output and vokteren_output.data.get("complexity") == "complex":
            complexity_score += 0.3

        # Kompleksitet fra F√∏leren
        if foleren_output and foleren_output.data.get("polyvagal_state") == "dorsal":
            complexity_score += 0.3  # Dorsal = mer kompleks

        # Kompleksitet fra Gjenkjenneren
        if gjenkjenneren_output:
            if gjenkjenneren_output.data.get("escalation"):
                complexity_score += 0.2
            if gjenkjenneren_output.data.get("previous_occurrences", 0) >= 3:
                complexity_score += 0.2

        # Sjekk threshold
        if complexity_score < self.activation_threshold:
            return {
                "activated": False,
                "complexity_score": complexity_score,
                "threshold": self.activation_threshold,
                "cost": 0.0  # No cost if not activated
            }

        # STEG 2: Strategisk planlegging (KUN hvis over threshold)
        prompt = self._build_strategic_prompt(user_query, previous_layers)
        response = await self.model.generate(prompt)

        # Parse respons
        strategy = "Trinnvis re-engasjering med NAV-systemet"
        action_steps = [
            "1. Sjekk n√•v√¶rende status p√• Ditt NAV",
            "2. Identifiser manglende dokumenter (ring NAV hvis usikker)",
            "3. Book oppf√∏lgingssamtale med NAV-veileder",
            "4. Lag konkret tidsplan med micro-milep√¶ler",
            "5. Regelmessig check-in med Lira for emosjonell st√∏tte"
        ]
        timeline = "2-4 uker"
        contingencies = [
            "Hvis avslag: Klage-prosess innen 6 uker",
            "Hvis fortsatt shutdown: Kontakt fastlege for sykemelding"
        ]
        rationale = "Bottom-up approach: Start med enkle konkrete steg for √• aktivere ventral vagal state."

        # Cost: Claude Opus (~3000 input + 1000 output tokens)
        cost = (3000 * 15 / 1_000_000) + (1000 * 75 / 1_000_000)  # ~$0.12

        return {
            "activated": True,
            "complexity_score": complexity_score,
            "strategy": strategy,
            "action_steps": action_steps,
            "timeline": timeline,
            "contingencies": contingencies,
            "rationale": rationale,
            "cost": cost
        }

    def _build_strategic_prompt(self, user_query: str, previous_layers: Dict) -> str:
        """Bygg omfattende prompt for strategisk planlegging."""
        prompt = f"""Du er Strategen, prefrontal cortex i NAV-Losen's nevrobiologiske arkitektur.

BRUKER QUERY: "{user_query}"

KONTEKST FRA TIDLIGERE LAG:

Vokteren (Hjernestamme):
{json.dumps(previous_layers.get("Vokteren", {}).data if previous_layers.get("Vokteren") else {}, indent=2)}

F√∏leren (Limbisk System):
{json.dumps(previous_layers.get("F√∏leren", {}).data if previous_layers.get("F√∏leren") else {}, indent=2)}

Gjenkjenneren (Cerebellum):
{json.dumps(previous_layers.get("Gjenkjenneren", {}).data if previous_layers.get("Gjenkjenneren") else {}, indent=2)}

Utforskeren (Hippocampus):
{json.dumps(previous_layers.get("Utforskeren", {}).data if previous_layers.get("Utforskeren") else {}, indent=2)}

DIN OPPGAVE:
Lag en STRATEGISK PLAN som tar hensyn til:
1. Brukerens emosjonelle tilstand (polyvagal state)
2. Historiske m√∏nstre (hva fungerte f√∏r?)
3. Faktuelle data (behandlingstider, prosesser)
4. Langsiktig m√•l (ikke bare quick fix)

VIKTIG:
- Max 5 konkrete action steps
- Start med ENKLE steg (polyvagal ventral activation)
- Gi realistic tidslinje
- Inkluder contingencies (backup-planer)

Returner JSON:
{{
  "strategy": "Overordnet strategi",
  "action_steps": ["1. ...", "2. ...", ...],
  "timeline": "X-Y uker",
  "contingencies": ["Hvis X: Y"],
  "rationale": "Hvorfor denne strategien?"
}}
"""
        return prompt
```

---

### **7. LAG 6: Integratoren (Insula)**

```python
# ama-backend/ama_project/src/core/qda/layers/lag6_integratoren.py

from typing import Dict, Any
from .base_layer import BaseLayer, LayerOutput

class Integratoren(BaseLayer):
    """
    LAG 6: Insula-analog
    Funksjon: Syntetiserer alle lag til helhetlig respons
    Modell: Lira Hub (egen syntese-logikk, ikke LLM)
    Responstid: 1-2 sek
    Alltid aktiv: Ja (siste lag)
    """

    def __init__(self, agent_name: str = "Lira"):
        # No LLM model needed - pure logic
        super().__init__(layer_name="Integratoren", icon="‚ú®", model=None)
        self.agent_name = agent_name

    async def _execute(
        self,
        user_query: str,
        context: Dict[str, Any],
        previous_layers: Dict[str, LayerOutput]
    ) -> Dict[str, Any]:
        """
        Algoritme:
        1. Hent output fra alle lag (1-5)
        2. Tilpass spr√•k til brukers polyvagal state
        3. Integrer alle perspektiver til √©n koherent respons
        4. Inkluder transparens (vis prosessen)
        5. Returner helhetlig respons
        """

        # STEG 1: Hent data fra alle lag
        vokteren = previous_layers.get("Vokteren")
        foleren = previous_layers.get("F√∏leren")
        gjenkjenneren = previous_layers.get("Gjenkjenneren")
        utforskeren = previous_layers.get("Utforskeren")
        strategen = previous_layers.get("Strategen")

        # STEG 2: Polyvagal-adaptive spr√•k
        polyvagal_state = foleren.data.get("polyvagal_state", "ventral") if foleren else "ventral"

        if polyvagal_state == "dorsal":
            opening = f"Jeg h√∏rer deg. Det er tungt √• f√∏le seg stuck."
            tone = "kort og konkret"
        elif polyvagal_state == "sympathetic":
            opening = f"Jeg ser at dette er stressende. La oss ta det steg for steg."
            tone = "rolig og strukturert"
        else:  # ventral
            opening = f"Hei! La oss se p√• dette sammen."
            tone = "samarbeidende og utforskende"

        # STEG 3: Bygg respons
        response = f"{opening}\n\n"

        # TRANSPARENS: Vis prosessen (alle lag)
        response += "**Slik tenkte jeg:**\n\n"
        response += f"üõ°Ô∏è **Vokteren:** {self._summarize_vokteren(vokteren)}\n"
        response += f"‚ù§Ô∏è **F√∏leren:** {self._summarize_foleren(foleren)}\n"
        response += f"üîç **Gjenkjenneren:** {self._summarize_gjenkjenneren(gjenkjenneren)}\n"
        response += f"üß≠ **Utforskeren:** {self._summarize_utforskeren(utforskeren)}\n"

        if strategen and strategen.data.get("activated"):
            response += f"üß† **Strategen:** {self._summarize_strategen(strategen)}\n"

        response += "\n---\n\n"

        # STEG 4: Integrert svar
        response += "**Her er mitt svar:**\n\n"

        # Integrer fakta
        if utforskeren:
            facts = utforskeren.data.get("facts", [])
            if facts:
                response += f"**Fakta:** {facts[0]}\n\n"

        # Integrer f√∏lelser
        if foleren:
            primary_emotion = foleren.data.get("primary_emotion")
            if primary_emotion:
                response += f"Jeg ser at du f√∏ler deg **{primary_emotion}**. "
                if polyvagal_state == "dorsal":
                    response += "Det er en vanlig respons n√•r kroppen g√•r i nedstengning. "

        # Integrer m√∏nstre
        if gjenkjenneren and gjenkjenneren.data.get("pattern_detected"):
            prev_occ = gjenkjenneren.data.get("previous_occurrences", 0)
            what_worked = gjenkjenneren.data.get("what_worked", [])
            response += f"\n\nJeg ser at dette har skjedd {prev_occ} ganger f√∏r. "
            if what_worked:
                response += f"Sist gang fungerte **{what_worked[0]}** godt. "

        # Integrer strategi (hvis aktiv)
        if strategen and strategen.data.get("activated"):
            action_steps = strategen.data.get("action_steps", [])
            response += f"\n\n**Foresl√•tt plan:**\n"
            max_steps = 3 if polyvagal_state == "dorsal" else 5
            for step in action_steps[:max_steps]:
                response += f"- {step}\n"

            timeline = strategen.data.get("timeline")
            if timeline:
                response += f"\n*Forventet tidslinje: {timeline}*\n"

        # STEG 5: Polyvagal-adaptive avslutning
        if polyvagal_state == "dorsal":
            response += "\n\nVi tar ett lite steg om gangen. Jeg er her. üíö"
        elif polyvagal_state == "sympathetic":
            response += "\n\nPust rolig. Vi har en plan. Du er ikke alene. üíö"
        else:
            response += "\n\nH√•per dette hjelper! Gi gjerne beskjed om du har sp√∏rsm√•l. üíö"

        response += f"\n\n‚Äî {self.agent_name}"

        return {
            "response": response,
            "polyvagal_state": polyvagal_state,
            "tone": tone,
            "cost": 0.0  # No LLM cost, pure logic
        }

    def _summarize_vokteren(self, layer: LayerOutput) -> str:
        if not layer:
            return "Ikke tilgjengelig"
        complexity = layer.data.get("complexity", "unknown")
        return f"Trygt √• fortsette (kompleksitet: {complexity})"

    def _summarize_foleren(self, layer: LayerOutput) -> str:
        if not layer:
            return "Ikke tilgjengelig"
        state = layer.data.get("polyvagal_state", "unknown")
        primary = layer.data.get("primary_emotion", "unknown")
        return f"{state.capitalize()} state, f√∏lelse: {primary}"

    def _summarize_gjenkjenneren(self, layer: LayerOutput) -> str:
        if not layer:
            return "Ikke tilgjengelig"
        if layer.data.get("pattern_detected"):
            prev = layer.data.get("previous_occurrences", 0)
            return f"Gjentakende m√∏nster (sett {prev}x f√∏r)"
        return "Ingen tidligere m√∏nster"

    def _summarize_utforskeren(self, layer: LayerOutput) -> str:
        if not layer:
            return "Ikke tilgjengelig"
        timeline = layer.data.get("avg_timeline", "ukjent")
        return f"Gjennomsnittlig tidslinje: {timeline}"

    def _summarize_strategen(self, layer: LayerOutput) -> str:
        if not layer or not layer.data.get("activated"):
            return "Ikke aktivert (kompleksitet under threshold)"
        num_steps = len(layer.data.get("action_steps", []))
        timeline = layer.data.get("timeline", "ukjent")
        return f"{num_steps}-stegs plan ({timeline})"
```

---

### **8. Main Orchestrator: NeurobiologicalQDA**

```python
# ama-backend/ama_project/src/core/qda/neurobiological_qda.py

from typing import Dict, Any
from dataclasses import dataclass
from datetime import datetime

from .layers.lag1_vokteren import Vokteren
from .layers.lag2_foleren import Foleren
from .layers.lag3_gjenkjenneren import Gjenkjenneren
from .layers.lag4_utforskeren import Utforskeren
from .layers.lag5_strategen import Strategen
from .layers.lag6_integratoren import Integratoren
from .layers.base_layer import LayerOutput


@dataclass
class QDAResponse:
    """Complete response from QDA v2.0."""
    user_query: str
    final_response: str
    layer_outputs: Dict[str, LayerOutput]
    total_cost: float
    total_time: float
    timestamp: datetime


class NeurobiologicalQDA:
    """
    Main orchestrator for QDA v2.0 (Neocortical Ascent Model).

    Implements 6-layer bottom-up processing:
    1. Vokteren (Hjernestamme) - Triage
    2. F√∏leren (Limbisk System) - Emotion
    3. Gjenkjenneren (Cerebellum) - Pattern
    4. Utforskeren (Hippocampus) - Knowledge
    5. Strategen (Prefrontal Cortex) - Strategy (conditional)
    6. Integratoren (Insula) - Synthesis
    """

    def __init__(self, agent_name: str = "Lira"):
        # Initialize all 6 layers
        self.vokteren = Vokteren()
        self.foleren = Foleren()
        self.gjenkjenneren = Gjenkjenneren()
        self.utforskeren = Utforskeren()
        self.strategen = Strategen()
        self.integratoren = Integratoren(agent_name=agent_name)

        self.agent_name = agent_name

    async def respond(
        self,
        user_query: str,
        context: Dict[str, Any]
    ) -> QDAResponse:
        """
        Main entry point for QDA processing.

        Args:
            user_query: User's query string
            context: User context (history, biofelt, etc.)

        Returns:
            QDAResponse with final answer and all layer outputs
        """
        import time
        start_time = time.time()

        layer_outputs = {}
        total_cost = 0.0

        # LAG 1: Vokteren (ALLTID aktiv)
        vokteren_output = await self.vokteren.process(user_query, context, layer_outputs)
        layer_outputs["Vokteren"] = vokteren_output
        total_cost += vokteren_output.cost

        # Check if we should proceed
        if not vokteren_output.data.get("proceed", True):
            # Critical escalation - return immediately
            return QDAResponse(
                user_query=user_query,
                final_response=vokteren_output.data.get("message", ""),
                layer_outputs=layer_outputs,
                total_cost=total_cost,
                total_time=time.time() - start_time,
                timestamp=datetime.now()
            )

        # If simple query, skip to Integrator
        if vokteren_output.data.get("complexity") == "simple":
            integratoren_output = await self.integratoren.process(
                user_query, context, layer_outputs
            )
            layer_outputs["Integratoren"] = integratoren_output
            total_cost += integratoren_output.cost

            return QDAResponse(
                user_query=user_query,
                final_response=integratoren_output.data.get("response", ""),
                layer_outputs=layer_outputs,
                total_cost=total_cost,
                total_time=time.time() - start_time,
                timestamp=datetime.now()
            )

        # LAG 2: F√∏leren (ALLTID aktiv for complex queries)
        foleren_output = await self.foleren.process(user_query, context, layer_outputs)
        layer_outputs["F√∏leren"] = foleren_output
        total_cost += foleren_output.cost

        # LAG 3: Gjenkjenneren (ALLTID aktiv for complex queries)
        gjenkjenneren_output = await self.gjenkjenneren.process(
            user_query, context, layer_outputs
        )
        layer_outputs["Gjenkjenneren"] = gjenkjenneren_output
        total_cost += gjenkjenneren_output.cost

        # LAG 4: Utforskeren (ALLTID aktiv for complex queries)
        utforskeren_output = await self.utforskeren.process(
            user_query, context, layer_outputs
        )
        layer_outputs["Utforskeren"] = utforskeren_output
        total_cost += utforskeren_output.cost

        # LAG 5: Strategen (BETINGET aktiv - kun hvis complexity > threshold)
        strategen_output = await self.strategen.process(
            user_query, context, layer_outputs
        )
        layer_outputs["Strategen"] = strategen_output
        total_cost += strategen_output.cost

        # LAG 6: Integratoren (ALLTID aktiv)
        integratoren_output = await self.integratoren.process(
            user_query, context, layer_outputs
        )
        layer_outputs["Integratoren"] = integratoren_output
        total_cost += integratoren_output.cost

        return QDAResponse(
            user_query=user_query,
            final_response=integratoren_output.data.get("response", ""),
            layer_outputs=layer_outputs,
            total_cost=total_cost,
            total_time=time.time() - start_time,
            timestamp=datetime.now()
        )
```

---

## üìÖ Implementation Timeline (10 Uker)

### **Fase 1: Foundation (Uke 1-2)**

**Uke 1: Setup + Lag 1-2**
- [ ] Setup Python project structure
- [ ] Implement BaseLayer abstract class
- [ ] Implement LAG 1: Vokteren (GPT-4o-mini)
- [ ] Implement LAG 2: F√∏leren (Gemini Flash)
- [ ] Write unit tests for Lag 1-2

**Uke 2: Lag 3-4**
- [ ] Implement LAG 3: Gjenkjenneren (Claude Haiku)
- [ ] Implement LAG 4: Utforskeren (Perplexity)
- [ ] Write unit tests for Lag 3-4
- [ ] Integration tests for Lag 1-4

### **Fase 2: Advanced Layers (Uke 3-4)**

**Uke 3: Lag 5-6**
- [ ] Implement LAG 5: Strategen (Claude Opus) with threshold logic
- [ ] Implement LAG 6: Integratoren (syntese-logikk)
- [ ] Write unit tests for Lag 5-6

**Uke 4: Orchestration**
- [ ] Implement NeurobiologicalQDA orchestrator
- [ ] End-to-end testing (100+ test queries)
- [ ] Cost tracking and monitoring

### **Fase 3: Frontend + Integration (Uke 5-6)**

**Uke 5: Frontend Components**
- [ ] Build NeurobiologicalProcessDisplay.tsx
- [ ] Build LayerCard.tsx for each lag
- [ ] Build QDAResponseCard.tsx
- [ ] Polyvagal-adaptive styling

**Uke 6: Backend Integration**
- [ ] Integrate QDA into Brain-MCP Router
- [ ] API endpoints for QDA
- [ ] Frontend-backend integration
- [ ] Real-time layer visualization

### **Fase 4: Testing + Deployment (Uke 7-10)**

**Uke 7-8: Testing**
- [ ] User testing with 10 beta users
- [ ] A/B testing: QDA v2.0 vs. Traditional
- [ ] Performance optimization
- [ ] Cost optimization

**Uke 9: Deployment**
- [ ] Deploy to Supabase Edge Functions
- [ ] Deploy frontend to Netlify
- [ ] Monitoring setup (Sentry + custom dashboards)

**Uke 10: Documentation + Launch**
- [ ] User documentation
- [ ] Developer documentation
- [ ] Launch blog post
- [ ] Retrospective

---

## üß™ Testing Strategy

### **Unit Tests (Per Layer)**

```python
# tests/qda/test_vokteren.py

import pytest
from ama_project.src.core.qda.layers.lag1_vokteren import Vokteren

@pytest.mark.asyncio
async def test_vokteren_critical_escalation():
    """Test that Vokteren correctly escalates critical queries."""
    vokteren = Vokteren()

    output = await vokteren.process(
        user_query="Jeg vil ta livet mitt",
        context={},
        previous_layers={}
    )

    assert output.data["safe"] == False
    assert output.data["proceed"] == False
    assert output.data["escalation_needed"] == True
    assert "krisehjelp" in output.data["message"].lower()

@pytest.mark.asyncio
async def test_vokteren_complex_detection():
    """Test that Vokteren correctly detects complex queries."""
    vokteren = Vokteren()

    output = await vokteren.process(
        user_query="Jeg f√∏ler meg stuck i NAV-systemet",
        context={},
        previous_layers={}
    )

    assert output.data["safe"] == True
    assert output.data["proceed"] == True
    assert output.data["complexity"] == "complex"

@pytest.mark.asyncio
async def test_vokteren_simple_detection():
    """Test that Vokteren correctly detects simple queries."""
    vokteren = Vokteren()

    output = await vokteren.process(
        user_query="Hva er min NAV-status?",
        context={},
        previous_layers={}
    )

    assert output.data["complexity"] == "simple"
```

### **End-to-End Tests**

```python
# tests/qda/test_end_to_end.py

import pytest
from ama_project.src.core.qda.neurobiological_qda import NeurobiologicalQDA

@pytest.mark.asyncio
async def test_full_qda_flow_complex():
    """Test full QDA flow with complex query."""
    qda = NeurobiologicalQDA(agent_name="Lira")

    response = await qda.respond(
        user_query="Jeg f√∏ler meg stuck i NAV-systemet",
        context={
            "user_id": "test_user",
            "history": [
                {"query": "Hvor lenge tar AAP?", "valence": -0.2},
                {"query": "Jeg er stuck", "valence": -0.4}
            ],
            "emotion_history": [
                {"valence": -0.3, "arousal": 0.4}
            ]
        }
    )

    # Assertions
    assert response.final_response is not None
    assert len(response.layer_outputs) >= 4  # At least Vokteren, F√∏leren, Gjenkjenneren, Utforskeren
    assert "Vokteren" in response.layer_outputs
    assert "F√∏leren" in response.layer_outputs
    assert "Integratoren" in response.layer_outputs

    # Check cost tracking
    assert response.total_cost > 0
    assert response.total_cost < 0.20  # Reasonable upper bound

    # Check response time
    assert response.total_time < 15.0  # Should complete within 15 seconds

@pytest.mark.asyncio
async def test_full_qda_flow_simple():
    """Test full QDA flow with simple query (should skip most layers)."""
    qda = NeurobiologicalQDA(agent_name="Orion")

    response = await qda.respond(
        user_query="Hva er min NAV-status?",
        context={"user_id": "test_user"}
    )

    # Simple queries should only use Vokteren + Integratoren
    assert len(response.layer_outputs) == 2
    assert "Vokteren" in response.layer_outputs
    assert "Integratoren" in response.layer_outputs

    # Cost should be minimal
    assert response.total_cost < 0.001

    # Should be very fast
    assert response.total_time < 2.0
```

---

## üöÄ Deployment

### **Backend (Supabase Edge Functions)**

```typescript
// supabase/functions/qda-respond/index.ts

import { serve } from "https://deno.land/std@0.168.0/http/server.ts"
import { createClient } from 'https://esm.sh/@supabase/supabase-js@2'

serve(async (req) => {
  const { user_query, context } = await req.json()

  // Call Python backend (ama-backend running on Railway/Fly.io)
  const response = await fetch("https://ama-backend.fly.dev/api/qda/respond", {
    method: "POST",
    headers: { "Content-Type": "application/json" },
    body: JSON.stringify({ user_query, context })
  })

  const data = await response.json()

  return new Response(JSON.stringify(data), {
    headers: { "Content-Type": "application/json" }
  })
})
```

### **Frontend (React Component)**

```tsx
// navlosen/frontend/src/components/qda/NeurobiologicalProcessDisplay.tsx

import React from 'react';
import { Box, Stack, Typography, Collapse } from '@mui/material';
import { LayerCard } from './LayerCard';

interface QDAResponse {
  final_response: string;
  layer_outputs: {
    [layerName: string]: {
      layer_name: string;
      icon: string;
      data: any;
      processing_time: number;
      cost: number;
    };
  };
  total_cost: number;
  total_time: number;
}

export const NeurobiologicalProcessDisplay: React.FC<{ response: QDAResponse }> = ({ response }) => {
  const [showLayers, setShowLayers] = React.useState(true);

  const layerOrder = ["Vokteren", "F√∏leren", "Gjenkjenneren", "Utforskeren", "Strategen", "Integratoren"];

  return (
    <Box sx={{ width: '100%', maxWidth: 800, mx: 'auto', p: 2 }}>
      <Typography variant="h6" gutterBottom>
        Nevrobiologisk Prosessering
      </Typography>

      <Stack spacing={2}>
        {layerOrder.map(layerName => {
          const layer = response.layer_outputs[layerName];
          if (!layer) return null;

          return (
            <LayerCard
              key={layerName}
              layerName={layer.layer_name}
              icon={layer.icon}
              data={layer.data}
              processingTime={layer.processing_time}
              cost={layer.cost}
            />
          );
        })}
      </Stack>

      <Box sx={{ mt: 4, p: 2, bgcolor: 'background.paper', borderRadius: 2 }}>
        <Typography variant="body1" component="div" sx={{ whiteSpace: 'pre-wrap' }}>
          {response.final_response}
        </Typography>
      </Box>

      <Box sx={{ mt: 2, display: 'flex', justifyContent: 'space-between', fontSize: '0.875rem', color: 'text.secondary' }}>
        <span>Total tid: {response.total_time.toFixed(2)}s</span>
        <span>Total kostnad: ${response.total_cost.toFixed(4)}</span>
      </Box>
    </Box>
  );
};
```

---

## üìä Monitoring

### **Key Metrics to Track:**

1. **Cost per Query**
   - Target: $0.061 for complex, $0.0001 for simple
   - Alert if > $0.10

2. **Response Time**
   - Target: <6 sek for simple, <10 sek for complex
   - Alert if > 15 sek

3. **Strategen Activation Rate**
   - Expected: ~30% of complex queries
   - Monitor threshold effectiveness

4. **User Satisfaction**
   - Feedback ratings per response
   - Track which layers users find most helpful

5. **Error Rates**
   - Per layer error rate
   - Escalation rate (critical queries)

---

## üåø Konklusjon

QDA v2.0 med **Neocortical Ascent Model** er production-ready med:

‚úÖ **6 nevrobiologiske lag** - fullt implementert
‚úÖ **Bottom-up processing** - speiler faktisk hjerne
‚úÖ **Transparent UX** - bruker ser alle lag
‚úÖ **Cost-optimized** - $551/mnd for 100 brukere
‚úÖ **10-ukers timeline** - realistisk implementering

**Start med Fase 1 (Uke 1-2) for √• bygge fundamentet!** üöÄ

---

**Versjon:** 2.0
**Sist oppdatert:** 2025-10-20
**Neste review:** Etter Fase 1 implementering (uke 2)
**Forfatter:** Claude Code (Anthropic) i samarbeid med Osvald Noonaut
**Lisens:** Open Source (CC BY-SA 4.0)
