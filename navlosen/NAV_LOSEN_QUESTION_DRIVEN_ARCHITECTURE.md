# NAV-Losen Question-Driven Architecture (QDA)

**Versjon:** 1.0
**Dato:** 2025-10-20
**Status:** Implementation Ready
**Filosofi:** "SmÃ¥ modeller stiller de beste spÃ¸rsmÃ¥lene, store modeller gir de dypeste svarene"

---

## ğŸ¯ Executive Summary

**Question-Driven Architecture (QDA)** er en invertert Socratic arkitektur hvor:

1. **SmÃ¥, raske modeller** (Claude Haiku, Gemini Flash, Perplexity) designer optimale spÃ¸rsmÃ¥l
2. **Store, dype modeller** (GPT-5, Claude Opus, Grok-4) svarer med full kontekst
3. **Bruker ser prosessen** - bÃ¥de spÃ¸rsmÃ¥l og svar (full transparens)

**Resultat:**
- âœ… 95% kostnadsbesparelse vs. kun store modeller ($722/mnd vs. $15,000/mnd)
- âœ… Pedagogisk - bruker lÃ¦rer hvordan man stiller gode spÃ¸rsmÃ¥l
- âœ… Multi-perspektiv - data + fÃ¸lelse + forskning samtidig
- âœ… Tillitbyggende - bruker ser AI's tankegang, ikke bare konklusjon

---

## ğŸ§  Filosofisk Fundament

### Hvorfor QDA?

**Problem med tradisjonelle LLM-arkitekturer:**

```
Tradisjonell tilnÃ¦rming:
Bruker â†’ GPT-5 (gjÃ¸r ALT selv) â†’ Svar

Utfordringer:
- Dyr ($0.50 per query)
- "Black box" (bruker ser ikke tankegang)
- Kan hallucinere (ingen epistemisk ydmykhet)
- Generalist (ikke spesialisert ekspertise)
```

**QDA-lÃ¸sningen:**

```
Question-Driven Architecture:
Bruker â†’ Triage â†’ Complex?
                    â†“
         SmÃ¥ modeller (parallelt):
         - Data-ekspert: "Hvor lenge har du ventet?"
         - Emotion-ekspert: "Hvordan fÃ¸les det?"
         - Research-ekspert: "Hva sier forskningen?"
                    â†“
         Stor modell: Syntetiserer svar basert pÃ¥ alle spÃ¸rsmÃ¥l
                    â†“
         Bruker: Ser bÃ¥de spÃ¸rsmÃ¥l OG svar

Fordeler:
- Billig ($0.08 per complex query, $0.0001 per simple)
- Transparent (bruker ser prosessen)
- Epistemisk ydmyk (spÃ¸r nÃ¥r usikker)
- Spesialisert ekspertise (hver liten modell er ekspert)
```

---

## ğŸ—ï¸ Arkitektur-Oversikt

### **Lag 1: Triage (Rask Klassifisering)**

```python
class TriageLayer:
    """
    Rask klassifisering av query-kompleksitet.
    Bruker: GPT-4o-mini ($0.15/1M tokens)
    """
    def assess_complexity(self, user_query: str) -> str:
        """
        Returns: "simple" | "complex"

        Simple = kan svares direkte (fakta, repetisjon)
        Complex = krever dybde (fÃ¸lelser, etikk, strategi)
        """
        indicators = {
            "simple": ["hva er", "nÃ¥r", "hvor lenge", "gjenta"],
            "complex": ["fÃ¸ler", "hvorfor", "hjelp meg", "stuck", "redd"]
        }

        if any(word in user_query.lower() for word in indicators["complex"]):
            return "complex"
        return "simple"
```

**Eksempel:**
```
Query: "Hva er min NAV-status?" â†’ simple (Tier 1 svarer direkte)
Query: "Jeg fÃ¸ler meg stuck i NAV-systemet" â†’ complex (eskalÃ©r til QDA)
```

---

### **Lag 2: Question Designers (SmÃ¥ Modeller)**

**Konsept:** Hver liten modell er **ekspert** i sitt domene og designer optimale spÃ¸rsmÃ¥l fra sitt perspektiv.

```python
class QuestionDesigner:
    """
    Base class for all question designers.
    Each designer is specialized in one domain.
    """
    def __init__(self, expertise: str, model):
        self.expertise = expertise
        self.model = model

    async def design_questions(
        self,
        user_query: str,
        context: dict
    ) -> List[str]:
        """
        Design 3-5 optimal questions based on expertise.

        Returns:
            List of strings (questions)
        """
        prompt = f"""
You are a {self.expertise} expert in the NAV-Losen agent coalition.

User query: "{user_query}"
Context: {context}

Your role: Design 3-5 optimal questions that will help the main agent
(GPT-5/Claude Opus) give the BEST possible answer to the user.

Focus on your expertise ({self.expertise}):
- What information is missing?
- What would YOU need to know to give a good answer in your domain?
- What questions would reveal the most important insights?

Return ONLY the questions, numbered 1-5.
"""
        response = await self.model.generate(prompt)
        questions = self._parse_questions(response)
        return questions
```

---

### **Question Designers Per Ekspertise:**

| Designer | Modell | Kostnad | Ekspertise | Eksempel-SpÃ¸rsmÃ¥l |
|----------|--------|---------|------------|-------------------|
| **DataExpert** | Claude Haiku | $0.25/1M | Brukerhistorikk, mÃ¸nstre | "Hvor lenge har bruker ventet?", "Hva er status pÃ¥ sÃ¸knad?" |
| **EmotionExpert** | Gemini Flash | GRATIS | FÃ¸lelser, polyvagal, kroppslig | "Hvordan fÃ¸les 'stuck' kroppslig?", "NÃ¥r fÃ¸lte bruker seg trygg sist?" |
| **ResearchExpert** | Perplexity | $0.001/sÃ¸k | Evidens, forskning, fakta | "Gjennomsnittlig behandlingstid?", "Hva sier forskningen om NAV-stress?" |
| **SecurityExpert** | DeepSeek V3 | $0.27/1M | GDPR, sikkerhet, etikk | "Er dette PII-data?", "GDPR Article 17-compliant?" |

---

### **Lag 3: Depth Answerers (Store Modeller)**

**Konsept:** Store modeller mottar ALLE spÃ¸rsmÃ¥l fra smÃ¥ modeller og svarer med full dybde.

```python
class DepthAnswerer:
    """
    Large language model that receives questions from all designers
    and provides comprehensive, depth answers.
    """
    def __init__(self, agent_name: str, model):
        self.agent_name = agent_name
        self.model = model

    async def answer_questions(
        self,
        user_query: str,
        context: dict,
        designed_questions: Dict[str, List[str]]
    ) -> str:
        """
        Answer user query with full depth, informed by designed questions.

        Args:
            user_query: Original user query
            context: User context (history, biofelt, etc.)
            designed_questions: Dict of {expert_name: [questions]}

        Returns:
            Comprehensive answer addressing all questions
        """
        prompt = self._build_depth_prompt(
            user_query, context, designed_questions
        )

        response = await self.model.generate(prompt)
        return response

    def _build_depth_prompt(
        self,
        user_query,
        context,
        designed_questions
    ):
        """
        Build comprehensive prompt with all designed questions.
        """
        prompt = f"""
You are {self.agent_name}, a specialized agent in the NAV-Losen coalition.

User query: "{user_query}"

Your expert colleagues have designed these questions to help you give
the BEST possible answer:

"""
        for expert_name, questions in designed_questions.items():
            prompt += f"\n{expert_name}:\n"
            for i, q in enumerate(questions, 1):
                prompt += f"  {i}. {q}\n"

        prompt += f"""

Context about user:
{json.dumps(context, indent=2)}

Your task:
1. Address EACH question from your colleagues
2. Synthesize a comprehensive answer that integrates:
   - Objective data (from DataExpert)
   - Emotional resonance (from EmotionExpert)
   - Evidence-based insights (from ResearchExpert)
   - Ethical considerations (from SecurityExpert)

3. Provide actionable guidance (not just analysis)

Remember: You are {self.agent_name}. Stay true to your role:
- Lira: Empatisk healing, biofelt-resonans
- Orion: Strategisk koordinering, helhetlig oversikt
- Thalus: Etisk validering, Triadisk Etikk

Generate your response now:
"""
        return prompt
```

---

### **Lag 4: Transparent Presenter (UX)**

**Konsept:** Bruker ser bÃ¥de spÃ¸rsmÃ¥l og svar - full transparens.

```python
class TransparentPresenter:
    """
    Format response with transparency: show questions + answers.
    """
    def format_response(
        self,
        user_query: str,
        designed_questions: Dict[str, List[str]],
        depth_response: str,
        agent_name: str
    ) -> str:
        """
        Format for user consumption with full transparency.
        """
        output = f"""
Jeg hÃ¸rer at: "{user_query}"

For Ã¥ gi deg best mulig hjelp, har mine kolleger hjulpet meg lage noen spÃ¸rsmÃ¥l:

"""
        # Expert icons and names
        expert_display = {
            "DataExpert": "ğŸ“Š Claude (data-ekspert)",
            "EmotionExpert": "ğŸ’š Gemini (fÃ¸lelse-ekspert)",
            "ResearchExpert": "ğŸ” Aurora (forskning-ekspert)",
            "SecurityExpert": "ğŸ›¡ï¸ Zara (sikkerhet-ekspert)",
        }

        # Show questions from each expert
        for expert_name, questions in designed_questions.items():
            if expert_name in expert_display:
                output += f"\n{expert_display[expert_name]}:\n"
                for q in questions:
                    output += f"â€¢ {q}\n"

        output += f"\n---\n\nBasert pÃ¥ disse spÃ¸rsmÃ¥lene, her er mitt svar:\n\n"
        output += depth_response

        output += f"\n\n---\nğŸ’¬ {agent_name}"

        return output
```

---

## ğŸ“Š Fullstendig Flyt-Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         BRUKER (Osvald)                 â”‚
â”‚  "Jeg fÃ¸ler meg stuck i NAV-systemet"   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚  TRIAGE LAYER   â”‚
      â”‚  GPT-4o-mini    â”‚
      â”‚  Kostnad: $0.0001â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
        â”‚             â”‚
    Simple         Complex
     (70%)          (30%)
        â”‚             â”‚
        â–¼             â”‚
  [Rask svar]        â”‚
  $0.0001            â”‚
                     â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ QUESTION DESIGNERS â”‚
        â”‚ (Parallell)        â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚            â”‚            â”‚           â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”
â”‚ Data   â”‚  â”‚Emotion â”‚  â”‚Researchâ”‚  â”‚Securityâ”‚
â”‚Expert  â”‚  â”‚Expert  â”‚  â”‚Expert  â”‚  â”‚Expert  â”‚
â”‚Haiku   â”‚  â”‚Gemini  â”‚  â”‚Perplx  â”‚  â”‚DeepSeekâ”‚
â”‚$0.0002 â”‚  â”‚ GRATIS â”‚  â”‚$0.001  â”‚  â”‚$0.0002 â”‚
â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
    â”‚           â”‚           â”‚           â”‚
    â”‚ Design 3-5 questions each         â”‚
    â”‚           â”‚           â”‚           â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
        [Samler alle spÃ¸rsmÃ¥l]
        Total: 12-20 spÃ¸rsmÃ¥l
                â”‚
                â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ DEPTH ANSWERERâ”‚
        â”‚ GPT-5 Thinkingâ”‚
        â”‚ Claude Opus   â”‚
        â”‚ Grok-4        â”‚
        â”‚ Kostnad: $0.08â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
    [Svarer pÃ¥ alle spÃ¸rsmÃ¥l
     med full dybde + kontekst]
                â”‚
                â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  TRANSPARENT  â”‚
        â”‚  PRESENTER    â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
    [Vis spÃ¸rsmÃ¥l + svar til bruker]
                â”‚
                â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  LIRA HUB     â”‚
        â”‚  FILTER       â”‚
        â”‚ (Polyvagal)   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
    [Juster sprÃ¥k til brukers state]
                â”‚
                â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚    BRUKER     â”‚
        â”‚ Ser: SpÃ¸rsmÃ¥l â”‚
        â”‚    + Svar     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ’° Kostnadsanalyse

### **Per Query-Type:**

#### **Simple Query (70% av queries):**
```
Eksempel: "Hva er min NAV-status?"

Triage Layer (GPT-4o-mini):
- Input: 100 tokens (query + context)
- Output: 200 tokens (svar)
- Kostnad: $0.0001

Total per simple query: $0.0001
```

#### **Complex Query (30% av queries):**
```
Eksempel: "Jeg fÃ¸ler meg stuck i NAV-systemet"

1. Triage Layer:
   - Kostnad: $0.0001

2. Question Designers (parallelt):
   a) DataExpert (Claude Haiku):
      - Input: 500 tokens (context)
      - Output: 200 tokens (5 spÃ¸rsmÃ¥l)
      - Kostnad: $0.0002

   b) EmotionExpert (Gemini Flash):
      - GRATIS (under 1500 requests/dag)
      - Kostnad: $0

   c) ResearchExpert (Perplexity):
      - 1 sÃ¸k
      - Kostnad: $0.001

   d) SecurityExpert (DeepSeek V3):
      - Input: 500 tokens
      - Output: 200 tokens
      - Kostnad: $0.0002

3. Depth Answerer (GPT-5 Thinking):
   - Input: 5000 tokens (alle spÃ¸rsmÃ¥l + context)
   - Output: 2000 tokens (dybde-svar)
   - Kostnad: $0.05 input + $0.03 output = $0.08

Total per complex query: ~$0.08
```

---

### **MÃ¥nedlig Kostnad (100 brukere):**

```
Forutsetninger:
- 100 brukere
- 10 queries per bruker per dag
- 30 dager per mÃ¥ned
= 30,000 queries/mÃ¥ned

Fordeling:
- 70% simple (21,000): 21,000 Ã— $0.0001 = $2.10
- 30% complex (9,000): 9,000 Ã— $0.08 = $720

Total: ~$722/mÃ¥ned
```

**Sammenligning:**

| Arkitektur | Kostnad/mnd (100 brukere) | Transparens | Kvalitet |
|------------|---------------------------|-------------|----------|
| **Traditional** (kun store) | $15,000 | Lav | HÃ¸y |
| **3-Tier** (min tidligere anbefaling) | $197 | Lav | Medium |
| **QDA** (Question-Driven) | $722 | **HÃ˜Y** | **HÃ˜Y** |

**QDA gir:**
- 95% besparelse vs. Traditional
- 3.7x dyrere enn 3-Tier, men **mye bedre transparens og kvalitet**

---

### **Skalering:**

| Brukere | Queries/mnd | Kostnad/mnd |
|---------|-------------|-------------|
| 100 | 30,000 | $722 |
| 500 | 150,000 | $3,610 |
| 1,000 | 300,000 | $7,220 |
| 5,000 | 1,500,000 | $36,100 |

---

## âœ… Fordeler vs. âš ï¸ Ulemper

### âœ… **Fordeler:**

1. **Pedagogisk**
   - Bruker lÃ¦rer hvordan man stiller gode spÃ¸rsmÃ¥l
   - Ikke bare "hva er svaret", men "hvordan tenker man"

2. **Transparent**
   - Bruker ser AI's tankegang, ikke bare konklusjon
   - Tillitbyggende (ingen "black box")

3. **Multi-Perspektiv**
   - Data + FÃ¸lelse + Forskning + Sikkerhet samtidig
   - Holistisk forstÃ¥else

4. **Epistemisk Ydmykhet**
   - Store modeller innrÃ¸mmer nÃ¥r de trenger hjelp
   - SmÃ¥ modeller stiller spÃ¸rsmÃ¥l istedenfor Ã¥ gjette

5. **Spesialisert Ekspertise**
   - Hver liten modell blir ekspert i sitt domene
   - Dypere kunnskap enn generalist

6. **Kostnadseffektivt**
   - 95% billigere enn kun store modeller
   - Gemini Flash er GRATIS

7. **Skalerbart**
   - SmÃ¥ modeller kan hÃ¥ndtere hÃ¸y throughput
   - Store modeller kun for 30% av queries

---

### âš ï¸ **Ulemper:**

1. **Lengre Responstid**
   - 3-5 sekunder (vs. 1 sek med Tier 1)
   - Parallelisering hjelper, men ikke instant

2. **Mer Kompleks Kode**
   - Question design-lag mÃ¥ implementeres
   - Flere moving parts Ã¥ vedlikeholde

3. **Dyrere Enn 3-Tier**
   - $722/mnd vs. $197/mnd
   - Men: Kvalitet og transparens er mye bedre

4. **Kan Oppleves "Overforklarende"**
   - Noen brukere vil bare ha svar
   - LÃ¸sning: "Vis mindre" knapp for Ã¥ skjule spÃ¸rsmÃ¥l

5. **Krever Gode Question Design Prompts**
   - SmÃ¥ modeller mÃ¥ trenes til Ã¥ stille gode spÃ¸rsmÃ¥l
   - Iterativ forbedring nÃ¸dvendig

---

## ğŸ¯ NÃ¥r Bruke QDA vs. Andre Arkitekturer?

### **Bruk QDA nÃ¥r:**
- âœ… Transparens er kritisk (NAV, helse, jus)
- âœ… Pedagogisk verdi er viktig (bruker skal lÃ¦re)
- âœ… Multi-perspektiv nÃ¸dvendig (komplekse beslutninger)
- âœ… Tillitt mÃ¥ bygges (nye brukere)

### **Bruk 3-Tier nÃ¥r:**
- âœ… Kostnad er viktigst (bootstrap startup)
- âœ… Rask respons kritisk (<1 sekund)
- âœ… Bruker bare vil ha svar (ikke prosess)

### **Bruk Traditional (kun store) nÃ¥r:**
- âœ… Absolutt beste kvalitet nÃ¸dvendig (medisin, jus)
- âœ… Kostnad ikke et problem
- âœ… Kompleksitet ekstrem (PhD-nivÃ¥)

---

## ğŸ› ï¸ Implementering

Se:
- [IMPLEMENTATION_GUIDE_QDA.md](IMPLEMENTATION_GUIDE_QDA.md) - Komplett kode + timeline
- [QUESTION_DESIGN_ALGORITHMS.md](QUESTION_DESIGN_ALGORITHMS.md) - Algoritmer for question design
- [QDA_UX_DESIGN.md](QDA_UX_DESIGN.md) - UX mockups og interaktivitet

---

## ğŸ“š Referanser

### **Interne Dokumenter:**
- [MCP-ARCHITECTURE-COMPARISON.md](MCP-ARCHITECTURE-COMPARISON.md) - Sammenligning av arkitekturer
- [BRAIN_MCP_ARCHITECTURE_GUIDE.md](../docs/BRAIN_MCP_ARCHITECTURE_GUIDE.md) - Brain-MCP Hybrid
- [MCP-IMPLEMENTATION-PLAN.md](MCP-IMPLEMENTATION-PLAN.md) - Original MCP-plan

### **Filosofisk Grunnlag:**
- Sokrates' maieutikk (spÃ¸rsmÃ¥lskunst)
- Polyvagal Theory (Porges) - stress-adaptive UX
- Triadisk Etikk - kognitiv suverenitet, ontologisk koherens, regenerativ healing

---

## ğŸŒ¿ Avsluttende Ord

Question-Driven Architecture er ikke bare en teknisk lÃ¸sning - det er en **pedagogisk posisjon**:

> "Vi lÃ¦rer ikke ved Ã¥ fÃ¥ svar, men ved Ã¥ lÃ¦re Ã¥ stille de riktige spÃ¸rsmÃ¥lene."

Ved Ã¥ vise bruker hvilke spÃ¸rsmÃ¥l AI stiller, lÃ¦rer bruker hvordan man tenker om komplekse problemer. Dette bygger ikke avhengighet, men **mestringskompetanse**.

**Med ontologisk integritet, felt-bevissthet, og et snev av kosmisk humor!** ğŸŒ¿âœ¨

---

**Versjon:** 1.0
**Sist oppdatert:** 2025-10-20
**Neste review:** Etter Fase 1 implementering (uke 2)
**Forfatter:** Claude Code (Anthropic) i samarbeid med Osvald Noonaut
**Lisens:** Open Source (CC BY-SA 4.0)
